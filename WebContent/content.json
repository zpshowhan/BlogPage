{"meta":{"title":"迷失的男孩","subtitle":"个人博客","description":"火龙战士,zhengweishan,郑伟山的博客，bolg,博客","author":"郑伟山","url":"http://zhengweishan.oschina.io"},"pages":[{"title":"关于我","date":"2017-03-01T09:54:09.191Z","updated":"2017-03-01T09:54:09.191Z","comments":false,"path":"about/index.html","permalink":"http://zhengweishan.oschina.io/about/index.html","excerpt":"","text":"自我介绍祖籍河南，现居北京。IT技术狂，程序猿，软件工程专业，主要从事软件研发。现就职于天源迪科，研发中国联通号卡资源管理项目，中航电子采购平台项目。网络常用ID：火龙战士，迷失的男孩，大山，wesley5201314。 联系方式： Email: wesley5201314@live.com GitHub: https://github.com/wesley5201314 OSChina：https://my.oschina.net/zhengweishan CSDN: http://my.csdn.net/wesley5201314"},{"title":"文章分类","date":"2017-01-20T04:16:36.715Z","updated":"2017-01-20T04:16:36.715Z","comments":false,"path":"categories/index.html","permalink":"http://zhengweishan.oschina.io/categories/index.html","excerpt":"","text":""},{"title":"标签云","date":"2017-01-20T04:16:26.909Z","updated":"2017-01-20T04:16:26.909Z","comments":false,"path":"tags/index.html","permalink":"http://zhengweishan.oschina.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"java并发包里的CountDownLatch的用法","slug":"CountDownLatch","date":"2017-03-26T16:00:00.000Z","updated":"2017-03-27T10:19:12.313Z","comments":true,"path":"2017/03/27/CountDownLatch/","link":"","permalink":"http://zhengweishan.oschina.io/2017/03/27/CountDownLatch/","excerpt":"CountDownLatch:官方的解释为：一个同步辅助类，在完成一组正在其他线程中执行的操作之前，它允许一个或多个线程一直等待。 我们现在就把它理解为倒数计数器，什么是倒数计数器呢，通俗的理解就是这个计数器事先有一个初始计数，在这个计数减到0之前，所有的线程等待。 最近公司有出去旅游，一个业务场景浮现在脑海：部门一共十个人出去旅游，必须10个人上车之后大巴才能开车，下面就来模拟这个上车的过程。","text":"CountDownLatch:官方的解释为：一个同步辅助类，在完成一组正在其他线程中执行的操作之前，它允许一个或多个线程一直等待。 我们现在就把它理解为倒数计数器，什么是倒数计数器呢，通俗的理解就是这个计数器事先有一个初始计数，在这个计数减到0之前，所有的线程等待。 最近公司有出去旅游，一个业务场景浮现在脑海：部门一共十个人出去旅游，必须10个人上车之后大巴才能开车，下面就来模拟这个上车的过程。 模拟上车过程：首先创建人这个实体： 12345678910111213141516171819202122232425262728293031import java.util.concurrent.TimeUnit;public class Person implements Runnable&#123; private Car car; private String name; public Person() &#123; super(); &#125; public Person(Car car,String name) &#123; this.car = car; this.name = name; &#125; @Override public void run() &#123; // TODO Auto-generated method stub try &#123; TimeUnit.SECONDS.sleep((long)(Math.random()*10)); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; car.getton(name); &#125;&#125; 然后在创建一个大巴车： 12345678910111213141516171819202122232425262728293031323334import java.util.concurrent.CountDownLatch;public class Car implements Runnable&#123; private CountDownLatch countDownLatch; public Car() &#123; super(); &#125; public Car(int count) &#123; this.countDownLatch = new CountDownLatch(count); &#125; @Override public void run() &#123; System.out.println(\"一共需要上车屌丝数：\"+countDownLatch.getCount()); try &#123; countDownLatch.await(); System.out.println(\"屌丝全部上车了---&gt;&gt;&gt;老司机准备开车了。。。。\"); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; public void getton(String name) &#123; System.err.println(name+\"上车\"); countDownLatch.countDown(); System.err.println(\"还剩下\"+countDownLatch.getCount()+\"个屌丝没有上车\"); &#125;&#125; 测试类： 1234567891011121314151617public class Test &#123; public static void main(String[] args) &#123; Car c = new Car(10); Thread thread = new Thread(c); thread.start(); for(int i=1;i&lt;=10;i++)&#123; Person p = new Person(c, \"屌丝\"+i); Thread t = new Thread(p); t.start(); &#125; &#125;&#125; 执行结果： 原理分析：当创建CountDownLatch对象时，对象使用构造函数来初始化内部计数器。 CountDownLatch类只提供了一个构造器：public CountDownLatch(intcount) { };//参数count为计数值 每次调用countDown()方法，对象内部计数器减一。当内部计数器达到0时，CountDownLatch对象唤醒全部使用await()方法睡眠的线程。 总结:CountDownLatch对象的内部计数器的值初始化之后是不能修改的，唯一可以修改的方式就是调用countDown()方法，当计数器为0时，await()方法会立即返回，任何方法的调用都是无效的，如果想再次使用同步，必须重新初始化。","categories":[{"name":"并发","slug":"并发","permalink":"http://zhengweishan.oschina.io/categories/并发/"}],"tags":[{"name":"并发，CountDownLatch","slug":"并发，CountDownLatch","permalink":"http://zhengweishan.oschina.io/tags/并发，CountDownLatch/"}]},{"title":"spring boot + mybatis + quartz + druid + swagger2","slug":"spring-boot-demo","date":"2017-03-23T16:00:00.000Z","updated":"2017-03-27T10:28:17.417Z","comments":true,"path":"2017/03/24/spring-boot-demo/","link":"","permalink":"http://zhengweishan.oschina.io/2017/03/24/spring-boot-demo/","excerpt":"spring boot + mybatis + quartz + druid + Swagger2 演示demo 说明：主要演示如何整合，简单的任务调用。 环境准备： jdk:1.7 maven:3.2.3 开发工具：IDEA 源码地址： gitosc: https://git.oschina.net/zhengweishan/spring-boot_demo github: https://github.com/wesley5201314/spring-boot-demo 项目结构：","text":"spring boot + mybatis + quartz + druid + Swagger2 演示demo 说明：主要演示如何整合，简单的任务调用。 环境准备： jdk:1.7 maven:3.2.3 开发工具：IDEA 源码地址： gitosc: https://git.oschina.net/zhengweishan/spring-boot_demo github: https://github.com/wesley5201314/spring-boot-demo 项目结构： 备注：每个包的作用大家一看就明白了，这里主要说明下application.properties：这里主要配置针对于不同的环境用那个配置文件，这里我只提供了开发，测试的环境属性文件。配置如下： spring.profiles.active = dev 应用启动： 1234567891011//启动入口@SpringBootApplication@ServletComponentScan //扫描Servlet@MapperScan(\"com.springboot.demo.dao\") //扫描daopublic class App &#123; public static void main(String[] args) &#123; SpringApplication.run(App.class, args); &#125;&#125; 启动之后访问：durid ： http://localhost:8080/druid/index.html 如图： 登录之后： 配置代码： 1234567891011121314151617181920212223//过滤资源@WebFilter(filterName=\"druidWebStatFilter\",urlPatterns=\"/*\", initParams=&#123; @WebInitParam(name=\"exclusions\",value=\"*.js,*.gif,*.jpg,*.bmp,*.png,*.css,*.ico,/druid/*\")// 忽略资源 &#125;)public class DruidStatFilter extends WebStatFilter implements Serializable&#123; private static final long serialVersionUID = 1L;&#125;//配置访问路径，用户名，密码@WebServlet(urlPatterns = \"/druid/*\", initParams=&#123; @WebInitParam(name=\"allow\",value=\"\"),// IP白名单 (没有配置或者为空，则允许所有访问) @WebInitParam(name=\"deny\",value=\"\"),// IP黑名单 (存在共同时，deny优先于allow) @WebInitParam(name=\"loginUsername\",value=\"root\"),// 用户名 @WebInitParam(name=\"loginPassword\",value=\"root\"),// 密码 @WebInitParam(name=\"resetEnable\",value=\"false\")// 禁用HTML页面上的“Reset All”功能 &#125;)public class DruidStatViewServlet extends StatViewServlet implements Serializable&#123; private static final long serialVersionUID = 1L;&#125; swagger2 ： http://localhost:8080/swagger-ui.html 如图： 配置代码： 1234567891011121314151617181920212223242526272829303132//SwaggerConfig@Configuration@EnableSwagger2public class SwaggerConfig &#123; /** * 可以定义多个组，比如本类中定义把test和demo区分开了 （访问页面就可以看到效果了） * */ @Bean public Docket testApi() &#123; return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() .apis(RequestHandlerSelectors .basePackage(\"com.springboot.demo.controller\")) .paths(PathSelectors.any()).build(); &#125; private ApiInfo apiInfo() &#123; ApiInfo apiInfo = new ApiInfo(\"SpringBootDemo\", // 大标题 \"Spring boot + swagger + mybatis + druid\", // 小标题 \"1.0\", // 版本 \"spring-boot-demo\", \"zhengweishan\", // 作者 \"blog\", // 链接显示文字 \"http://zhengweishan.oschina.io/\"// 网站链接 ); return apiInfo; &#125;&#125; 添加jsp支持 12345678910111213141516import com.springboot.demo.App;import org.springframework.boot.builder.SpringApplicationBuilder;import org.springframework.boot.context.web.SpringBootServletInitializer;/** * Created by wesley on 2017-03-24. * spring boot jsp支持 */public class JspInitContext extends SpringBootServletInitializer &#123; @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder application) &#123; return application.sources(App.class); &#125;&#125; 配置文件配置添加如下： #jsp视图设置 spring.mvc.view.prefix=/WEB-INF/jsp/ spring.mvc.view.suffix=.jsp","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://zhengweishan.oschina.io/categories/SpringBoot/"}],"tags":[{"name":"SpingBoot","slug":"SpingBoot","permalink":"http://zhengweishan.oschina.io/tags/SpingBoot/"}]},{"title":"分布式rpc框架","slug":"boy-rpc-framework","date":"2017-03-22T16:00:00.000Z","updated":"2017-03-23T02:53:29.037Z","comments":true,"path":"2017/03/23/boy-rpc-framework/","link":"","permalink":"http://zhengweishan.oschina.io/2017/03/23/boy-rpc-framework/","excerpt":"什么是RPCRPC（Remote Procedure Call Protocol）——远程过程调用协议，它是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。说得通俗一点就是：调用远程计算机上的服务，就像调用本地服务一样。它可以有不同的实现方式:如RMI(远程方法调用)、Hessian、Http invoker等。另外，RPC是与语言无关的。 RPC示意图（来源网络）","text":"什么是RPCRPC（Remote Procedure Call Protocol）——远程过程调用协议，它是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。说得通俗一点就是：调用远程计算机上的服务，就像调用本地服务一样。它可以有不同的实现方式:如RMI(远程方法调用)、Hessian、Http invoker等。另外，RPC是与语言无关的。 RPC示意图（来源网络） 如何开发一个rpc框架首先我们要考虑我们这个rpc框架需要具备哪些东西，比如：用什么作为底层协议，是否支持高并发，是否支持高效的序列化方式，能否同时具备服务的发现与注册。 RPC 可基于 HTTP 或 TCP 协议，Web Service 就是基于 HTTP 协议的 RPC，它具有良好的跨平台性，但其性能却不如基于 TCP 协议的 RPC。会两方面会直接影响 RPC 的性能，一是传输方式，二是序列化。 众所周知，TCP 是传输层协议，HTTP 是应用层协议，而传输层较应用层更加底层，在数据传输方面，越底层越快，因此，在一般情况下，TCP 一定比 HTTP 快。就序列化而言，Java 提供了默认的序列化方式，但在高并发的情况下，这种方式将会带来一些性能上的瓶颈，于是市面上出现了一系列优秀的序列化框架，比如：Protobuf、Kryo、Hessian、Jackson 等，它们可以取代 Java 默认的序列化，从而提供更高效的性能。 为了支持高并发，传统的阻塞式 IO 显然不太合适，因此我们需要异步的 IO，即 NIO。Java 提供了 NIO 的解决方案，Java 7 也提供了更优秀的 NIO.2 支持，用 Java 实现 NIO 并不是遥不可及的事情，只是需要我们熟悉 NIO 的技术细节。 我们需要将服务部署在分布式环境下的不同节点上，通过服务注册的方式，让客户端来自动发现当前可用的服务，并调用这些服务。这需要一种服务注册表（Service Registry）的组件，让它来注册分布式环境下所有的服务地址（包括：主机名与端口号）。 应用、服务、服务注册表之间的关系见下图： 每台 Server 上可发布多个 Service，这些 Service 共用一个 host 与 port，在分布式环境下会提供 Server 共同对外提供 Service。此外，为防止 Service Registry 出现单点故障，因此需要将其搭建为集群环境。 综合考虑，我们可以选用以下技术作为我们开发rpc框架的技术选型： Spring：它是最强大的依赖注入框架，也是业界的权威标准。 Netty：它使 NIO 编程更加容易，屏蔽了 Java 底层的 NIO 细节。 Protostuff：它基于 Protobuf 序列化框架，面向 POJO，无需编写 .proto 文件。 ZooKeeper/redis：提供服务注册与发现功能，开发分布式系统的必备选择，同时它也具备天生的集群能力。 开发准备项目整体构思如图： 各部分的作用： 开发流程开发之前我们先看下整个服务的请求流程： 这里用redis作为注册中心，来演示一个开发过程。 编写服务接口：public interface HelloRedisService { String sayHello(String str); } 将该接口放在独立的客户端 jar 包中，以供应用使用。 编写服务接口实现类：@BoyRpcService(HelloRedisService.class) public class HelloRedisServiceImpl implements HelloRedisService { @Override public String sayHello(String str) { return &quot;redis say:&quot;+str+&quot;,Hello!&quot;; } } BoyRpcService注解定义在服务接口的实现类上，需要对该实现类指定远程接口，因为实现类可能会实现多个接口，一定要告诉框架哪个才是远程接口。 @Target({ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) @Component public @interface BoyRpcService { /** * 服务接口类 */ Class&lt;?&gt; value(); /** * 服务版本号 */ String version() default &quot;&quot;; } 该注解具备 Spring 的Component注解的特性，可被 Spring 扫描。 该实现类放在服务端 jar 包中，该 jar 包还提供了一些服务端的配置文件与启动服务的引导程序。 配置服务端：服务端 Spring 配置文件名为spring-by-redis.xml，内容如下： &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;context:component-scan base-package=&quot;com.boy.rpc.framework.sample.server&quot;/&gt; &lt;context:property-placeholder location=&quot;classpath:rpc-redis.properties&quot;/&gt; &lt;bean id=&quot;redisConfig&quot; class=&quot;com.boy.rpc.framework.registry.redis.bean.RedisConfig&quot;&gt; &lt;property name=&quot;redisAddress&quot; value=&quot;${rpc.registry_address}&quot;/&gt; &lt;property name=&quot;redisPassword&quot; value=&quot;${rpc.registry_password}&quot;/&gt; &lt;property name=&quot;redisPort&quot; value=&quot;${rpc.registry_port}&quot;/&gt; &lt;/bean&gt; &lt;bean id=&quot;serviceRegistry&quot; class=&quot;com.boy.rpc.framework.registry.redis.RedisServiceRegistry&quot;&gt; &lt;constructor-arg name=&quot;redisConfig&quot; ref =&quot;redisConfig&quot;/&gt; &lt;/bean&gt; &lt;bean id=&quot;rpcServer&quot; class=&quot;com.boy.rpc.framework.server.BoyRpcServer&quot;&gt; &lt;constructor-arg name=&quot;serviceAddress&quot; value=&quot;${rpc.redis_service_address}&quot;/&gt; &lt;constructor-arg name=&quot;serviceRegistry&quot; ref=&quot;serviceRegistry&quot;/&gt; &lt;/bean&gt; &lt;/beans&gt; 具体的配置参数在rpc-redis.properties文件中，内容如下： #服务部署地址# rpc.redis_service_address = 127.0.0.1:8081 #注册中心地址# rpc.registry_address = 127.0.0.1 #注册中心端口# rpc.registry_port = 6379 #注册中心密码# rpc.registry_password = 25362e3e047b413d:Redis123 以上配置表明：连接本地的 redis 服务器，并在 8081 端口上发布 RPC 服务。 启动服务器并发布服务：public class RedisRpcBootstrap { private static final Logger logger = LoggerFactory.getLogger(RedisRpcBootstrap.class); public static void main(String[] args) { logger.debug(&quot;redis rpc start server&quot;); new ClassPathXmlApplicationContext(&quot;spring-by-redis.xml&quot;); } } 实现服务注册:public class RedisServiceRegistry implements ServiceRegistry { private static final Logger logger = LoggerFactory.getLogger(RedisServiceRegistry.class); private RedisClient redisClient = null; public RedisServiceRegistry(RedisConfig redisConfig){ redisClient = new RedisClient(redisConfig); } @Override public void register(String serviceName, String serviceAddress) { logger.debug(&quot;redis register start!&quot;); if(redisClient.existsKey(serviceName)){ List&lt;String&gt; oldList = (List&lt;String&gt;) redisClient.getObject(serviceName); oldList.add(serviceAddress); logger.debug(&quot;service exits create service address : {}&quot;, oldList); redisClient.setObject(serviceName,oldList); }else{ List&lt;String&gt; addressList = new ArrayList&lt;&gt;(); addressList.add(serviceAddress); logger.debug(&quot;service not exits create service address : {}&quot;, addressList); redisClient.setObject(serviceName,addressList); } logger.debug(&quot;redis register end!&quot;); } } 实现 RPC 服务器:使用 Netty 可实现一个支持 NIO 的 RPC 服务器，需要使用ServiceRegistry注册服务地址，代码如下 public class BoyRpcServer implements ApplicationContextAware, InitializingBean { private static final Logger logger = LoggerFactory.getLogger(BoyRpcServer.class); private String serviceAddress; private ServiceRegistry serviceRegistry; /** * 存放 服务名 与 服务对象 之间的映射关系 */ private Map&lt;String, Object&gt; handlerMap = new HashMap&lt;&gt;(); public BoyRpcServer(String serviceAddress) { this.serviceAddress = serviceAddress; } public BoyRpcServer(String serviceAddress, ServiceRegistry serviceRegistry) { this.serviceAddress = serviceAddress; this.serviceRegistry = serviceRegistry; } @Override public void setApplicationContext(ApplicationContext ctx) throws BeansException { // 扫描带有 RpcService 注解的类并初始化 handlerMap 对象 Map&lt;String, Object&gt; serviceBeanMap = ctx.getBeansWithAnnotation(BoyRpcService.class); if (MapUtils.isNotEmpty(serviceBeanMap)) { for (Object serviceBean : serviceBeanMap.values()) { BoyRpcService rpcService = serviceBean.getClass().getAnnotation(BoyRpcService.class); String serviceName = rpcService.value().getName(); String serviceVersion = rpcService.version(); if (StringUtil.isNotEmpty(serviceVersion)) { serviceName += &quot;-&quot; + serviceVersion; } handlerMap.put(serviceName, serviceBean); } } } @Override public void afterPropertiesSet() throws Exception { EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { // 创建并初始化 Netty 服务端 Bootstrap 对象 ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap.group(bossGroup, workerGroup); bootstrap.channel(NioServerSocketChannel.class); bootstrap.childHandler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override public void initChannel(SocketChannel channel) throws Exception { ChannelPipeline pipeline = channel.pipeline(); pipeline.addLast(new BoyRpcDecoder(BoyRpcRequest.class)); // 解码 RPC 请求 pipeline.addLast(new BoyRpcEncoder(BoyRpcResponse.class)); // 编码 RPC 响应 pipeline.addLast(new BoyRpcServerHandler(handlerMap)); // 处理 RPC 请求 } }); bootstrap.option(ChannelOption.SO_BACKLOG, 1024); bootstrap.childOption(ChannelOption.SO_KEEPALIVE, true); // 获取 RPC 服务器的 IP 地址与端口号 String[] addressArray = StringUtil.split(serviceAddress, &quot;:&quot;); String ip = addressArray[0]; int port = Integer.parseInt(addressArray[1]); // 启动 RPC 服务器 ChannelFuture future = bootstrap.bind(ip, port).sync(); // 注册 RPC 服务地址 if (serviceRegistry != null) { for (String interfaceName : handlerMap.keySet()) { serviceRegistry.register(interfaceName, serviceAddress); logger.debug(&quot;register service: {} =&gt; {}&quot;, interfaceName, serviceAddress); } } logger.debug(&quot;server started on port {}&quot;, port); // 关闭 RPC 服务器 future.channel().closeFuture().sync(); } finally { workerGroup.shutdownGracefully(); bossGroup.shutdownGracefully(); } } } 以上代码中，有两个重要的 POJO 需要描述一下，它们分别是BoyRpcRequest与BoyRpcResponse。使用RpcRequest封装 RPC 请求,使用RpcResponse封装 RPC 响应.使用BoyRpcDecoder提供 RPC 解码，只需扩展 Netty 的ByteToMessageDecoder抽象类的decode方法即可,使用BoyRpcEncoder提供 RPC 编码，只需扩展 Netty 的MessageToByteEncoder抽象类的encode方法即可.使用RpcHandler中处理 RPC 请求，只需扩展 Netty 的SimpleChannelInboundHandler抽象类即可，具体代码才看源码： https://git.oschina.net/zhengweishan/boy-rpc-framework 配置客户端：同样使用 Spring 配置文件来配置 RPC 客户端，spring-by-redis.xml代码如下： &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;context:property-placeholder location=&quot;classpath:rpc-redis.properties&quot;/&gt; &lt;bean id=&quot;redisConfig&quot; class=&quot;com.boy.rpc.framework.registry.redis.bean.RedisConfig&quot;&gt; &lt;property name=&quot;redisAddress&quot; value=&quot;${rpc.registry_address}&quot;/&gt; &lt;property name=&quot;redisPassword&quot; value=&quot;${rpc.registry_password}&quot;/&gt; &lt;property name=&quot;redisPort&quot; value=&quot;${rpc.registry_port}&quot;/&gt; &lt;/bean&gt; &lt;bean id=&quot;serviceDiscovery&quot; class=&quot;com.boy.rpc.framework.registry.redis.RedisServiceDiscovery&quot;&gt; &lt;constructor-arg name=&quot;redisConfig&quot; ref=&quot;redisConfig&quot;/&gt; &lt;/bean&gt; &lt;bean id=&quot;rpcProxy&quot; class=&quot;com.boy.rpc.framework.client.BoyRpcProxy&quot;&gt; &lt;constructor-arg name=&quot;serviceDiscovery&quot; ref=&quot;serviceDiscovery&quot;/&gt; &lt;/bean&gt; &lt;/beans&gt; 其中rpc-redis.properties提供了具体的配置： #redis注册中心地址# rpc.registry_address = 127.0.0.1 #redis注册中心端口# rpc.registry_port = 6379 #redis注册中心密码# rpc.registry_password = 25362e3e047b413d:Redis123 实现服务发现:同样使用 redis 实现服务发现功能，见如下代码: public class RedisServiceDiscovery implements ServiceDiscovery { private static final Logger logger = LoggerFactory.getLogger(RedisServiceRegistry.class); private RedisClient redisClient = null; public RedisServiceDiscovery(RedisConfig redisConfig) { redisClient = new RedisClient(redisConfig); } @Override public String discover(String serviceName) { String address = null; if(redisClient.existsKey(serviceName)){ List&lt;String&gt; list = (List&lt;String&gt;) redisClient.getObject(serviceName); int size = list.size(); if(size == 1){ //只有一个地址 address = list.get(0); logger.debug(&quot;get only address : {}&quot;, address); } else { // 若存在多个地址，则随机获取一个地址 address = list.get(ThreadLocalRandom.current().nextInt(size)); logger.debug(&quot;get random address : {}&quot;, address); } } return address; } } 实现 RPC 代理:这里使用 Java 提供的动态代理技术实现 RPC 代理（当然也可以使用 CGLib 来实现），具体代码如下： public class BoyRpcProxy { private static final Logger logger = LoggerFactory.getLogger(BoyRpcProxy.class); private String serviceAddress; private ServiceDiscovery serviceDiscovery; public BoyRpcProxy(String serviceAddress) { this.serviceAddress = serviceAddress; } public BoyRpcProxy(ServiceDiscovery serviceDiscovery) { this.serviceDiscovery = serviceDiscovery; } @SuppressWarnings(&quot;unchecked&quot;) public &lt;T&gt; T create(final Class&lt;?&gt; interfaceClass) { return create(interfaceClass, &quot;&quot;); } @SuppressWarnings(&quot;unchecked&quot;) public &lt;T&gt; T create(final Class&lt;?&gt; interfaceClass, final String serviceVersion) { // 创建动态代理对象 return (T) Proxy.newProxyInstance( interfaceClass.getClassLoader(), new Class&lt;?&gt;[]{interfaceClass}, new InvocationHandler() { @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { // 创建 RPC 请求对象并设置请求属性 BoyRpcRequest request = new BoyRpcRequest(); request.setRequestId(UUID.randomUUID().toString()); request.setInterfaceName(method.getDeclaringClass().getName()); request.setServiceVersion(serviceVersion); request.setMethodName(method.getName()); request.setParameterTypes(method.getParameterTypes()); request.setParameters(args); // 获取 RPC 服务地址 if (serviceDiscovery != null) { String serviceName = interfaceClass.getName(); if (StringUtil.isNotEmpty(serviceVersion)) { serviceName += &quot;-&quot; + serviceVersion; } serviceAddress = serviceDiscovery.discover(serviceName); logger.debug(&quot;discover service: {} =&gt; {}&quot;, serviceName, serviceAddress); } if (StringUtil.isEmpty(serviceAddress)) { throw new RuntimeException(&quot;server address is empty&quot;); } // 从 RPC 服务地址中解析主机名与端口号 String[] array = StringUtil.split(serviceAddress, &quot;:&quot;); String host = array[0]; int port = Integer.parseInt(array[1]); // 创建 RPC 客户端对象并发送 RPC 请求 BoyRpcClient client = new BoyRpcClient(host, port); long time = System.currentTimeMillis(); BoyRpcResponse response = client.send(request); logger.debug(&quot;time: {}ms&quot;, System.currentTimeMillis() - time); if (response == null) { throw new RuntimeException(&quot;response is null&quot;); } // 返回 RPC 响应结果 if (response.hasException()) { throw response.getException(); } else { return response.getResult(); } } } ); } } 发送 RPC 请求:使用 main 方法结合 Spring 编写一个测试，代码如下： public class RedisHelloClient { public static void main(String[] args) throws Exception { ApplicationContext context = new ClassPathXmlApplicationContext(&quot;spring-by-redis.xml&quot;); BoyRpcProxy rpcProxy = context.getBean(BoyRpcProxy.class); HelloRedisService helloService = rpcProxy.create(HelloRedisService.class); String result = helloService.sayHello(&quot;World&quot;); System.out.println(result); System.exit(0); } } 如果不出意外的话，您应该会看到：redis say:World Hello! 总结本文通过 Spring + Netty + Protostuff + ZooKeeper/Redis 实现了一个轻量级 RPC 框架，使用 Spring 提供依赖注入与参数配置，使用 Netty 实现 NIO 方式的数据传输，使用 Protostuff 实现对象序列化，使用 ZooKeeper/Redis 实现服务注册与发现。使用该框架，可将服务部署到分布式环境中的任意节点上，客户端通过远程接口来调用服务端的具体实现，让服务端与客户端的开发完全分离，为实现大规模分布式应用提供了基础支持。","categories":[{"name":"rpc","slug":"rpc","permalink":"http://zhengweishan.oschina.io/categories/rpc/"}],"tags":[{"name":"rpc 分布式","slug":"rpc-分布式","permalink":"http://zhengweishan.oschina.io/tags/rpc-分布式/"}]},{"title":"Tomcat源码学习（六）--Tomcat_7.0.70 生命周期管理","slug":"（六）Tomcat_7.0.70生命周期管理","date":"2017-02-09T16:00:00.000Z","updated":"2017-03-01T08:53:36.617Z","comments":true,"path":"2017/02/10/（六）Tomcat_7.0.70生命周期管理/","link":"","permalink":"http://zhengweishan.oschina.io/2017/02/10/（六）Tomcat_7.0.70生命周期管理/","excerpt":"想必大家都知道，从server.xml文件解析出来的各个对象都是容器，比如：Server、Service、Connector等。这些容器都具有新建、初始化完成、启动、停止、失败、销毁等状态。Tomcat的实现机制是通过实现org.apache.catalina.Lifecycle接口来管理。 Tomcat–Lifecycle接口定义了容器生命周期、容器状态转换及容器状态迁移事件的监听器注册和移除等主要接口。代码清单： public interface Lifecycle { public static final String BEFORE_INIT_EVENT = &quot;before_init&quot;; public static final String AFTER_INIT_EVENT = &quot;after_init&quot;; public static final String START_EVENT = &quot;start&quot;; public static final String BEFORE_START_EVENT = &quot;before_start&quot;; public static final String AFTER_START_EVENT = &quot;after_start&quot;; public static final String STOP_EVENT = &quot;stop&quot;; public static final String BEFORE_STOP_EVENT = &quot;before_stop&quot;; public static final String AFTER_STOP_EVENT = &quot;after_stop&quot;; public static final String AFTER_DESTROY_EVENT = &quot;after_destroy&quot;; public static final String BEFORE_DESTROY_EVENT = &quot;before_destroy&quot;; public static final String PERIODIC_EVENT = &quot;periodic&quot;; public static final String CONFIGURE_START_EVENT = &quot;configure_start&quot;; public static final String CONFIGURE_STOP_EVENT = &quot;configure_stop&quot;; public void addLifecycleListener(LifecycleListener listener); public LifecycleListener[] findLifecycleListeners(); public void removeLifecycleListener(LifecycleListener listener); public void init() throws LifecycleException; public void start() throws LifecycleException; public void stop() throws LifecycleException; public void destroy() throws LifecycleException; public LifecycleState getState(); public String getStateName(); public interface SingleUse { } } 其中，最重要的方法时start和stop方法。父组件通过这两个方法来启动/关闭该组件。addLifecycleListener，findLifecycleListeners，removeLifecycleListener三个方法用于向组件注册/查找/删除监听器。当事件发生时，会触发监听器。接口中还定义了相关事件。","text":"想必大家都知道，从server.xml文件解析出来的各个对象都是容器，比如：Server、Service、Connector等。这些容器都具有新建、初始化完成、启动、停止、失败、销毁等状态。Tomcat的实现机制是通过实现org.apache.catalina.Lifecycle接口来管理。 Tomcat–Lifecycle接口定义了容器生命周期、容器状态转换及容器状态迁移事件的监听器注册和移除等主要接口。代码清单： public interface Lifecycle { public static final String BEFORE_INIT_EVENT = &quot;before_init&quot;; public static final String AFTER_INIT_EVENT = &quot;after_init&quot;; public static final String START_EVENT = &quot;start&quot;; public static final String BEFORE_START_EVENT = &quot;before_start&quot;; public static final String AFTER_START_EVENT = &quot;after_start&quot;; public static final String STOP_EVENT = &quot;stop&quot;; public static final String BEFORE_STOP_EVENT = &quot;before_stop&quot;; public static final String AFTER_STOP_EVENT = &quot;after_stop&quot;; public static final String AFTER_DESTROY_EVENT = &quot;after_destroy&quot;; public static final String BEFORE_DESTROY_EVENT = &quot;before_destroy&quot;; public static final String PERIODIC_EVENT = &quot;periodic&quot;; public static final String CONFIGURE_START_EVENT = &quot;configure_start&quot;; public static final String CONFIGURE_STOP_EVENT = &quot;configure_stop&quot;; public void addLifecycleListener(LifecycleListener listener); public LifecycleListener[] findLifecycleListeners(); public void removeLifecycleListener(LifecycleListener listener); public void init() throws LifecycleException; public void start() throws LifecycleException; public void stop() throws LifecycleException; public void destroy() throws LifecycleException; public LifecycleState getState(); public String getStateName(); public interface SingleUse { } } 其中，最重要的方法时start和stop方法。父组件通过这两个方法来启动/关闭该组件。addLifecycleListener，findLifecycleListeners，removeLifecycleListener三个方法用于向组件注册/查找/删除监听器。当事件发生时，会触发监听器。接口中还定义了相关事件。 下面从一幅图来了解Tomcat涉及生命周期管理的主要类： Lifecycle：定义了容器生命周期、容器状态转换及容器状态迁移事件的监听器注册和移除等主要接口； LifecycleBase：作为Lifecycle接口的抽象实现类，运用抽象模板模式将所有容器的生命周期及状态转换衔接起来，此外还提供了生成LifecycleEvent事件的接口； LifecycleSupport：提供有关LifecycleEvent事件的监听器注册、移除，并且使用经典的监听器模式，实现事件生成后触打监听器的实现； MBeanRegistration：Java jmx框架提供的注册MBean的接口，引入此接口是为了便于使用JMX提供的管理功能； LifecycleMBeanBase：Tomcat提供的对MBeanRegistration的抽象实现类，运用抽象模板模式将所有容器统一注册到JMX； 从上图可以看出ContainerBase、StandardServer、StandardService、WebappLoader、Connector、StandardContext、StandardEngine、StandardHost、StandardWrapper等容器都继承了LifecycleMBeanBase，因此这些容器都具有了同样的生命周期并可以通过JMX进行管理。 什么是JMX?JMX（Java Management Extensions，即Java管理扩展）是一个为应用程序、设备、系统等植入管理功能的框架。JMX可以跨越一系列异构操作系统平台、系统体系结构和网络传输协议，灵活的开发无缝集成的系统、网络和服务管理应用。 JMX体系结构分为以下四个层次： 设备层 设备层（Instrumentation Level）：主要定义了信息模型。在JMX中，各种管理对象以管理构件的形式存在，需要管理时，向MBean服务器进行注册。该层还定义了通知机制以及一些辅助元数据类。 代理层 代理层（Agent Level）：主要定义了各种服务以及通信模型。该层的核心是一个MBean服务器，所有的管理构件都需要向它注册，才能被管理。注册在MBean服务器上管理构件并不直接和远程应用程序进行通信，它们通过协议适配器和连接器进行通信。而协议适配器和连接器也以管理构件的形式向MBean服务器注册才能提供相应的服务。 分布服务层 分布服务层（Distributed Service Level）：主要定义了能对代理层进行操作的管理接口和构件，这样管理者就可以操作代理。然而，当前的JMX规范并没有给出这一层的具体规范。 附加管理协议API 定义的API主要用来支持当前已经存在的网络管理协议，如SNMP、TMN、CIM/WBEM等。 Tomcat–事件、监听每个容器由于继承自LifecycleBase，当容器状态发生变化时，都会调用fireLifecycleEvent方法，生成LifecycleEvent，并且交由此容器的事件监听器处理。 LifecycleBase的fireLifecycleEvent方法的实现： protected void fireLifecycleEvent(String type, Object data) { lifecycle.fireLifecycleEvent(type, data); } //lifecycle定义 private LifecycleSupport lifecycle = new LifecycleSupport(this); //LifecycleSupport的fireLifecycleEvent方法的实现 public void fireLifecycleEvent(String type, Object data) { LifecycleEvent event = new LifecycleEvent(lifecycle, type, data); LifecycleListener interested[] = listeners; for (int i = 0; i &lt; interested.length; i++) interested[i].lifecycleEvent(event); } 然后将事件通知给所有监听当前容器的生命周期监听器LifecycleListener，并调用LifecycleListener的lifecycleEvent方法。 那么监听器LifecycleListener是何时注册进来的？其实每个容器在新建、初始化、启动，销毁，被添加到父容器的过程中都会调用父类LifecycleBase的addLifecycleListener方法： public void addLifecycleListener(LifecycleListener listener) { lifecycle.addLifecycleListener(listener); } LifecycleBase的addLifecycleListener方法实际是对LifecycleSupport的addLifecycleListener方法的简单代理，LifecycleSupport的addLifecycleListener方法的实现： public void addLifecycleListener(LifecycleListener listener) { synchronized (listenersLock) { LifecycleListener results[] = new LifecycleListener[listeners.length + 1]; for (int i = 0; i &lt; listeners.length; i++) results[i] = listeners[i]; results[listeners.length] = listener; listeners = results; } } 容器会最终调用每个对此容器感兴趣的LifecycleListener的lifecycleEvent方法，那么LifecycleListener的lifecycleEvent方法会做些什么呢？为了简单起见，我们以监听器JasperListener为例，JasperListener的lifecycleEvent方法的实现： public void lifecycleEvent(LifecycleEvent event) { if (Lifecycle.BEFORE_INIT_EVENT.equals(event.getType())) { try { // Set JSP factory Class.forName(&quot;org.apache.jasper.compiler.JspRuntimeContext&quot;, true, this.getClass().getClassLoader()); } catch (Throwable t) { ExceptionUtils.handleThrowable(t); // Should not occur, obviously log.warn(&quot;Couldn&apos;t initialize Jasper&quot;, t); } // Another possibility is to do directly: // JspFactory.setDefaultFactory(new JspFactoryImpl()); } } Tomcat–容器生命周期StandardServer、StandardService、Connector、StandardContext这些容器，彼此之间都有父子关系，每个容器都可能包含零个或者多个子容器，这些子容器可能存在不同类型或者相同类型的多个。在一个容器创建成功后，会有以下状态： NEW：容器刚刚创建时，即在LifecycleBase实例构造完成时的状态。 INITIALIZED：容器初始化完成时的状态。 STARTING_PREP：容器启动前的状态。 STARTING：容器启动过程中的状态。 STARTED：容器启动完成的状态。 STOPPING_PREP：容器停止前的状态。 STOPPING：容器停止过程中的状态。 STOPPED：容器停止完成的状态。 DESTROYED：容器销毁后的状态。 FAILED：容器启动、停止过程中出现异常的状态。 MUST_STOP：此状态未使用。 MUST_DESTROY：此状态未使用。 这些状态都定义在枚举类LifecycleState中。代码详单： public enum LifecycleState { NEW(false, null), INITIALIZING(false, Lifecycle.BEFORE_INIT_EVENT), INITIALIZED(false, Lifecycle.AFTER_INIT_EVENT), STARTING_PREP(false, Lifecycle.BEFORE_START_EVENT), STARTING(true, Lifecycle.START_EVENT), STARTED(true, Lifecycle.AFTER_START_EVENT), STOPPING_PREP(true, Lifecycle.BEFORE_STOP_EVENT), STOPPING(false, Lifecycle.STOP_EVENT), STOPPED(false, Lifecycle.AFTER_STOP_EVENT), DESTROYING(false, Lifecycle.BEFORE_DESTROY_EVENT), DESTROYED(false, Lifecycle.AFTER_DESTROY_EVENT), FAILED(false, null), /** * @deprecated Unused. Will be removed in Tomcat 9.0.x. The state transition * checking in {@link org.apache.catalina.util.LifecycleBase} * makes it impossible to use this state. The intended behaviour * can be obtained by setting the state to * {@link LifecycleState#FAILED} in * &lt;code&gt;LifecycleBase.startInternal()&lt;/code&gt; */ @Deprecated MUST_STOP(true, null), /** * @deprecated Unused. Will be removed in Tomcat 9.0.x. The state transition * checking in {@link org.apache.catalina.util.LifecycleBase} * makes it impossible to use this state. The intended behaviour * can be obtained by implementing {@link Lifecycle.SingleUse}. */ @Deprecated MUST_DESTROY(false, null); private final boolean available; private final String lifecycleEvent; private LifecycleState(boolean available, String lifecycleEvent) { this.available = available; this.lifecycleEvent = lifecycleEvent; } /** * May the public methods other than property getters/setters and lifecycle * methods be called for a component in this state? It returns * &lt;code&gt;true&lt;/code&gt; for any component in any of the following states: * &lt;ul&gt; * &lt;li&gt;{@link #STARTING}&lt;/li&gt; * &lt;li&gt;{@link #STARTED}&lt;/li&gt; * &lt;li&gt;{@link #STOPPING_PREP}&lt;/li&gt; * &lt;li&gt;{@link #MUST_STOP}&lt;/li&gt; * &lt;/ul&gt; */ public boolean isAvailable() { return available; } /** * */ public String getLifecycleEvent() { return lifecycleEvent; } } 每个容器都会有自身的生命周期，其中也涉及状态的迁移，以及伴随的事件生成。所有容器的状态转换（如新建、初始化、启动、停止等）都是由外到内，由上到下进行，即先执行父容器的状态转换及相关操作，然后再执行子容器的转态转换，这个过程是层层迭代执行的。 Tomcat容器生命周期—-新建所有容器在构造的过程中，都会首先对父类LifecycleBase进行构造。LifecycleBase中定义了所有容器的起始状态为LifecycleState.NEW。 private volatile LifecycleState state = LifecycleState.NEW; Tomcat容器生命周期—-初始化每个容器的init方法是自身初始化的入口，其初始化过程如图所示： 调用方调用容器父类LifecycleBase的init方法，LifecycleBase的init方法主要完成一些所有容器公共抽象出来的动作； LifecycleBase的init方法调用具体容器的initInternal方法实现，此initInternal方法用于对容器本身真正的初始化； 具体容器的initInternal方法调用父类LifecycleMBeanBase的initInternal方法实现，此initInternal方法用于将容器托管到JMX，便于运维管理； LifecycleMBeanBase的initInternal方法调用自身的register方法，将容器作为MBean注册到MBeanServer； 容器如果有子容器，会调用子容器的init方法； 容器初始化完毕，LifecycleBase会将容器的状态更改为初始化完毕，即LifecycleState.INITIALIZED。 **init方法的实现** public final synchronized void init() throws LifecycleException { if (!state.equals(LifecycleState.NEW)) { invalidTransition(Lifecycle.BEFORE_INIT_EVENT); } setStateInternal(LifecycleState.INITIALIZING, null, false); try { initInternal();//调用具体容器的initInternal方法实现 } catch (Throwable t) { ExceptionUtils.handleThrowable(t); setStateInternal(LifecycleState.FAILED, null, false); throw new LifecycleException( sm.getString(&quot;lifecycleBase.initFail&quot;,toString()), t); } setStateInternal(LifecycleState.INITIALIZED, null, false); } 只有当前容器的状态处于LifecycleState.NEW的才可以被初始化，真正执行初始化的方法是initInternal，当初始化完毕，当前容器的状态会被更改为LifecycleState.INITIALIZED。以StandardService这个容器为例举例分析，StandardService容器的initInternal方法实现： protected void initInternal() throws LifecycleException { super.initInternal(); if (container != null) { container.init(); } // Initialize any Executors for (Executor executor : findExecutors()) { if (executor instanceof LifecycleMBeanBase) { ((LifecycleMBeanBase) executor).setDomain(getDomain()); } executor.init(); } // Initialize our defined Connectors synchronized (connectorsLock) { for (Connector connector : connectors) { try { connector.init(); } catch (Exception e) { String message = sm.getString( &quot;standardService.connector.initFailed&quot;, connector); log.error(message, e); if (Boolean.getBoolean(&quot;org.apache.catalina.startup.EXIT_ON_INIT_FAILURE&quot;)) throw new LifecycleException(message); } } } } 其处理过程： a、调用父类LifecycleBase的initInternal方法，为当前容器创建DynamicMBean，并注册到JMX中。 protected void initInternal() throws LifecycleException { // If oname is not null then registration has already happened via // preRegister(). if (oname == null) { mserver = Registry.getRegistry(null, null).getMBeanServer(); oname = register(this, getObjectNameKeyProperties()); } } //getObjectNameKeyProperties()方法 public final String getObjectNameKeyProperties() { return &quot;type=Service&quot;; } LifecycleBase的register方法会为当前容器创建对应的注册名称，以StandardService为例，getDomain默认返回Catalina，因此StandardService的JMX注册名称默认为Catalina:type=Service，真正的注册在registerComponent方法中实现。 //register方法 protected final ObjectName register(Object obj, String objectNameKeyProperties) { // Construct an object name with the right domain StringBuilder name = new StringBuilder(getDomain()); name.append(&apos;:&apos;); name.append(objectNameKeyProperties); ObjectName on = null; try { on = new ObjectName(name.toString()); Registry.getRegistry(null, null).registerComponent(obj, on, null); } catch (MalformedObjectNameException e) { log.warn(sm.getString(&quot;lifecycleMBeanBase.registerFail&quot;, obj, name), e); } catch (Exception e) { log.warn(sm.getString(&quot;lifecycleMBeanBase.registerFail&quot;, obj, name), e); } return on; } //registerComponent方法 public void registerComponent(Object bean, ObjectName oname, String type) throws Exception { if( log.isDebugEnabled() ) { log.debug( &quot;Managed= &quot;+ oname); } if( bean ==null ) { log.error(&quot;Null component &quot; + oname ); return; } try { if( type==null ) { type=bean.getClass().getName(); } ManagedBean managed = findManagedBean(bean.getClass(), type); // The real mbean is created and registered DynamicMBean mbean = managed.createMBean(bean); if( getMBeanServer().isRegistered( oname )) { if( log.isDebugEnabled()) { log.debug(&quot;Unregistering existing component &quot; + oname ); } getMBeanServer().unregisterMBean( oname ); } getMBeanServer().registerMBean( mbean, oname); } catch( Exception ex) { log.error(&quot;Error registering &quot; + oname, ex ); throw ex; } } Registry的registerComponent方法会为当前容器（如StandardService）创建DynamicMBean，并且注册到MBeanServer中。 b、将StringCache、MBeanFactory、globalNamingResources注册到JMX 其中StringCache的注册名为Catalina:type=StringCache，MBeanFactory的注册名为Catalina:type=MBeanFactory，globalNamingResources的注册名为Catalina:type=NamingResources（如StandardService则为：Catalina:type=Service） c、初始化子容器 主要对Service子容器进行初始化，默认是StandardService。 注意：个别容器并不完全遵循以上的初始化过程，比如ProtocolHandler作为Connector的子容器，其初始化过程并不是由Connector的initInternal方法调用的，而是与启动过程一道被Connector的startInternal方法所调用。 Tomcat容器生命周期—-容器启动每个容器的start方法是自身启动的入口 调用方调用容器父类LifecycleBase的start方法，LifecycleBase的start方法主要完成一些所有容器公共抽象出来的动作； LifecycleBase的start方法先将容器状态改为LifecycleState.STARTING_PREP，然后调用具体容器的startInternal方法实现，此startInternal方法用于对容器本身真正的初始化； 具体容器的startInternal方法会将容器状态改为LifecycleState.STARTING，容器如果有子容器，会调用子容器的start方法启动子容器； 容器启动完毕，LifecycleBase会将容器的状态更改为启动完毕，即LifecycleState.STARTED。 //LifecycleBase的start方法 public final synchronized void start() throws LifecycleException { if (LifecycleState.STARTING_PREP.equals(state) || LifecycleState.STARTING.equals(state) || LifecycleState.STARTED.equals(state)) { if (log.isDebugEnabled()) { Exception e = new LifecycleException(); log.debug(sm.getString(&quot;lifecycleBase.alreadyStarted&quot;, toString()), e); } else if (log.isInfoEnabled()) { log.info(sm.getString(&quot;lifecycleBase.alreadyStarted&quot;, toString())); } return; } if (state.equals(LifecycleState.NEW)) { init(); } else if (state.equals(LifecycleState.FAILED)) { stop(); } else if (!state.equals(LifecycleState.INITIALIZED) &amp;&amp; !state.equals(LifecycleState.STOPPED)) { invalidTransition(Lifecycle.BEFORE_START_EVENT); } setStateInternal(LifecycleState.STARTING_PREP, null, false); try { startInternal(); } catch (Throwable t) { // This is an &apos;uncontrolled&apos; failure so put the component into the // FAILED state and throw an exception. ExceptionUtils.handleThrowable(t); setStateInternal(LifecycleState.FAILED, null, false); throw new LifecycleException(sm.getString(&quot;lifecycleBase.startFail&quot;, toString()), t); } if (state.equals(LifecycleState.FAILED)) { // This is a &apos;controlled&apos; failure. The component put itself into the // FAILED state so call stop() to complete the clean-up. stop(); } else if (!state.equals(LifecycleState.STARTING)) { // Shouldn&apos;t be necessary but acts as a check that sub-classes are // doing what they are supposed to. invalidTransition(Lifecycle.AFTER_START_EVENT); } else { setStateInternal(LifecycleState.STARTED, null, false); } } 在真正启动容器之前需要做2种检查： 如果当前容器已经处于启动过程（即容器状态为LifecycleState.STARTING_PREP、LifecycleState.STARTING、LifecycleState.STARTED）中，则会产生并且用日志记录LifecycleException异常并退出。如果容器依然处于LifecycleState.NEW状态，则在启动之前，首先确保初始化完毕。 启动容器完毕后，需要做1种检查:即如果容器启动异常导致容器进入LifecycleState.FAILED或者LifecycleState.MUST_STOP状态，则需要调用stop方法停止容器。 以StandardService为例，其startInternal的实现: protected void startInternal() throws LifecycleException { if(log.isInfoEnabled()) log.info(sm.getString(&quot;standardService.start.name&quot;, this.name)); setState(LifecycleState.STARTING);//将自身状态更改为LifecycleState.STARTING； // Start our defined Container first if (container != null) { synchronized (container) { container.start();//调用子容器Service的start方法启动子容器。 } } synchronized (executors) { for (Executor executor: executors) { executor.start(); } } // Start our defined Connectors second synchronized (connectorsLock) { for (Connector connector: connectors) { try { // If it has already failed, don&apos;t try and start it if (connector.getState() != LifecycleState.FAILED) { connector.start(); } } catch (Exception e) { log.error(sm.getString( &quot;standardService.connector.startFailed&quot;, connector), e); } } } } 除了初始化、启动外，各个容器还有停止和销毁的生命周期，其原理与初始化、启动类似。 总结Tomcat通过将内部所有组件都抽象为容器，为容器提供统一的生命周期管理，各个子容器只需要关心各自的具体实现，这便于Tomcat以后扩展更多的容器。","categories":[{"name":"Tomcat源码","slug":"Tomcat源码","permalink":"http://zhengweishan.oschina.io/categories/Tomcat源码/"}],"tags":[{"name":"tomcat","slug":"tomcat","permalink":"http://zhengweishan.oschina.io/tags/tomcat/"}]},{"title":"Tomcat源码学习（五）-- Tomcat_7.0.70 类加载体系分析","slug":"（五）Tomcat_7.0.70类加载体系","date":"2017-02-08T16:00:00.000Z","updated":"2017-03-01T09:01:05.987Z","comments":true,"path":"2017/02/09/（五）Tomcat_7.0.70类加载体系/","link":"","permalink":"http://zhengweishan.oschina.io/2017/02/09/（五）Tomcat_7.0.70类加载体系/","excerpt":"1、前言Tomcat遵循J2EE规范，实现了Web容器。Java虚拟机有自己的一套类加载体系，同样Tomcat也有自己的一套类加载体系。 2、概述首先简单介绍下Java虚拟机的主要的类加载器： 启动类加载器（bootstrap classloader） 它用来加载 Java 的核心库，是用原生代码(本地代码，与平台有关)来实现的，并不继承自java.lang.ClassLoader。这个类加载器负责将存放在\\lib目录中的，或者被-Xbootclasspath参数所指定的路径中的，并且是虚拟机识加的（仅按照文件名识别，如rt.jar，名字不符合的类库即使放在lib目录中也不会被加载）类库加载到虚拟机内存中。启动类加载器无法被Java程序直接引用。 扩展类加载器（extensions classloader） 扩展类加载器是由 Sun 的 ExtClassLoader（sun.misc.Launcher$ExtClassLoader） 实现的。它负责将 &lt; Java_Runtime_Home &gt;/lib/ext 或者由系统变量java.ext.dir 指定位置中的类库加载到内存中 应用程序类加载器（application classloader） 系统类加载器是由 Sun 的 AppClassLoader（sun.misc.Launcher$AppClassLoader）实现的，由于这个类加载器是ClassLoader中getSystemClassLoader()方法的返回值，所以一般也称它为系统类加载器。它根据 Java 应用的类路径（CLASSPATH）来加载 Java 类。开发者可以直接使用这个类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序默认的类加载器。 用户自定义的类装载器 用户自定义的类装载器是普通的Java对象，它的类必须派生自java.lang.ClassLoader类。ClassLoader中定义的方法为程序为程序提供了访问类装载器机制的接口。此外，对于每一个被装载的类型，Java虚拟机都会为它创建一个java.lang.Class类的实例来代表该类型。和所有其它对象一样，用户自定义的类装载器以有Class类的实例都放在内存中的堆区，而装载的类型信息则都放在方法区。","text":"1、前言Tomcat遵循J2EE规范，实现了Web容器。Java虚拟机有自己的一套类加载体系，同样Tomcat也有自己的一套类加载体系。 2、概述首先简单介绍下Java虚拟机的主要的类加载器： 启动类加载器（bootstrap classloader） 它用来加载 Java 的核心库，是用原生代码(本地代码，与平台有关)来实现的，并不继承自java.lang.ClassLoader。这个类加载器负责将存放在\\lib目录中的，或者被-Xbootclasspath参数所指定的路径中的，并且是虚拟机识加的（仅按照文件名识别，如rt.jar，名字不符合的类库即使放在lib目录中也不会被加载）类库加载到虚拟机内存中。启动类加载器无法被Java程序直接引用。 扩展类加载器（extensions classloader） 扩展类加载器是由 Sun 的 ExtClassLoader（sun.misc.Launcher$ExtClassLoader） 实现的。它负责将 &lt; Java_Runtime_Home &gt;/lib/ext 或者由系统变量java.ext.dir 指定位置中的类库加载到内存中 应用程序类加载器（application classloader） 系统类加载器是由 Sun 的 AppClassLoader（sun.misc.Launcher$AppClassLoader）实现的，由于这个类加载器是ClassLoader中getSystemClassLoader()方法的返回值，所以一般也称它为系统类加载器。它根据 Java 应用的类路径（CLASSPATH）来加载 Java 类。开发者可以直接使用这个类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序默认的类加载器。 用户自定义的类装载器 用户自定义的类装载器是普通的Java对象，它的类必须派生自java.lang.ClassLoader类。ClassLoader中定义的方法为程序为程序提供了访问类装载器机制的接口。此外，对于每一个被装载的类型，Java虚拟机都会为它创建一个java.lang.Class类的实例来代表该类型。和所有其它对象一样，用户自定义的类装载器以有Class类的实例都放在内存中的堆区，而装载的类型信息则都放在方法区。 然后在来一张图简要说明Tomcat的类加载体系（图画的不好）： ClassLoader：Java提供的类加载器抽象类，用户自定义的类加载器需要继承实现 commonLoader：Tomcat最基本的类加载器，加载路径中的class可以被Tomcat容器本身以及各个Webapp访问 catalinaLoader：Tomcat容器私有的类加载器，加载路径中的class对于Webapp不可见 sharedLoader：各个Webapp共享的类加载器，加载路径中的class对于所有Webapp可见，但是对于Tomcat容器不可见 WebappClassLoader：各个Webapp私有的类加载器，加载路径中的class只对当前Webapp可见 3、分析commonLoader、catalinaLoader和sharedLoader在Tomcat容器初始化的一开始，即调用Bootstrap的init方法时创建。catalinaLoader会被设置为Tomcat主线程的线程上下文类加载器，并且使用catalinaLoader加载Tomcat容器自身容器下的class。Bootstrap的init方法的部分代码如下： /** Initialize daemon.*/public void init() throws Exception{ setCatalinaHome(); setCatalinaBase(); initClassLoaders(); Thread.currentThread().setContextClassLoader(catalinaLoader); SecurityClassLoad.securityClassLoad(catalinaLoader); …..} initClassLoaders方法： private void initClassLoaders() { try { commonLoader = createClassLoader(&quot;common&quot;, null); if( commonLoader == null ) { // no config file, default to this loader - we might be in a &apos;single&apos; env. commonLoader=this.getClass().getClassLoader(); } catalinaLoader = createClassLoader(&quot;server&quot;, commonLoader); sharedLoader = createClassLoader(&quot;shared&quot;, commonLoader); } catch (Throwable t) { handleThrowable(t); log.error(&quot;Class loader creation threw exception&quot;, t); System.exit(1); } } 创建类加载器的createClassLoader方法的实现： private ClassLoader createClassLoader(String name, ClassLoader parent) throws Exception { String value = CatalinaProperties.getProperty(name + &quot;.loader&quot;); if ((value == null) || (value.equals(&quot;&quot;))) return parent; value = replace(value); List&lt;Repository&gt; repositories = new ArrayList&lt;Repository&gt;(); StringTokenizer tokenizer = new StringTokenizer(value, &quot;,&quot;); while (tokenizer.hasMoreElements()) { String repository = tokenizer.nextToken().trim(); if (repository.length() == 0) { continue; } // Check for a JAR URL repository try { @SuppressWarnings(&quot;unused&quot;) URL url = new URL(repository); repositories.add( new Repository(repository, RepositoryType.URL)); continue; } catch (MalformedURLException e) { // Ignore } // Local repository if (repository.endsWith(&quot;*.jar&quot;)) { repository = repository.substring (0, repository.length() - &quot;*.jar&quot;.length()); repositories.add( new Repository(repository, RepositoryType.GLOB)); } else if (repository.endsWith(&quot;.jar&quot;)) { repositories.add( new Repository(repository, RepositoryType.JAR)); } else { repositories.add( new Repository(repository, RepositoryType.DIR)); } } return ClassLoaderFactory.createClassLoader(repositories, parent); } createClassLoader最终使用ClassLoaderFactory.createClassLoader(locations, types, parent)方法创建ClassLoader。 我们在看SecurityClassLoad.securityClassLoad(catalinaLoader); public static void securityClassLoad(ClassLoader loader) throws Exception { if( System.getSecurityManager() == null ){ return; } loadCorePackage(loader); loadCoyotePackage(loader); loadLoaderPackage(loader); loadRealmPackage(loader); loadServletsPackage(loader); loadSessionPackage(loader); loadUtilPackage(loader); loadValvesPackage(loader); loadJavaxPackage(loader); loadConnectorPackage(loader); loadTomcatPackage(loader); } securityClassLoad方法主要加载Tomcat容器所需的class，包括： Tomcat核心class，即org.apache.catalina.core路径下的class； org.apache.catalina.loader.WebappClassLoader$PrivilegedFindResourceByName Tomcat有关session的class，即org.apache.catalina.session路径下的class Tomcat工具类的class，即org.apache.catalina.util路径下的class javax.servlet.http.Cookie Tomcat处理请求的class，即org.apache.catalina.connector路径下的class Tomcat其它工具类的class，也是org.apache.catalina.util路径下的class 我们以加载Tomcat核心class的loadCorePackage方法为例，查看其实现： private static final void loadCorePackage(ClassLoader loader) throws Exception { final String basePackage = &quot;org.apache.catalina.core.&quot;; loader.loadClass (basePackage + &quot;AccessLogAdapter&quot;); loader.loadClass (basePackage + &quot;ApplicationContextFacade$1&quot;); loader.loadClass (basePackage + &quot;ApplicationDispatcher$PrivilegedForward&quot;); loader.loadClass (basePackage + &quot;ApplicationDispatcher$PrivilegedInclude&quot;); loader.loadClass (basePackage + &quot;AsyncContextImpl&quot;); loader.loadClass (basePackage + &quot;AsyncContextImpl$DebugException&quot;); loader.loadClass (basePackage + &quot;AsyncContextImpl$1&quot;); loader.loadClass (basePackage + &quot;AsyncListenerWrapper&quot;); loader.loadClass (basePackage + &quot;ContainerBase$PrivilegedAddChild&quot;); loader.loadClass (basePackage + &quot;DefaultInstanceManager$1&quot;); loader.loadClass (basePackage + &quot;DefaultInstanceManager$2&quot;); loader.loadClass (basePackage + &quot;DefaultInstanceManager$3&quot;); loader.loadClass (basePackage + &quot;DefaultInstanceManager$AnnotationCacheEntry&quot;); loader.loadClass (basePackage + &quot;DefaultInstanceManager$AnnotationCacheEntryType&quot;); loader.loadClass (basePackage + &quot;ApplicationHttpRequest$AttributeNamesEnumerator&quot;); } 至此为止，我们还没有看到WebappClassLoader。启动StandardContext的时候会创建WebappLoader，StandardContext的方法startInternal的部分代码如下： protected synchronized void startInternal() throws LifecycleException { ...... if (getLoader() == null) { WebappLoader webappLoader = new WebappLoader(getParentClassLoader()); webappLoader.setDelegate(getDelegate()); setLoader(webappLoader); } ...... if ((loader != null) &amp;&amp; (loader instanceof Lifecycle)) ((Lifecycle) loader).start(); // 省略后边的代码 } 从上面代码看到最后会调用WebappLoader的start方法: public final synchronized void start() throws LifecycleException { if (LifecycleState.STARTING_PREP.equals(state) || LifecycleState.STARTING.equals(state) || LifecycleState.STARTED.equals(state)) { if (log.isDebugEnabled()) { Exception e = new LifecycleException(); log.debug(sm.getString(&quot;lifecycleBase.alreadyStarted&quot;, toString()), e); } else if (log.isInfoEnabled()) { log.info(sm.getString(&quot;lifecycleBase.alreadyStarted&quot;, toString())); } return; } if (state.equals(LifecycleState.NEW)) { init(); } else if (state.equals(LifecycleState.FAILED)) { stop(); } else if (!state.equals(LifecycleState.INITIALIZED) &amp;&amp; !state.equals(LifecycleState.STOPPED)) { invalidTransition(Lifecycle.BEFORE_START_EVENT); } setStateInternal(LifecycleState.STARTING_PREP, null, false); try { startInternal();//start再次调用了startInternal方法（WebappLoader中的方法） } catch (Throwable t) { // This is an &apos;uncontrolled&apos; failure so put the component into the // FAILED state and throw an exception. ExceptionUtils.handleThrowable(t); setStateInternal(LifecycleState.FAILED, null, false); throw new LifecycleException(sm.getString(&quot;lifecycleBase.startFail&quot;, toString()), t); } if (state.equals(LifecycleState.FAILED)) { // This is a &apos;controlled&apos; failure. The component put itself into the // FAILED state so call stop() to complete the clean-up. stop(); } else if (!state.equals(LifecycleState.STARTING)) { // Shouldn&apos;t be necessary but acts as a check that sub-classes are // doing what they are supposed to. invalidTransition(Lifecycle.AFTER_START_EVENT); } else { setStateInternal(LifecycleState.STARTED, null, false); } } start又调用了startInternal方法，startInternal的实现如下： protected void startInternal() throws LifecycleException { if (log.isDebugEnabled()) log.debug(sm.getString(&quot;webappLoader.starting&quot;)); if (container.getResources() == null) { log.info(&quot;No resources for &quot; + container); setState(LifecycleState.STARTING); return; } // Register a stream handler factory for the JNDI protocol URLStreamHandlerFactory streamHandlerFactory = DirContextURLStreamHandlerFactory.getInstance(); if (first) { first = false; try { URL.setURLStreamHandlerFactory(streamHandlerFactory); } catch (Exception e) { // Log and continue anyway, this is not critical log.error(&quot;Error registering jndi stream handler&quot;, e); } catch (Throwable t) { ExceptionUtils.handleThrowable(t); // This is likely a dual registration log.info(&quot;Dual registration of jndi stream handler: &quot; + t.getMessage()); } } // Construct a class loader based on our current repositories list try { classLoader = createClassLoader(); classLoader.setResources(container.getResources()); classLoader.setDelegate(this.delegate); classLoader.setSearchExternalFirst(searchExternalFirst); if (container instanceof StandardContext) { classLoader.setAntiJARLocking( ((StandardContext) container).getAntiJARLocking()); classLoader.setClearReferencesRmiTargets( ((StandardContext) container).getClearReferencesRmiTargets()); classLoader.setClearReferencesStatic( ((StandardContext) container).getClearReferencesStatic()); classLoader.setClearReferencesStopThreads( ((StandardContext) container).getClearReferencesStopThreads()); classLoader.setClearReferencesStopTimerThreads( ((StandardContext) container).getClearReferencesStopTimerThreads()); classLoader.setClearReferencesHttpClientKeepAliveThread( ((StandardContext) container).getClearReferencesHttpClientKeepAliveThread()); } for (int i = 0; i &lt; repositories.length; i++) { classLoader.addRepository(repositories[i]); } // Configure our repositories setRepositories(); setClassPath(); setPermissions(); ((Lifecycle) classLoader).start(); // Binding the Webapp class loader to the directory context DirContextURLStreamHandler.bind(classLoader, this.container.getResources()); StandardContext ctx=(StandardContext)container; String contextName = ctx.getName(); if (!contextName.startsWith(&quot;/&quot;)) { contextName = &quot;/&quot; + contextName; } ObjectName cloname = new ObjectName (MBeanUtils.getDomain(ctx) + &quot;:type=WebappClassLoader,context=&quot; + contextName + &quot;,host=&quot; + ctx.getParent().getName()); Registry.getRegistry(null, null) .registerComponent(classLoader, cloname, null); } catch (Throwable t) { t = ExceptionUtils.unwrapInvocationTargetException(t); ExceptionUtils.handleThrowable(t); log.error( &quot;LifecycleException &quot;, t ); throw new LifecycleException(&quot;start: &quot;, t); } setState(LifecycleState.STARTING); } 最后我们看看createClassLoader的实现： private WebappClassLoaderBase createClassLoader() throws Exception { Class&lt;?&gt; clazz = Class.forName(loaderClass); WebappClassLoaderBase classLoader = null; if (parentClassLoader == null) { parentClassLoader = container.getParentClassLoader(); } Class&lt;?&gt;[] argTypes = { ClassLoader.class }; Object[] args = { parentClassLoader }; Constructor&lt;?&gt; constr = clazz.getConstructor(argTypes); classLoader = (WebappClassLoaderBase) constr.newInstance(args); return classLoader; } 至此Tomcat类加载完毕。","categories":[{"name":"Tomcat源码","slug":"Tomcat源码","permalink":"http://zhengweishan.oschina.io/categories/Tomcat源码/"}],"tags":[{"name":"tomcat","slug":"tomcat","permalink":"http://zhengweishan.oschina.io/tags/tomcat/"}]},{"title":"Tommcat源码学习（四）--Tomcat_7.0.70 server.xml文件的加载与解析","slug":"（四）Tomcat_7.0.70 server.xml文件的加载与解析","date":"2017-02-07T16:00:00.000Z","updated":"2017-03-01T08:54:07.663Z","comments":true,"path":"2017/02/08/（四）Tomcat_7.0.70 server.xml文件的加载与解析/","link":"","permalink":"http://zhengweishan.oschina.io/2017/02/08/（四）Tomcat_7.0.70 server.xml文件的加载与解析/","excerpt":"1、文件的加载Bootstrap的load方法是加载Tomcat的server.xml的入口，load方法实际通过反射调用catalinaDaemon（类型为Catalina）的load方法： /** * Load daemon. */ private void load(String[] arguments) throws Exception { // Call the load() method String methodName = &quot;load&quot;; Object param[]; Class&lt;?&gt; paramTypes[]; if (arguments==null || arguments.length==0) { paramTypes = null; param = null; } else { paramTypes = new Class[1]; paramTypes[0] = arguments.getClass(); param = new Object[1]; param[0] = arguments; } Method method = catalinaDaemon.getClass().getMethod(methodName, paramTypes);//通过反射机制调用Catalina类的load方法。 if (log.isDebugEnabled()) log.debug(&quot;Calling startup class &quot; + method); method.invoke(catalinaDaemon, param); }","text":"1、文件的加载Bootstrap的load方法是加载Tomcat的server.xml的入口，load方法实际通过反射调用catalinaDaemon（类型为Catalina）的load方法： /** * Load daemon. */ private void load(String[] arguments) throws Exception { // Call the load() method String methodName = &quot;load&quot;; Object param[]; Class&lt;?&gt; paramTypes[]; if (arguments==null || arguments.length==0) { paramTypes = null; param = null; } else { paramTypes = new Class[1]; paramTypes[0] = arguments.getClass(); param = new Object[1]; param[0] = arguments; } Method method = catalinaDaemon.getClass().getMethod(methodName, paramTypes);//通过反射机制调用Catalina类的load方法。 if (log.isDebugEnabled()) log.debug(&quot;Calling startup class &quot; + method); method.invoke(catalinaDaemon, param); } Catalina类的load方法： /* * Load using arguments */ public void load(String args[]) { try { if (arguments(args)) { load();//调用自身的load方法 } } catch (Exception e) { e.printStackTrace(System.out); } } /** * Start a new server instance. */ public void load() { long t1 = System.nanoTime(); initDirs(); //用于对catalina.home和catalina.base的一些检查工作 // Before digester - it may be needed initNaming();//给系统设置java.naming.factory.url.pkgs和java.naming.factory.initial // Create and execute our Digester Digester digester = createStartDigester();//实例化Digester InputSource inputSource = null; InputStream inputStream = null; File file = null; try { try { file = configFile();//获取conf/server.xml配置文件 inputStream = new FileInputStream(file);获取conf/server.xml配置文件输入流 inputSource = new InputSource(file.toURI().toURL().toString()); } catch (Exception e) { if (log.isDebugEnabled()) { log.debug(sm.getString(&quot;catalina.configFail&quot;, file), e); } } if (inputStream == null) { try { inputStream = getClass().getClassLoader() .getResourceAsStream(getConfigFile()); inputSource = new InputSource (getClass().getClassLoader() .getResource(getConfigFile()).toString()); } catch (Exception e) { if (log.isDebugEnabled()) { log.debug(sm.getString(&quot;catalina.configFail&quot;, getConfigFile()), e); } } } // This should be included in catalina.jar // Alternative: don&apos;t bother with xml, just create it manually. if( inputStream==null ) { try { inputStream = getClass().getClassLoader() .getResourceAsStream(&quot;server-embed.xml&quot;); inputSource = new InputSource (getClass().getClassLoader() .getResource(&quot;server-embed.xml&quot;).toString()); } catch (Exception e) { if (log.isDebugEnabled()) { log.debug(sm.getString(&quot;catalina.configFail&quot;, &quot;server-embed.xml&quot;), e); } } } if (inputStream == null || inputSource == null) { if (file == null) { log.warn(sm.getString(&quot;catalina.configFail&quot;, getConfigFile() + &quot;] or [server-embed.xml]&quot;)); } else { log.warn(sm.getString(&quot;catalina.configFail&quot;, file.getAbsolutePath())); if (file.exists() &amp;&amp; !file.canRead()) { log.warn(&quot;Permissions incorrect, read permission is not allowed on the file.&quot;); } } return; } try { inputSource.setByteStream(inputStream);//将FileInputStream封装为InputSource digester.push(this); digester.parse(inputSource);//调用Digester的parse方法进行解析 } catch (SAXParseException spe) { log.warn(&quot;Catalina.start using &quot; + getConfigFile() + &quot;: &quot; + spe.getMessage()); return; } catch (Exception e) { log.warn(&quot;Catalina.start using &quot; + getConfigFile() + &quot;: &quot; , e); return; } } finally { if (inputStream != null) { try { inputStream.close(); } catch (IOException e) { // Ignore } } } getServer().setCatalina(this); // Stream redirection initStreams();//initStreams对输出流、错误流重定向 // Start the new server try { getServer().init();//初始化server } catch (LifecycleException e) { if (Boolean.getBoolean(&quot;org.apache.catalina.startup.EXIT_ON_INIT_FAILURE&quot;)) { throw new java.lang.Error(e); } else { log.error(&quot;Catalina.start&quot;, e); } } long t2 = System.nanoTime(); if(log.isInfoEnabled()) { log.info(&quot;Initialization processed in &quot; + ((t2 - t1) / 1000000) + &quot; ms&quot;); } } 下面开始分析整个过程： 1.1、initDirs（）方法用于对catalina.home和catalina.base的一些检查工作protected void initDirs() { String catalinaHome = System.getProperty(Globals.CATALINA_HOME_PROP); if (catalinaHome == null) { // Backwards compatibility patch for J2EE RI 1.3 String j2eeHome = System.getProperty(&quot;com.sun.enterprise.home&quot;); if (j2eeHome != null) { catalinaHome=System.getProperty(&quot;com.sun.enterprise.home&quot;); } else if (System.getProperty(Globals.CATALINA_BASE_PROP) != null) { catalinaHome = System.getProperty(Globals.CATALINA_BASE_PROP); } } // last resort - for minimal/embedded cases. if(catalinaHome==null) { catalinaHome=System.getProperty(&quot;user.dir&quot;); } if (catalinaHome != null) { File home = new File(catalinaHome); if (!home.isAbsolute()) { try { catalinaHome = home.getCanonicalPath(); } catch (IOException e) { catalinaHome = home.getAbsolutePath(); } } System.setProperty(Globals.CATALINA_HOME_PROP, catalinaHome); } if (System.getProperty(Globals.CATALINA_BASE_PROP) == null) { System.setProperty(Globals.CATALINA_BASE_PROP, catalinaHome); } else { String catalinaBase = System.getProperty(Globals.CATALINA_BASE_PROP); File base = new File(catalinaBase); if (!base.isAbsolute()) { try { catalinaBase = base.getCanonicalPath(); } catch (IOException e) { catalinaBase = base.getAbsolutePath(); } } System.setProperty(Globals.CATALINA_BASE_PROP, catalinaBase); } String temp = System.getProperty(&quot;java.io.tmpdir&quot;); if (temp == null || (!(new File(temp)).exists()) || (!(new File(temp)).isDirectory())) { log.error(sm.getString(&quot;embedded.notmp&quot;, temp)); } } 1.2、initNaming()方法给系统设置java.naming.factory.url.pkgs和java.naming.factory.initial protected void initNaming() { // Setting additional variables if (!useNaming) { log.info( &quot;Catalina naming disabled&quot;); System.setProperty(&quot;catalina.useNaming&quot;, &quot;false&quot;); } else { System.setProperty(&quot;catalina.useNaming&quot;, &quot;true&quot;); String value = &quot;org.apache.naming&quot;; String oldValue = System.getProperty(javax.naming.Context.URL_PKG_PREFIXES); if (oldValue != null) { value = value + &quot;:&quot; + oldValue; } System.setProperty(javax.naming.Context.URL_PKG_PREFIXES, value); if( log.isDebugEnabled() ) { log.debug(&quot;Setting naming prefix=&quot; + value); } value = System.getProperty (javax.naming.Context.INITIAL_CONTEXT_FACTORY); if (value == null) { System.setProperty (javax.naming.Context.INITIAL_CONTEXT_FACTORY, &quot;org.apache.naming.java.javaURLContextFactory&quot;); } else { log.debug( &quot;INITIAL_CONTEXT_FACTORY already set &quot; + value ); } } } 在创建JNDI上下文时，使用Context.INITIAL CONTEXT FACTORY（”java.naming.factory.initial”）属性，来指定创建JNDI上下文的工厂类；Context.URL PKG PREFIXES(“java.naming.factory.url.pkgs”)用在查询url中包括scheme方法id时创建对应的JNDI上下文. 1.3、createStartDigester()创建并配置将要用来启动的Digester实例，并且设置一些列Rule，具体映射到server.xml/** * Create and configure the Digester we will be using for startup. */ protected Digester createStartDigester() { long t1=System.currentTimeMillis(); // Initialize the digester Digester digester = new Digester(); digester.setValidating(false); digester.setRulesValidation(true); HashMap&lt;Class&lt;?&gt;, List&lt;String&gt;&gt; fakeAttributes = new HashMap&lt;Class&lt;?&gt;, List&lt;String&gt;&gt;(); ArrayList&lt;String&gt; attrs = new ArrayList&lt;String&gt;(); attrs.add(&quot;className&quot;); fakeAttributes.put(Object.class, attrs); digester.setFakeAttributes(fakeAttributes); digester.setUseContextClassLoader(true); // Configure the actions we will be using digester.addObjectCreate(&quot;Server&quot;, &quot;org.apache.catalina.core.StandardServer&quot;, &quot;className&quot;); digester.addSetProperties(&quot;Server&quot;); digester.addSetNext(&quot;Server&quot;, &quot;setServer&quot;, &quot;org.apache.catalina.Server&quot;); digester.addObjectCreate(&quot;Server/GlobalNamingResources&quot;, &quot;org.apache.catalina.deploy.NamingResources&quot;); digester.addSetProperties(&quot;Server/GlobalNamingResources&quot;); digester.addSetNext(&quot;Server/GlobalNamingResources&quot;, &quot;setGlobalNamingResources&quot;, &quot;org.apache.catalina.deploy.NamingResources&quot;); digester.addObjectCreate(&quot;Server/Listener&quot;, null, // MUST be specified in the element &quot;className&quot;); digester.addSetProperties(&quot;Server/Listener&quot;); digester.addSetNext(&quot;Server/Listener&quot;, &quot;addLifecycleListener&quot;, &quot;org.apache.catalina.LifecycleListener&quot;); digester.addObjectCreate(&quot;Server/Service&quot;, &quot;org.apache.catalina.core.StandardService&quot;, &quot;className&quot;); digester.addSetProperties(&quot;Server/Service&quot;); digester.addSetNext(&quot;Server/Service&quot;, &quot;addService&quot;, &quot;org.apache.catalina.Service&quot;); digester.addObjectCreate(&quot;Server/Service/Listener&quot;, null, // MUST be specified in the element &quot;className&quot;); digester.addSetProperties(&quot;Server/Service/Listener&quot;); digester.addSetNext(&quot;Server/Service/Listener&quot;, &quot;addLifecycleListener&quot;, &quot;org.apache.catalina.LifecycleListener&quot;); //Executor digester.addObjectCreate(&quot;Server/Service/Executor&quot;, &quot;org.apache.catalina.core.StandardThreadExecutor&quot;, &quot;className&quot;); digester.addSetProperties(&quot;Server/Service/Executor&quot;); digester.addSetNext(&quot;Server/Service/Executor&quot;, &quot;addExecutor&quot;, &quot;org.apache.catalina.Executor&quot;); digester.addRule(&quot;Server/Service/Connector&quot;, new ConnectorCreateRule()); digester.addRule(&quot;Server/Service/Connector&quot;, new SetAllPropertiesRule(new String[]{&quot;executor&quot;})); digester.addSetNext(&quot;Server/Service/Connector&quot;, &quot;addConnector&quot;, &quot;org.apache.catalina.connector.Connector&quot;); digester.addObjectCreate(&quot;Server/Service/Connector/Listener&quot;, null, // MUST be specified in the element &quot;className&quot;); digester.addSetProperties(&quot;Server/Service/Connector/Listener&quot;); digester.addSetNext(&quot;Server/Service/Connector/Listener&quot;, &quot;addLifecycleListener&quot;, &quot;org.apache.catalina.LifecycleListener&quot;); // Add RuleSets for nested elements digester.addRuleSet(new NamingRuleSet(&quot;Server/GlobalNamingResources/&quot;)); digester.addRuleSet(new EngineRuleSet(&quot;Server/Service/&quot;)); digester.addRuleSet(new HostRuleSet(&quot;Server/Service/Engine/&quot;)); digester.addRuleSet(new ContextRuleSet(&quot;Server/Service/Engine/Host/&quot;)); addClusterRuleSet(digester, &quot;Server/Service/Engine/Host/Cluster/&quot;); digester.addRuleSet(new NamingRuleSet(&quot;Server/Service/Engine/Host/Context/&quot;)); // When the &apos;engine&apos; is found, set the parentClassLoader. digester.addRule(&quot;Server/Service/Engine&quot;, new SetParentClassLoaderRule(parentClassLoader)); addClusterRuleSet(digester, &quot;Server/Service/Engine/Cluster/&quot;); long t2=System.currentTimeMillis(); if (log.isDebugEnabled()) { log.debug(&quot;Digester for server.xml created &quot; + ( t2-t1 )); } return (digester); } 从上面的代码可以看出：首先创建Digester，Digester继承了DefaultHandler，而DefaultHandler默认实现了ContentHander、DTDHander、ErrorHandler及EntityResolver 这4个接口，代码如下： public class DefaultHandler implements EntityResolver, DTDHandler, ContentHandler, ErrorHandler 通过源码可以发现DefaultHandler的所有实现都是空实现，所以解析还需要Digester。（具体分析后面在说）。 1.4、configFile()获取配置文件conf/server.xml，并使用FileInputStream获取conf/server.xml配置文件输入流/** * Return a File object representing our configuration file. */ protected File configFile() { File file = new File(configFile); if (!file.isAbsolute()) { file = new File(System.getProperty(Globals.CATALINA_BASE_PROP), configFile); } return (file); } 1.5、将FileInputStream封装为InputSource，并且调用Digester的parse方法进行解析inputSource.setByteStream(inputStream); digester.push(this); digester.parse(inputSource); 1.6、initStreams()对输出流、错误流重定向 protected void initStreams() { // Replace System.out and System.err with a custom PrintStream System.setOut(new SystemLogHandler(System.out)); System.setErr(new SystemLogHandler(System.err)); } 1.7、初始化server// Start the new server try { getServer().init(); } catch (LifecycleException e) { if (Boolean.getBoolean(&quot;org.apache.catalina.startup.EXIT_ON_INIT_FAILURE&quot;)) { throw new java.lang.Error(e); } else { log.error(&quot;Catalina.start&quot;, e); } } 2、文件的解析当加载server.xml配置文件到内存后，开始对XML文件中的内容进行解析，主要包含两个步骤： 构造server.xml的规则，这些规则即可以用于构造Tomcat内部的容器（如StandardServer，StandardService等），也可以对server.xml进行合法性检查。如果server.xml不符合Tomcat内置的规则，在解析时将抛出异常，进而导致Tomcat无法启动。 使用SAX解析server.xml，边解析边应用规则，最终使用server.xml中的配置构建好Tomcat所需的各种容器。 Tomcat将server.xml文件中的所有元素上的属性都抽象为Rule，以Server元素为例，在内存中对应Server实例，Server实例的属性值就来自于Server元素的属性值。通过对规则（Rule）的应用，最终改变Server实例的属性值。Rule是一个抽象类，其中定义了以下方法： getDigester：获取Digester实例； setDigester：设置Digester实例； getNamespaceURI：获取Rule所在的相对命名空间URI； setNamespaceURI：设置Rule所在的相对命名空间URI； begin(String namespace, String name, Attributes attributes)：此方法在遇到一个匹配的XML元素的开头时被调用，如； body(String namespace, String name, String text)：在遇到匹配XML元素的body时，此方法被调用，如进入标签内部时； end(String namespace, String name)：此方法在遇到一个匹配的XML元素的末尾时被调用。如：&lt; /Server&gt;； Rule目前有很多实现类，如：NodeCreateRule、AbsoluteOrderingRule、CallParamRule、ConnectorCreateRule等。下图展示了Rule的部分实现类： Tomcat使用SAX（Simple API for XML)解析XML: SAX解析XML采用的是从上而下的基于事件驱动的解析方式，在解析过程中会视情况自动调用ContentHandler接口中的startDocument()、startElement()、characters()、endElement()、endDocument()等相关的方法。 由编译执行的结果分析： startDocument()方法只会在文档开始解析的时候被调用，每次解析只会调用一次。 startElement()方法每次在开始解析一个元素，即遇到元素标签开始的时候都会调用。 characters()方法也是在每次解析到元素标签携带的内容时都会调用，即使该元素标签的内容为空或换行。而且如果元素内嵌套元素，在父元素结束标签前， characters()方法会再次被调用，此处需要注意。 endElement()方法每次在结束解析一个元素，即遇到元素标签结束的时候都会调用。 endDocument()方法只会在文档解析结束的时候被调用，每次解析只会调用一次。 使用SAX解析XML的好处： SAX 不用解析完整个文档 相比于 DOM 而言 SAX 是一种速度更快，更有效，占用内存更少的解析 XML 文件的方法 逐行扫描，可以做到边扫描边解析，因此 SAX 可以在解析文档的任意时刻停止解析 由于SAX是基于事件驱动的，不用解析完整个文档，在按内容顺序解析文档过程中， SAX 会判断当前读到的字符是否符合 XML 文件语法中的某部分。如果符合某部分，则会触发事件。所谓触发事件，就是调用一些回调方法。在用 SAX 解析 xml 文档时候，在读取到文档开始和结束标签时候就会回调一个事件，在读取到其他节点与内容时候也会回调一个事件。在 SAX 接口中，事件源是 org.xml.sax 包中的 XMLReader ，它通过 parser() 方法来解析 XML 文档，并产生事件。事件处理器是 org.xml.sax 包中 ContentHander 、 DTDHander 、 ErrorHandler ，以及 EntityResolver 这4个接口： ContentHander （ XML 文档的开始与结束）setContentHandler(ContentHandler h) DTDHander （ 处理 DTD 解析） setDTDHandler(DTDHandler h) ErrorHandler （ 处理 XML 时产生的错误）setErrorHandler(ErrorHandler h) EntityResolver （处理外部实体） setEntityResolver(EntityResolver e) 回调方法一般都定义在ContentHandler接口中，上面已经对这些回调方法的加载顺序已经说了就不在介绍了。 使用 SAX 解析 XML 文件一般有以下五个步骤： 创建一个 SAXParserFactory 对象； 调用 SAXParserFactory 中的 newSAXParser 方法创建一个 SAXParser 对象； 然后在调用 SAXParser 中的 getXMLReader 方法获取一个 XMLReader 对象； 实例化一个 DefaultHandler 对象； 连接事件源对象 XMLReader 到事件处理类 DefaultHandler 中； 调用 XMLReader 的 parse 方法从输入源中获取到的 xml 数据； 通过 DefaultHandler 返回我们需要的数据集合。 我们通过源码可以发现DefaultHandler的所有实现都是空实现，所以解析还需要Digester自身，代码如下： @Override public void startDocument() throws SAXException { if (saxLog.isDebugEnabled()) { saxLog.debug(&quot;startDocument()&quot;); } // ensure that the digester is properly configured, as // the digester could be used as a SAX ContentHandler // rather than via the parse() methods. configure(); } @Override public void startElement(String namespaceURI, String localName, String qName, Attributes list) throws SAXException { boolean debug = log.isDebugEnabled(); if (saxLog.isDebugEnabled()) { saxLog.debug(&quot;startElement(&quot; + namespaceURI + &quot;,&quot; + localName + &quot;,&quot; + qName + &quot;)&quot;); } // Parse system properties list = updateAttributes(list); // Save the body text accumulated for our surrounding element bodyTexts.push(bodyText); bodyText = new StringBuilder(); // the actual element name is either in localName or qName, depending // on whether the parser is namespace aware String name = localName; if ((name == null) || (name.length() &lt; 1)) { name = qName; } // Compute the current matching rule StringBuilder sb = new StringBuilder(match); if (match.length() &gt; 0) { sb.append(&apos;/&apos;); } sb.append(name); match = sb.toString(); if (debug) { log.debug(&quot; New match=&apos;&quot; + match + &quot;&apos;&quot;); } // Fire &quot;begin&quot; events for all relevant rules List&lt;Rule&gt; rules = getRules().match(namespaceURI, match); matches.push(rules); if ((rules != null) &amp;&amp; (rules.size() &gt; 0)) { for (int i = 0; i &lt; rules.size(); i++) { try { Rule rule = rules.get(i); if (debug) { log.debug(&quot; Fire begin() for &quot; + rule); } rule.begin(namespaceURI, name, list); } catch (Exception e) { log.error(&quot;Begin event threw exception&quot;, e); throw createSAXException(e); } catch (Error e) { log.error(&quot;Begin event threw error&quot;, e); throw e; } } } else { if (debug) { log.debug(&quot; No rules found matching &apos;&quot; + match + &quot;&apos;.&quot;); } } } @Override public void endDocument() throws SAXException { if (saxLog.isDebugEnabled()) { if (getCount() &gt; 1) { saxLog.debug(&quot;endDocument(): &quot; + getCount() + &quot; elements left&quot;); } else { saxLog.debug(&quot;endDocument()&quot;); } } while (getCount() &gt; 1) { pop(); } // Fire &quot;finish&quot; events for all defined rules Iterator&lt;Rule&gt; rules = getRules().rules().iterator(); while (rules.hasNext()) { Rule rule = rules.next(); try { rule.finish(); } catch (Exception e) { log.error(&quot;Finish event threw exception&quot;, e); throw createSAXException(e); } catch (Error e) { log.error(&quot;Finish event threw error&quot;, e); throw e; } } // Perform final cleanup clear(); } @Override public void endElement(String namespaceURI, String localName, String qName) throws SAXException { boolean debug = log.isDebugEnabled(); if (debug) { if (saxLog.isDebugEnabled()) { saxLog.debug(&quot;endElement(&quot; + namespaceURI + &quot;,&quot; + localName + &quot;,&quot; + qName + &quot;)&quot;); } log.debug(&quot; match=&apos;&quot; + match + &quot;&apos;&quot;); log.debug(&quot; bodyText=&apos;&quot; + bodyText + &quot;&apos;&quot;); } // Parse system properties bodyText = updateBodyText(bodyText); // the actual element name is either in localName or qName, depending // on whether the parser is namespace aware String name = localName; if ((name == null) || (name.length() &lt; 1)) { name = qName; } // Fire &quot;body&quot; events for all relevant rules List&lt;Rule&gt; rules = matches.pop(); if ((rules != null) &amp;&amp; (rules.size() &gt; 0)) { String bodyText = this.bodyText.toString(); for (int i = 0; i &lt; rules.size(); i++) { try { Rule rule = rules.get(i); if (debug) { log.debug(&quot; Fire body() for &quot; + rule); } rule.body(namespaceURI, name, bodyText); } catch (Exception e) { log.error(&quot;Body event threw exception&quot;, e); throw createSAXException(e); } catch (Error e) { log.error(&quot;Body event threw error&quot;, e); throw e; } } } else { if (debug) { log.debug(&quot; No rules found matching &apos;&quot; + match + &quot;&apos;.&quot;); } if (rulesValidation) { log.warn(&quot; No rules found matching &apos;&quot; + match + &quot;&apos;.&quot;); } } // Recover the body text from the surrounding element bodyText = bodyTexts.pop(); // Fire &quot;end&quot; events for all relevant rules in reverse order if (rules != null) { for (int i = 0; i &lt; rules.size(); i++) { int j = (rules.size() - i) - 1; try { Rule rule = rules.get(j); if (debug) { log.debug(&quot; Fire end() for &quot; + rule); } rule.end(namespaceURI, name); } catch (Exception e) { log.error(&quot;End event threw exception&quot;, e); throw createSAXException(e); } catch (Error e) { log.error(&quot;End event threw error&quot;, e); throw e; } } } // Recover the previous match expression int slash = match.lastIndexOf(&apos;/&apos;); if (slash &gt;= 0) { match = match.substring(0, slash); } else { match = &quot;&quot;; } } 当我们创建好Digester后，会调用addObjectCreate、addSetProperties、addSetNext方法陆续添加很多Rule，这些方法的实现如代码： public void addObjectCreate(String pattern, String className, String attributeName) { addRule(pattern, new ObjectCreateRule(className, attributeName)); } public void addSetProperties(String pattern) { addRule(pattern, new SetPropertiesRule()); } public void addSetNext(String pattern, String methodName, String paramType) { addRule(pattern, new SetNextRule(methodName, paramType)); } 这三个方法分别创建ObjectCreateRule、SetPropertiesRule及SetNextRule，为了便于理解，我们举例说明(Server标签)： digester.addObjectCreate(&quot;Server&quot;,&quot;org.apache.catalina.core.StandardServer&quot;,&quot;className&quot;); digester.addSetProperties(&quot;Server&quot;); digester.addSetNext(&quot;Server&quot;,&quot;setServer&quot;, &quot;org.apache.catalina.Server&quot;); 我们知道最终会创建ObjectCreateRule、SetPropertiesRule及SetNextRule，并且调用addRule方法。 public void addRule(String pattern, Rule rule) { rule.setDigester(this); getRules().add(pattern, rule); } 从代码可以看出，addRule方法首先调用getRules方法获取RulesBase，然后调用RulesBase的add方法。代码如下： //getRules()获取RulesBase public Rules getRules() { if (this.rules == null) { this.rules = new RulesBase(); this.rules.setDigester(this); } return (this.rules); } //RulesBase的add方法 @Override public void add(String pattern, Rule rule) { // to help users who accidently add &apos;/&apos; to the end of their patterns int patternLength = pattern.length(); if (patternLength&gt;1 &amp;&amp; pattern.endsWith(&quot;/&quot;)) { pattern = pattern.substring(0, patternLength-1); } List&lt;Rule&gt; list = cache.get(pattern); if (list == null) { list = new ArrayList&lt;Rule&gt;(); cache.put(pattern, list); } list.add(rule); rules.add(rule); if (this.digester != null) { rule.setDigester(this.digester); } if (this.namespaceURI != null) { rule.setNamespaceURI(this.namespaceURI); } } 其中，cache的数据结构为HashMap","categories":[{"name":"Tomcat源码","slug":"Tomcat源码","permalink":"http://zhengweishan.oschina.io/categories/Tomcat源码/"}],"tags":[{"name":"tomcat","slug":"tomcat","permalink":"http://zhengweishan.oschina.io/tags/tomcat/"}]},{"title":"Tommcat源码学习（三）--Tomcat_7.0.70停止过程分析","slug":"（三）Tomcat_7.0.70停止分析","date":"2017-02-06T16:00:00.000Z","updated":"2017-03-01T08:50:57.655Z","comments":true,"path":"2017/02/07/（三）Tomcat_7.0.70停止分析/","link":"","permalink":"http://zhengweishan.oschina.io/2017/02/07/（三）Tomcat_7.0.70停止分析/","excerpt":"Tomcat关闭命令（Linux下，大部分生产环境都是部署在Linux系统下)： sh shutdown.sh 执行这个命令之后，tomcat会为我们做了哪些操作呢？下面就来简单分析下。 shutdown.sh代码清单如下： # Better OS/400 detection: see Bugzilla 31132 os400=false case &quot;`uname`&quot; in OS400*) os400=true;; esac # resolve links - $0 may be a softlink PRG=&quot;$0&quot; while [ -h &quot;$PRG&quot; ] ; do ls=`ls -ld &quot;$PRG&quot;` link=`expr &quot;$ls&quot; : &apos;.*-&gt; \\(.*\\)$&apos;` if expr &quot;$link&quot; : &apos;/.*&apos; &gt; /dev/null; then PRG=&quot;$link&quot; else PRG=`dirname &quot;$PRG&quot;`/&quot;$link&quot; fi done PRGDIR=`dirname &quot;$PRG&quot;` EXECUTABLE=catalina.sh # Check that target executable exists if $os400; then # -x will Only work on the os400 if the files are: # 1. owned by the user # 2. owned by the PRIMARY group of the user # this will not work if the user belongs in secondary groups eval else if [ ! -x &quot;$PRGDIR&quot;/&quot;$EXECUTABLE&quot; ]; then echo &quot;Cannot find $PRGDIR/$EXECUTABLE&quot; echo &quot;The file is absent or does not have execute permission&quot; echo &quot;This file is needed to run this program&quot; exit 1 fi fi exec &quot;$PRGDIR&quot;/&quot;$EXECUTABLE&quot; stop &quot;$@&quot;","text":"Tomcat关闭命令（Linux下，大部分生产环境都是部署在Linux系统下)： sh shutdown.sh 执行这个命令之后，tomcat会为我们做了哪些操作呢？下面就来简单分析下。 shutdown.sh代码清单如下： # Better OS/400 detection: see Bugzilla 31132 os400=false case &quot;`uname`&quot; in OS400*) os400=true;; esac # resolve links - $0 may be a softlink PRG=&quot;$0&quot; while [ -h &quot;$PRG&quot; ] ; do ls=`ls -ld &quot;$PRG&quot;` link=`expr &quot;$ls&quot; : &apos;.*-&gt; \\(.*\\)$&apos;` if expr &quot;$link&quot; : &apos;/.*&apos; &gt; /dev/null; then PRG=&quot;$link&quot; else PRG=`dirname &quot;$PRG&quot;`/&quot;$link&quot; fi done PRGDIR=`dirname &quot;$PRG&quot;` EXECUTABLE=catalina.sh # Check that target executable exists if $os400; then # -x will Only work on the os400 if the files are: # 1. owned by the user # 2. owned by the PRIMARY group of the user # this will not work if the user belongs in secondary groups eval else if [ ! -x &quot;$PRGDIR&quot;/&quot;$EXECUTABLE&quot; ]; then echo &quot;Cannot find $PRGDIR/$EXECUTABLE&quot; echo &quot;The file is absent or does not have execute permission&quot; echo &quot;This file is needed to run this program&quot; exit 1 fi fi exec &quot;$PRGDIR&quot;/&quot;$EXECUTABLE&quot; stop &quot;$@&quot; 从上面的代码可以看出来，这里和启动文件是一样的，也有主要的两个变量： PRGDIR：当前shell脚本所在的路径； EXECUTABLE：脚本catalina.sh 从最后一行代码可以知道，执行catalina.sh，并传递参数：stop catalina.sh 与之相关的代码清单如下： elif [ &quot;$1&quot; = &quot;stop&quot; ] ; then shift SLEEP=5 if [ ! -z &quot;$1&quot; ]; then echo $1 | grep &quot;[^0-9]&quot; &gt;/dev/null 2&gt;&amp;1 if [ $? -gt 0 ]; then SLEEP=$1 shift fi fi FORCE=0 if [ &quot;$1&quot; = &quot;-force&quot; ]; then shift FORCE=1 fi if [ ! -z &quot;$CATALINA_PID&quot; ]; then if [ -f &quot;$CATALINA_PID&quot; ]; then if [ -s &quot;$CATALINA_PID&quot; ]; then kill -0 `cat &quot;$CATALINA_PID&quot;` &gt;/dev/null 2&gt;&amp;1 if [ $? -gt 0 ]; then echo &quot;PID file found but no matching process was found. Stop aborted.&quot; exit 1 fi else echo &quot;PID file is empty and has been ignored.&quot; fi else echo &quot;\\$CATALINA_PID was set but the specified file does not exist. Is Tomcat running? Stop aborted.&quot; exit 1 fi fi eval &quot;\\&quot;$_RUNJAVA\\&quot;&quot; $LOGGING_MANAGER $JAVA_OPTS \\ -Djava.endorsed.dirs=&quot;\\&quot;$JAVA_ENDORSED_DIRS\\&quot;&quot; -classpath &quot;\\&quot;$CLASSPATH\\&quot;&quot; \\ -Dcatalina.base=&quot;\\&quot;$CATALINA_BASE\\&quot;&quot; \\ -Dcatalina.home=&quot;\\&quot;$CATALINA_HOME\\&quot;&quot; \\ -Djava.io.tmpdir=&quot;\\&quot;$CATALINA_TMPDIR\\&quot;&quot; \\ org.apache.catalina.startup.Bootstrap &quot;$@&quot; stop 最终使用java命令执行了org.apache.catalina.startup.Bootstrap类中的main方法，参数是stop。 public static void main(String args[]) { if (daemon == null) { // Don&apos;t set daemon until init() has completed Bootstrap bootstrap = new Bootstrap(); try { bootstrap.init(); } catch (Throwable t) { handleThrowable(t); t.printStackTrace(); return; } daemon = bootstrap; } else { // When running as a service the call to stop will be on a new // thread so make sure the correct class loader is used to prevent // a range of class not found exceptions. Thread.currentThread().setContextClassLoader(daemon.catalinaLoader); } try { String command = &quot;start&quot;; if (args.length &gt; 0) { command = args[args.length - 1]; } if (command.equals(&quot;startd&quot;)) { args[args.length - 1] = &quot;start&quot;; daemon.load(args); daemon.start(); } else if (command.equals(&quot;stopd&quot;)) { args[args.length - 1] = &quot;stop&quot;; daemon.stop(); } else if (command.equals(&quot;start&quot;)) { daemon.setAwait(true); daemon.load(args); daemon.start(); } else if (command.equals(&quot;stop&quot;)) { daemon.stopServer(args); } else if (command.equals(&quot;configtest&quot;)) { daemon.load(args); if (null==daemon.getServer()) { System.exit(1); } System.exit(0); } else { log.warn(&quot;Bootstrap: command \\&quot;&quot; + command + &quot;\\&quot; does not exist.&quot;); } } catch (Throwable t) { // Unwrap the Exception for clearer error reporting if (t instanceof InvocationTargetException &amp;&amp; t.getCause() != null) { t = t.getCause(); } handleThrowable(t); t.printStackTrace(); System.exit(1); } } 当传递参数stop的时候，command等于stop，此时main方法的执行步骤如下： 初始化Bootstrap（启动的时候已经介绍过就不在介绍） 停止服务 通过调用Bootstrap的stopServer方法停止Tomcat，其实质是用反射调用catalinaDaemon（类型是Catalina）的stopServer方法。 /** * Stop the standalone server. */ public void stopServer(String[] arguments) throws Exception { Object param[]; Class&lt;?&gt; paramTypes[]; if (arguments==null || arguments.length==0) { paramTypes = null; param = null; } else { paramTypes = new Class[1]; paramTypes[0] = arguments.getClass(); param = new Object[1]; param[0] = arguments; } Method method = catalinaDaemon.getClass().getMethod(&quot;stopServer&quot;, paramTypes);//反射调用catalinaDaemon（类型是Catalina）的stopServer方法 method.invoke(catalinaDaemon, param); } Catalina的stopServer方法的执行步骤如下： 代码清单： public void stopServer() { stopServer(null); } public void stopServer(String[] arguments) { if (arguments != null) { arguments(arguments); } Server s = getServer(); if( s == null ) {//服务不存在 // Create and execute our Digester Digester digester = createStopDigester();//Digester解析server.xml文件，以构造出Server容器 File file = configFile(); FileInputStream fis = null; try { InputSource is = new InputSource(file.toURI().toURL().toString()); fis = new FileInputStream(file); is.setByteStream(fis); digester.push(this); digester.parse(is); } catch (Exception e) { log.error(&quot;Catalina.stop: &quot;, e); System.exit(1); } finally { if (fis != null) { try { fis.close(); } catch (IOException e) { // Ignore } } } } else { // Server object already present. Must be running as a service try { s.stop(); } catch (LifecycleException e) { log.error(&quot;Catalina.stop: &quot;, e); } return; } // Stop the existing server s = getServer(); if (s.getPort()&gt;0) { Socket socket = null; OutputStream stream = null; try { socket = new Socket(s.getAddress(), s.getPort());//创建Socket对象连接启动Tomcat时创建的ServerSocket stream = socket.getOutputStream(); String shutdown = s.getShutdown(); for (int i = 0; i &lt; shutdown.length(); i++) { stream.write(shutdown.charAt(i));//发送shutdown命令 } stream.flush(); } catch (ConnectException ce) { log.error(sm.getString(&quot;catalina.stopServer.connectException&quot;, s.getAddress(), String.valueOf(s.getPort()))); log.error(&quot;Catalina.stop: &quot;, ce); System.exit(1); } catch (IOException e) { log.error(&quot;Catalina.stop: &quot;, e); System.exit(1); } finally { if (stream != null) { try { stream.close(); } catch (IOException e) { // Ignore } } if (socket != null) { try { socket.close(); } catch (IOException e) { // Ignore } } } } else { log.error(sm.getString(&quot;catalina.stopServer&quot;)); System.exit(1); } } - 创建Digester解析server.xml文件（此处只解析标签），以构造出Server容器（此时Server容器的子容器没有被实例化）； - 从实例化的Server容器获取Server的socket监听端口和地址，然后创建Socket对象连接启动Tomcat时创建的ServerSocket，最后向ServerSocket发送SHUTDOWN命令。根据 @Override public void await() { // Negative values - don&apos;t wait on port - tomcat is embedded or we just don&apos;t like ports if( port == -2 ) { // undocumented yet - for embedding apps that are around, alive. return; } if( port==-1 ) { try { awaitThread = Thread.currentThread(); while(!stopAwait) { try { Thread.sleep( 10000 ); } catch( InterruptedException ex ) { // continue and check the flag } } } finally { awaitThread = null; } return; } // Set up a server socket to wait on try { awaitSocket = new ServerSocket(port, 1, InetAddress.getByName(address));//创建socket连接的服务端对象ServerSocket } catch (IOException e) { log.error(&quot;StandardServer.await: create[&quot; + address + &quot;:&quot; + port + &quot;]: &quot;, e); return; } try { awaitThread = Thread.currentThread(); // Loop waiting for a connection and a valid command while (!stopAwait) { ServerSocket serverSocket = awaitSocket; if (serverSocket == null) { break; } // Wait for the next connection Socket socket = null; StringBuilder command = new StringBuilder();//创建一个对象循环接收socket中的字符 try { InputStream stream; long acceptStartTime = System.currentTimeMillis(); try { socket = serverSocket.accept(); socket.setSoTimeout(10 * 1000); // Ten seconds stream = socket.getInputStream(); } catch (SocketTimeoutException ste) { // This should never happen but bug 56684 suggests that // it does. log.warn(sm.getString(&quot;standardServer.accept.timeout&quot;, Long.valueOf(System.currentTimeMillis() - acceptStartTime)), ste); continue; } catch (AccessControlException ace) { log.warn(&quot;StandardServer.accept security exception: &quot; + ace.getMessage(), ace); continue; } catch (IOException e) { if (stopAwait) { // Wait was aborted with socket.close() break; } log.error(&quot;StandardServer.await: accept: &quot;, e); break; } // Read a set of characters from the socket int expected = 1024; // Cut off to avoid DoS attack while (expected &lt; shutdown.length()) { if (random == null) random = new Random(); expected += (random.nextInt() % 1024); } while (expected &gt; 0) { int ch = -1; try { ch = stream.read(); } catch (IOException e) { log.warn(&quot;StandardServer.await: read: &quot;, e); ch = -1; } if (ch &lt; 32) // Control character or EOF terminates loop break; command.append((char) ch); expected--; } } finally { // Close the socket now that we are done with it try { if (socket != null) { socket.close(); } } catch (IOException e) { // Ignore } } // Match against our command string boolean match = command.toString().equals(shutdown); if (match) { //如果接收到的命令与SHUTDOWN匹配（由于使用了equals，所以shutdown命令必须是大写的），那么退出循环等待 log.info(sm.getString(&quot;standardServer.shutdownViaPort&quot;)); break; } else log.warn(&quot;StandardServer.await: Invalid command &apos;&quot; + command.toString() + &quot;&apos; received&quot;); } } finally { ServerSocket serverSocket = awaitSocket; awaitThread = null; awaitSocket = null; // Close the server socket and return if (serverSocket != null) { try { serverSocket.close(); } catch (IOException e) { // Ignore } } } } 内容，ServerSocket循环等待接收到SHUTDOWN命令后，最终调用stop方法停止Tomcat。 最后，我们看看Catalina的stop方法的实现，其执行步骤如下： 1. 将启动过程中添加的关闭钩子移除。Tomcat启动过程辛辛苦苦添加的关闭钩子为什么又要去掉呢？因为关闭钩子是为了在JVM异常退出后，进行资源的回收工作。主动停止Tomcat时调用的stop方法里已经包含了资源回收的内容，所以不再需要这个钩子了。 2. 停止Server容器。有关容器的停止内容，请阅读后续文章。 3. 代码清单： /** * Stop an existing server instance.**** */ public void stop() { try { // Remove the ShutdownHook first so that server.stop() // doesn&apos;t get invoked twice if (useShutdownHook) { Runtime.getRuntime().removeShutdownHook(shutdownHook);//将启动过程中添加的关闭钩子移除 // If JULI is being used, re-enable JULI&apos;s shutdown to ensure // log messages are not lost LogManager logManager = LogManager.getLogManager(); if (logManager instanceof ClassLoaderLogManager) { ((ClassLoaderLogManager) logManager).setUseShutdownHook( true); } } } catch (Throwable t) { ExceptionUtils.handleThrowable(t); // This will fail on JDK 1.2. Ignoring, as Tomcat can run // fine without the shutdown hook. } // Shut down the server try { Server s = getServer(); LifecycleState state = s.getState(); if (LifecycleState.STOPPING_PREP.compareTo(state) &lt;= 0 &amp;&amp; LifecycleState.DESTROYED.compareTo(state) &gt;= 0) { // Nothing to do. stop() was already called } else { s.stop();//停止Server容器。 s.destroy(); } } catch (LifecycleException e) { log.error(&quot;Catalina.stop&quot;, e); } } 总结： 通过对Tomcat源码的分析我们了解到Tomcat的启动和停止都离不开org.apache.catalina.startup.Bootstrap。 当停止Tomcat时，已经启动的Tomcat作为socket服务端，停止脚本启动的Bootstrap进程作为socket客户端向服务端发送shutdown命令 ，两个进程通过共享server.xml里Server标签的端口以及地址信息打通了socket的通信。","categories":[{"name":"Tomcat源码","slug":"Tomcat源码","permalink":"http://zhengweishan.oschina.io/categories/Tomcat源码/"}],"tags":[{"name":"tomcat","slug":"tomcat","permalink":"http://zhengweishan.oschina.io/tags/tomcat/"}]},{"title":"Tomcat源码学习（二）--Tomcat_7.0.70 启动分析","slug":"（二）Tomcat_7.0.70启动分析","date":"2017-02-05T16:00:00.000Z","updated":"2017-03-01T08:50:27.024Z","comments":true,"path":"2017/02/06/（二）Tomcat_7.0.70启动分析/","link":"","permalink":"http://zhengweishan.oschina.io/2017/02/06/（二）Tomcat_7.0.70启动分析/","excerpt":"1、运行Tomcat_7.0.70源码项目build成功后，刷新整个项目，会发现多出一个output目录： 为了让应用跑起来，可以检查一下output\\build\\conf下是否已经有配置文件，这些文件实际是从项目根路径conf目录下拷贝过来的。 找到BootStarp.java文件，Debug前加入默认的catalina home路径作为启动参数。 路径设置为output下build的绝对路径。比如我自己的机器设置的值是-Dcatalina.home=”W:\\workspace\\tc7.0.70\\output\\build” 这样就可以愉快的在文件中加入断点Debug源码分析了。运行之后的效果图：OK，源码到此运行成功，完美~","text":"1、运行Tomcat_7.0.70源码项目build成功后，刷新整个项目，会发现多出一个output目录： 为了让应用跑起来，可以检查一下output\\build\\conf下是否已经有配置文件，这些文件实际是从项目根路径conf目录下拷贝过来的。 找到BootStarp.java文件，Debug前加入默认的catalina home路径作为启动参数。 路径设置为output下build的绝对路径。比如我自己的机器设置的值是-Dcatalina.home=”W:\\workspace\\tc7.0.70\\output\\build” 这样就可以愉快的在文件中加入断点Debug源码分析了。运行之后的效果图：OK，源码到此运行成功，完美~ 2、启动分析上面运行源码用的BootStarp.java这个类中的main方法（后面再对这个main方法做分析），实际上我们在用Tomcat的时候,大部分都是使用脚本文件startup.sh、startup.bat、shutdown.sh、shutdown.bat等脚本或者批处理命令来启动Tomcat的.大家一定知道改如何使用它，但是它们究竟是如何实现的，下面就一点一点的分析。 由于在生产环境中，Tomcat一般部署在Linux系统下，所以将以startup.sh和shutdown.sh等shell脚本为准，对Tomcat的启动与停止进行分析。 Linux下启动Tomcat的命令： sh startup.sh 下面将从shell脚本startup.sh开始分析Tomcat的启动过程。 startup.sh脚本代码清单： # Better OS/400 detection: see Bugzilla 31132 os400=false case &quot;`uname`&quot; in OS400*) os400=true;; esac # resolve links - $0 may be a softlink PRG=&quot;$0&quot; while [ -h &quot;$PRG&quot; ] ; do ls=`ls -ld &quot;$PRG&quot;` link=`expr &quot;$ls&quot; : &apos;.*-&gt; \\(.*\\)$&apos;` if expr &quot;$link&quot; : &apos;/.*&apos; &gt; /dev/null; then PRG=&quot;$link&quot; else PRG=`dirname &quot;$PRG&quot;`/&quot;$link&quot; fi done PRGDIR=`dirname &quot;$PRG&quot;` EXECUTABLE=catalina.sh # Check that target executable exists if $os400; then # -x will Only work on the os400 if the files are: # 1. owned by the user # 2. owned by the PRIMARY group of the user # this will not work if the user belongs in secondary groups eval else if [ ! -x &quot;$PRGDIR&quot;/&quot;$EXECUTABLE&quot; ]; then echo &quot;Cannot find $PRGDIR/$EXECUTABLE&quot; echo &quot;The file is absent or does not have execute permission&quot; echo &quot;This file is needed to run this program&quot; exit 1 fi fi exec &quot;$PRGDIR&quot;/&quot;$EXECUTABLE&quot; start &quot;$@&quot; 从代码清单可以看出有两个主要的变量，分别是： 1. PRGDIR：当前shell脚本所在的路径； 2. EXECUTABLE：脚本catalina.sh。 exec &quot;$PRGDIR&quot;/&quot;$EXECUTABLE&quot; start &quot;$@&quot; 我们知道执行了shell脚本catalina.sh，并且传递参数start。 catalina.sh 脚本代码（部分）清单： shift touch &quot;$CATALINA_OUT&quot; if [ &quot;$1&quot; = &quot;-security&quot; ] ; then if [ $have_tty -eq 1 ]; then echo &quot;Using Security Manager&quot; fi shift eval $_NOHUP &quot;\\&quot;$_RUNJAVA\\&quot;&quot; &quot;\\&quot;$LOGGING_CONFIG\\&quot;&quot; $LOGGING_MANAGER $JAVA_OPTS $CATALINA_OPTS \\ -Djava.endorsed.dirs=&quot;\\&quot;$JAVA_ENDORSED_DIRS\\&quot;&quot; -classpath &quot;\\&quot;$CLASSPATH\\&quot;&quot; \\ -Djava.security.manager \\ -Djava.security.policy==&quot;\\&quot;$CATALINA_BASE/conf/catalina.policy\\&quot;&quot; \\ -Dcatalina.base=&quot;\\&quot;$CATALINA_BASE\\&quot;&quot; \\ -Dcatalina.home=&quot;\\&quot;$CATALINA_HOME\\&quot;&quot; \\ -Djava.io.tmpdir=&quot;\\&quot;$CATALINA_TMPDIR\\&quot;&quot; \\ org.apache.catalina.startup.Bootstrap &quot;$@&quot; start \\ &gt;&gt; &quot;$CATALINA_OUT&quot; 2&gt;&amp;1 &quot;&amp;&quot; else eval $_NOHUP &quot;\\&quot;$_RUNJAVA\\&quot;&quot; &quot;\\&quot;$LOGGING_CONFIG\\&quot;&quot; $LOGGING_MANAGER $JAVA_OPTS $CATALINA_OPTS \\ -Djava.endorsed.dirs=&quot;\\&quot;$JAVA_ENDORSED_DIRS\\&quot;&quot; -classpath &quot;\\&quot;$CLASSPATH\\&quot;&quot; \\ -Dcatalina.base=&quot;\\&quot;$CATALINA_BASE\\&quot;&quot; \\ -Dcatalina.home=&quot;\\&quot;$CATALINA_HOME\\&quot;&quot; \\ -Djava.io.tmpdir=&quot;\\&quot;$CATALINA_TMPDIR\\&quot;&quot; \\ org.apache.catalina.startup.Bootstrap &quot;$@&quot; start \\ &gt;&gt; &quot;$CATALINA_OUT&quot; 2&gt;&amp;1 &quot;&amp;&quot; fi if [ ! -z &quot;$CATALINA_PID&quot; ]; then echo $! &gt; &quot;$CATALINA_PID&quot; fi echo &quot;Tomcat started.&quot; 从上面可以看出，脚本最终使用java命令执行了org.apache.catalina.startup.Bootstrap类中的main方法，参数也是start。Bootstrap的main方法的实现如下： public static void main(String args[]) { if (daemon == null) { // Don&apos;t set daemon until init() has completed Bootstrap bootstrap = new Bootstrap(); try { bootstrap.init(); } catch (Throwable t) { handleThrowable(t); t.printStackTrace(); return; } daemon = bootstrap; } else { // When running as a service the call to stop will be on a new // thread so make sure the correct class loader is used to prevent // a range of class not found exceptions. Thread.currentThread().setContextClassLoader(daemon.catalinaLoader); } try { String command = &quot;start&quot;; if (args.length &gt; 0) { command = args[args.length - 1]; } if (command.equals(&quot;startd&quot;)) { args[args.length - 1] = &quot;start&quot;; daemon.load(args); daemon.start(); } else if (command.equals(&quot;stopd&quot;)) { args[args.length - 1] = &quot;stop&quot;; daemon.stop(); } else if (command.equals(&quot;start&quot;)) { //传递参数为start daemon.setAwait(true); daemon.load(args); daemon.start(); } else if (command.equals(&quot;stop&quot;)) { daemon.stopServer(args); } else if (command.equals(&quot;configtest&quot;)) { daemon.load(args); if (null==daemon.getServer()) { System.exit(1); } System.exit(0); } else { log.warn(&quot;Bootstrap: command \\&quot;&quot; + command + &quot;\\&quot; does not exist.&quot;); } } catch (Throwable t) { // Unwrap the Exception for clearer error reporting if (t instanceof InvocationTargetException &amp;&amp; t.getCause() != null) { t = t.getCause(); } handleThrowable(t); t.printStackTrace(); System.exit(1); } } 当传递参数start的时候，command等于start，此时main方法的执行步骤如下： 初始化Bootstrap public void init() throws Exception{ // Set Catalina path setCatalinaHome(); //1.设置Catalina路径，默认为Tomcat的根目录 setCatalinaBase(); initClassLoaders();//2.初始化Tomcat的类加载器 Thread.currentThread().setContextClassLoader(catalinaLoader);//3.并设置线程上下文类加载器 SecurityClassLoad.securityClassLoad(catalinaLoader); // Load our startup class and call its process() method if (log.isDebugEnabled()) log.debug(&quot;Loading startup class&quot;); //4.用反射实例化org.apache.catalina.startup.Catalina对象，并且使用反射调用其setParentClassLoader方法，给Catalina对象设置Tomcat类加载体系的顶级加载器（Java自带的三种类加载器除外） Class&lt;?&gt; startupClass = catalinaLoader.loadClass (&quot;org.apache.catalina.startup.Catalina&quot;); Object startupInstance = startupClass.newInstance(); // Set the shared extensions class loader if (log.isDebugEnabled()) log.debug(&quot;Setting startup class properties&quot;); String methodName = &quot;setParentClassLoader&quot;; Class&lt;?&gt; paramTypes[] = new Class[1]; paramTypes[0] = Class.forName(&quot;java.lang.ClassLoader&quot;); Object paramValues[] = new Object[1]; paramValues[0] = sharedLoader; Method method = startupInstance.getClass().getMethod(methodName, paramTypes); method.invoke(startupInstance, paramValues); catalinaDaemon = startupInstance; } 加载、解析server.xml配置文件 当传递参数start的时候，会调用Bootstrap的load方法： /** * Load daemon. */ private void load(String[] arguments) throws Exception { // Call the load() method String methodName = &quot;load&quot;; Object param[]; Class&lt;?&gt; paramTypes[]; if (arguments==null || arguments.length==0) { paramTypes = null; param = null; } else { paramTypes = new Class[1]; paramTypes[0] = arguments.getClass(); param = new Object[1]; param[0] = arguments; } Method method = catalinaDaemon.getClass().getMethod(methodName, paramTypes);//用反射调用catalinaDaemon（类型是Catalina）的load方法加载和解析server.xml配置文件。 if (log.isDebugEnabled()) log.debug(&quot;Calling startup class &quot; + method); method.invoke(catalinaDaemon, param); } 备注：如何加载和解析server.xml配置文件，后面会博客会陆续给出。 启动Tomcat 当传递参数start的时候，调用Bootstrap的load方法之后会接着调用start方法： /** * Start the Catalina daemon. */ public void start() throws Exception { if( catalinaDaemon==null ) init(); Method method = catalinaDaemon.getClass().getMethod(&quot;start&quot;, (Class [] )null);//启动Tomcat，此方法实际是用反射调用了catalinaDaemon（类型是Catalina）的start方法 method.invoke(catalinaDaemon, (Object [])null); } Catalina的start方法如下： /** * Start a new server instance. */ public void start() { //1.验证Server容器是否已经实例化 if (getServer() == null) { load(); //如果没有实例化Server容器，还会再次调用Catalina的load方法加载和解析server.xml，这也说明Tomcat只允许Server容器通过配置在server.xml的方式生成，用户也可以自己实现Server接口创建自定义的Server容器以取代默认的StandardServer。 } if (getServer() == null) { log.fatal(&quot;Cannot start server. Server instance is not configured.&quot;); return; } long t1 = System.nanoTime(); // Start the new server try { getServer().start(); //2.启动Server容器 } catch (LifecycleException e) { log.fatal(sm.getString(&quot;catalina.serverStartFail&quot;), e); try { getServer().destroy(); } catch (LifecycleException e1) { log.debug(&quot;destroy() failed for failed Server &quot;, e1); } return; } long t2 = System.nanoTime(); if(log.isInfoEnabled()) { log.info(&quot;Server startup in &quot; + ((t2 - t1) / 1000000) + &quot; ms&quot;); } // Register shutdown hook if (useShutdownHook) { if (shutdownHook == null) { shutdownHook = new CatalinaShutdownHook();//3.设置关闭钩子 } Runtime.getRuntime().addShutdownHook(shutdownHook); // If JULI is being used, disable JULI&apos;s shutdown hook since // shutdown hooks run in parallel and log messages may be lost // if JULI&apos;s hook completes before the CatalinaShutdownHook() LogManager logManager = LogManager.getLogManager(); if (logManager instanceof ClassLoaderLogManager) { ((ClassLoaderLogManager) logManager).setUseShutdownHook( false); } } if (await) { await();//4.最后调用Catalina的await方法循环等待接收Tomcat的shutdown命令 stop();//5.如果Tomcat运行正常且没有收到shutdown命令，是不会向下执行此方法的，当接收到shutdown命令，Catalina的await方法会退出循环等待，然后顺序执行stop方法停止Tomcat } } Catalina的await方法实际只是代理执行了Server容器的await方法。 /** * Await and shutdown. */ public void await() { getServer().await(); } 以Server的默认实现StandardServer为例，其await方法如下： @Override public void await() { // Negative values - don&apos;t wait on port - tomcat is embedded or we just don&apos;t like ports if( port == -2 ) { // undocumented yet - for embedding apps that are around, alive. return; } if( port==-1 ) { try { awaitThread = Thread.currentThread(); while(!stopAwait) { try { Thread.sleep( 10000 ); } catch( InterruptedException ex ) { // continue and check the flag } } } finally { awaitThread = null; } return; } // Set up a server socket to wait on try { awaitSocket = new ServerSocket(port, 1, InetAddress.getByName(address));//创建socket连接的服务端对象ServerSocket } catch (IOException e) { log.error(&quot;StandardServer.await: create[&quot; + address + &quot;:&quot; + port + &quot;]: &quot;, e); return; } try { awaitThread = Thread.currentThread(); // Loop waiting for a connection and a valid command while (!stopAwait) { ServerSocket serverSocket = awaitSocket; if (serverSocket == null) { break; } // Wait for the next connection Socket socket = null; StringBuilder command = new StringBuilder();//创建一个对象循环接收socket中的字符 try { InputStream stream; long acceptStartTime = System.currentTimeMillis(); try { socket = serverSocket.accept(); socket.setSoTimeout(10 * 1000); // Ten seconds stream = socket.getInputStream(); } catch (SocketTimeoutException ste) { // This should never happen but bug 56684 suggests that // it does. log.warn(sm.getString(&quot;standardServer.accept.timeout&quot;, Long.valueOf(System.currentTimeMillis() - acceptStartTime)), ste); continue; } catch (AccessControlException ace) { log.warn(&quot;StandardServer.accept security exception: &quot; + ace.getMessage(), ace); continue; } catch (IOException e) { if (stopAwait) { // Wait was aborted with socket.close() break; } log.error(&quot;StandardServer.await: accept: &quot;, e); break; } // Read a set of characters from the socket int expected = 1024; // Cut off to avoid DoS attack while (expected &lt; shutdown.length()) { if (random == null) random = new Random(); expected += (random.nextInt() % 1024); } while (expected &gt; 0) { int ch = -1; try { ch = stream.read(); } catch (IOException e) { log.warn(&quot;StandardServer.await: read: &quot;, e); ch = -1; } if (ch &lt; 32) // Control character or EOF terminates loop break; command.append((char) ch); expected--; } } finally { // Close the socket now that we are done with it try { if (socket != null) { socket.close(); } } catch (IOException e) { // Ignore } } // Match against our command string boolean match = command.toString().equals(shutdown); if (match) { //如果接收到的命令与SHUTDOWN匹配（由于使用了equals，所以shutdown命令必须是大写的），那么退出循环等待 log.info(sm.getString(&quot;standardServer.shutdownViaPort&quot;)); break; } else log.warn(&quot;StandardServer.await: Invalid command &apos;&quot; + command.toString() + &quot;&apos; received&quot;); } } finally { ServerSocket serverSocket = awaitSocket; awaitThread = null; awaitSocket = null; // Close the server socket and return if (serverSocket != null) { try { serverSocket.close(); } catch (IOException e) { // Ignore } } } } 至此，Tomcat启动完毕。 备注：如何启动server，这里不做过多解释，后面会有专门的博客介绍《容器启动过程分析》。","categories":[{"name":"Tomcat源码","slug":"Tomcat源码","permalink":"http://zhengweishan.oschina.io/categories/Tomcat源码/"}],"tags":[{"name":"tomcat","slug":"tomcat","permalink":"http://zhengweishan.oschina.io/tags/tomcat/"}]},{"title":"Tomcat 源码学习（一）--Tomcat_7.0.70 源码运行环境搭建","slug":"（一）Tomcat7.0.70源代码运行环境搭建","date":"2017-02-04T16:00:00.000Z","updated":"2017-03-01T08:48:29.343Z","comments":true,"path":"2017/02/05/（一）Tomcat7.0.70源代码运行环境搭建/","link":"","permalink":"http://zhengweishan.oschina.io/2017/02/05/（一）Tomcat7.0.70源代码运行环境搭建/","excerpt":"1、源码下载下载地址 2、环境配置2.1 新建eclipse项目新建项目tc7.0.70，其他设置默认就好。 项目建立好之后修改此项目的编译环境， 请选择编译环境为1.6，选择1.7会报错（tomcat-dbcp.jar依赖的是jdk1.6， 选择1.7在建立的时候会报错，这个大家可以尝试下看看是不是），下图就是选择编译环境为1.7的时候报的错误。 修改编译环境：选中项目右键-&gt;Properties-&gt;Java Complier 如下图：","text":"1、源码下载下载地址 2、环境配置2.1 新建eclipse项目新建项目tc7.0.70，其他设置默认就好。 项目建立好之后修改此项目的编译环境， 请选择编译环境为1.6，选择1.7会报错（tomcat-dbcp.jar依赖的是jdk1.6， 选择1.7在建立的时候会报错，这个大家可以尝试下看看是不是），下图就是选择编译环境为1.7的时候报的错误。 修改编译环境：选中项目右键-&gt;Properties-&gt;Java Complier 如下图： 2.2 导入源码将下载的tomcat源码包解压开： 修改bin目录为script（为什么要这样做？因为新建的Java项目中默认编译后的文件 存放目录是bin，这样做防止编译后的文件覆盖原来拷贝过去的内容。） 修改之后拷贝到Eclipse里新建的项目根目录下： 将项目中默认的src目录删掉，java和test作为源目录。如图这样操作选中java和test目录： 转换之后如图：（这里有红叉，不要管它，后面就解决这个问题） 2.3 添加需要的jar上面说到转换之后有红叉，很明显是缺少一些jar，这就需要我们自己手动添加了，所以我新建了一个depend的文件： 缺少的这些jar包，我整理下统一放在云盘了，大家从下面的地址下载就可以了，不用再来回找了。 缺少的jar下载，大家下载之后直接解压，然后放在depend下： 把这些jar包加入到编译路径里，如图： 此时发现test目录下还有错误，实际上是因为test里面用到了junit的一些注解，所以需要将junit4引进来 选中项目右键-&gt;Properties-&gt;Java Build Path如下图： 自此整个项目应该可以编译了。 2.4 build（验证能否构建成功）运行项目根目录下的build.xml，执行默认的ant任务，看看项目构建的有没有问题。 控制台输出&quot;BUILD SUCCESSFUL&quot;表示编译构建成功。如图： 至此源码运行环境搭建完毕。","categories":[{"name":"Tomcat源码","slug":"Tomcat源码","permalink":"http://zhengweishan.oschina.io/categories/Tomcat源码/"}],"tags":[{"name":"tomcat","slug":"tomcat","permalink":"http://zhengweishan.oschina.io/tags/tomcat/"}]},{"title":"kafka学习（四）---- Kafka整合SpringMVC实例（二)","slug":"kafka学习（四）---- Kafka整合SpringMVC实例（二）","date":"2017-02-03T16:00:00.000Z","updated":"2017-03-01T08:46:49.305Z","comments":true,"path":"2017/02/04/kafka学习（四）---- Kafka整合SpringMVC实例（二）/","link":"","permalink":"http://zhengweishan.oschina.io/2017/02/04/kafka学习（四）---- Kafka整合SpringMVC实例（二）/","excerpt":"1、概述目前没有很好的整合Kafka的案例，自己参考着使用spring-integration-kafka框架写了一个：Kafka整合SpringMVC实例，但同时也发现官方文档也不全，所以又用spring简单的实现了一下，感觉这个比使用spring-integration-kafka框架更简单一点，但是需要对kafka作深入的了解，废话不多说直接切入正题。 2、实例1. 安装Zookeeper Zookeeper下载基本使用 2. 安装Kafka kafka基本概念以及环境搭建","text":"1、概述目前没有很好的整合Kafka的案例，自己参考着使用spring-integration-kafka框架写了一个：Kafka整合SpringMVC实例，但同时也发现官方文档也不全，所以又用spring简单的实现了一下，感觉这个比使用spring-integration-kafka框架更简单一点，但是需要对kafka作深入的了解，废话不多说直接切入正题。 2、实例1. 安装Zookeeper Zookeeper下载基本使用 2. 安装Kafka kafka基本概念以及环境搭建 3. 创建spring项目（建议使用maven方式创建） 项目截图（小红叉不影响项目的启动） pom.xml配置 &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.kafka.demo&lt;/groupId&gt; &lt;artifactId&gt;SpringWithKafka&lt;/artifactId&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;SpringWithKafka Maven Webapp&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;properties&gt; &lt;spring.version&gt;4.2.5.RELEASE&lt;/spring.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- spring --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- spring-kafka --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt; &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt; &lt;version&gt;1.0.3.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 日志 --&gt; &lt;dependency&gt; &lt;groupId&gt;commons-logging&lt;/groupId&gt; &lt;artifactId&gt;commons-logging&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;1.7.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax&lt;/groupId&gt; &lt;artifactId&gt;javaee-api&lt;/artifactId&gt; &lt;version&gt;7.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-core&lt;/artifactId&gt; &lt;version&gt;2.7.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.7.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-annotations&lt;/artifactId&gt; &lt;version&gt;2.7.6&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;SpringWithKafka&lt;/finalName&gt; &lt;/build&gt; &lt;/project&gt; kafka-producer.xml配置 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;context:property-placeholder location=&quot;classpath:init.properties&quot; /&gt; &lt;!-- 定义producer的参数 --&gt; &lt;bean id=&quot;producerProperties&quot; class=&quot;java.util.HashMap&quot;&gt; &lt;constructor-arg&gt; &lt;map&gt; &lt;entry key=&quot;bootstrap.servers&quot; value=&quot;${bootstrap.servers}&quot;/&gt; &lt;entry key=&quot;group.id&quot; value=&quot;0&quot;/&gt; &lt;entry key=&quot;retries&quot; value=&quot;10&quot;/&gt; &lt;entry key=&quot;batch.size&quot; value=&quot;16384&quot;/&gt; &lt;entry key=&quot;linger.ms&quot; value=&quot;1&quot;/&gt; &lt;entry key=&quot;buffer.memory&quot; value=&quot;33554432&quot;/&gt; &lt;entry key=&quot;key.serializer&quot; value=&quot;org.apache.kafka.common.serialization.IntegerSerializer&quot;/&gt; &lt;entry key=&quot;value.serializer&quot; value=&quot;org.apache.kafka.common.serialization.StringSerializer&quot;/&gt; &lt;/map&gt; &lt;/constructor-arg&gt; &lt;/bean&gt; &lt;!-- 创建kafkatemplate需要使用的producerfactory bean --&gt; &lt;bean id=&quot;producerFactory&quot; class=&quot;org.springframework.kafka.core.DefaultKafkaProducerFactory&quot;&gt; &lt;constructor-arg&gt; &lt;ref bean=&quot;producerProperties&quot;/&gt; &lt;/constructor-arg&gt; &lt;/bean&gt; &lt;!-- 创建kafkatemplate，使用的时候，只需要注入这个bean，即可使用template的send消息方法 --&gt; &lt;bean id=&quot;KafkaTemplate&quot; class=&quot;org.springframework.kafka.core.KafkaTemplate&quot;&gt; &lt;constructor-arg ref=&quot;producerFactory&quot;/&gt; &lt;constructor-arg name=&quot;autoFlush&quot; value=&quot;true&quot;/&gt; &lt;property name=&quot;defaultTopic&quot; value=&quot;myTopic&quot;/&gt; &lt;/bean&gt; &lt;/beans&gt; kafka-consumer.xml配置 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;context:property-placeholder location=&quot;classpath:init.properties&quot; /&gt; &lt;!-- 定义consumer的参数 --&gt; &lt;bean id=&quot;consumerProperties&quot; class=&quot;java.util.HashMap&quot;&gt; &lt;constructor-arg&gt; &lt;map&gt; &lt;entry key=&quot;bootstrap.servers&quot; value=&quot;${bootstrap.servers}&quot;/&gt; &lt;entry key=&quot;group.id&quot; value=&quot;0&quot;/&gt; &lt;entry key=&quot;enable.auto.commit&quot; value=&quot;true&quot;/&gt; &lt;entry key=&quot;auto.commit.interval.ms&quot; value=&quot;1000&quot;/&gt; &lt;entry key=&quot;session.timeout.ms&quot; value=&quot;15000&quot;/&gt; &lt;entry key=&quot;key.deserializer&quot; value=&quot;org.apache.kafka.common.serialization.IntegerDeserializer&quot;/&gt; &lt;entry key=&quot;value.deserializer&quot; value=&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;/&gt; &lt;/map&gt; &lt;/constructor-arg&gt; &lt;/bean&gt; &lt;!-- 创建consumerFactory bean --&gt; &lt;bean id=&quot;consumerFactory&quot; class=&quot;org.springframework.kafka.core.DefaultKafkaConsumerFactory&quot;&gt; &lt;constructor-arg&gt; &lt;ref bean=&quot;consumerProperties&quot;/&gt; &lt;/constructor-arg&gt; &lt;/bean&gt; &lt;!-- 实际执行消息消费的类 --&gt; &lt;bean id=&quot;messageListernerConsumerService&quot; class=&quot;com.kafka.demo.service.KafkaConsumerService&quot;/&gt; &lt;!-- 消费者容器配置信息 --&gt; &lt;bean id=&quot;containerProperties&quot; class=&quot;org.springframework.kafka.listener.config.ContainerProperties&quot;&gt; &lt;constructor-arg value=&quot;myTopic&quot;/&gt; &lt;property name=&quot;messageListener&quot; ref=&quot;messageListernerConsumerService&quot;/&gt; &lt;/bean&gt; &lt;!-- 注册消费者容器到监听器 --&gt; &lt;bean id=&quot;messageListenerContainer&quot; class=&quot;org.springframework.kafka.listener.KafkaMessageListenerContainer&quot; init-method=&quot;doStart&quot;&gt; &lt;constructor-arg ref=&quot;consumerFactory&quot;/&gt; &lt;constructor-arg ref=&quot;containerProperties&quot;/&gt; &lt;/bean&gt; &lt;/beans&gt; 其他代码请参看实例源码：源码下载 三、实例演示a、运行项目访问 http://localhost:8080/SpringMvcWithKafka/kafka/test //测试地址效果如图： b、查看kafka控制台信息输出,如下图：","categories":[{"name":"kafka","slug":"kafka","permalink":"http://zhengweishan.oschina.io/categories/kafka/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"http://zhengweishan.oschina.io/tags/kafka/"}]},{"title":"kafka学习（三）----- Kafka整合SpringMVC实例","slug":"kafka学习（三）---- Kafka整合SpringMVC实例","date":"2017-02-02T16:00:00.000Z","updated":"2017-03-01T08:44:20.839Z","comments":true,"path":"2017/02/03/kafka学习（三）---- Kafka整合SpringMVC实例/","link":"","permalink":"http://zhengweishan.oschina.io/2017/02/03/kafka学习（三）---- Kafka整合SpringMVC实例/","excerpt":"一、概述kafka一个高吞吐量的分布式发布订阅消息系统。有关知识请参看：kafka基本概念以及环境搭建，kafka整合springMVC需要用到一个开源框架：spring-integration-kafka，这个官方框架我就不介绍了，请自行百度。 二、实例1. 安装Zookeeper Zookeeper下载基本使用 2. 安装Kafka kafka基本概念以及环境搭建","text":"一、概述kafka一个高吞吐量的分布式发布订阅消息系统。有关知识请参看：kafka基本概念以及环境搭建，kafka整合springMVC需要用到一个开源框架：spring-integration-kafka，这个官方框架我就不介绍了，请自行百度。 二、实例1. 安装Zookeeper Zookeeper下载基本使用 2. 安装Kafka kafka基本概念以及环境搭建 3. 创建spring项目（建议使用maven方式创建） 项目截图（小红叉不影响项目的启动） pom.xml配置 &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.kafka.demo&lt;/groupId&gt; &lt;artifactId&gt;SpringMvcWithKafka&lt;/artifactId&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;SpringMvcWithKafka Maven Webapp&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;properties&gt; &lt;spring.version&gt;4.2.5.RELEASE&lt;/spring.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;${spring.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.integration&lt;/groupId&gt; &lt;artifactId&gt;spring-integration-kafka&lt;/artifactId&gt; &lt;version&gt;1.3.0.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-logging&lt;/groupId&gt; &lt;artifactId&gt;commons-logging&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;1.7.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax&lt;/groupId&gt; &lt;artifactId&gt;javaee-api&lt;/artifactId&gt; &lt;version&gt;7.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-core&lt;/artifactId&gt; &lt;version&gt;2.7.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.7.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-annotations&lt;/artifactId&gt; &lt;version&gt;2.7.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.avro&lt;/groupId&gt; &lt;artifactId&gt;avro&lt;/artifactId&gt; &lt;version&gt;1.7.7&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;SpringMvcWithKafka&lt;/finalName&gt; &lt;/build&gt; &lt;/project&gt; spring-kafka-consumer.xml配置 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:int=&quot;http://www.springframework.org/schema/integration&quot; xmlns:int-kafka=&quot;http://www.springframework.org/schema/integration/kafka&quot; xmlns:task=&quot;http://www.springframework.org/schema/task&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/integration/kafka http://www.springframework.org/schema/integration/kafka/spring-integration-kafka.xsd http://www.springframework.org/schema/integration http://www.springframework.org/schema/integration/spring-integration.xsd http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/task http://www.springframework.org/schema/task/spring-task.xsd&quot;&gt; &lt;!-- topic test conf --&gt; &lt;int:channel id=&quot;inputFromKafka&quot;&gt; &lt;int:dispatcher task-executor=&quot;kafkaMessageExecutor&quot; /&gt; &lt;/int:channel&gt; &lt;!-- zookeeper配置 可以配置多个 --&gt; &lt;int-kafka:zookeeper-connect id=&quot;zookeeperConnect&quot; zk-connect=&quot;localhost:2181&quot; zk-connection-timeout=&quot;6000&quot; zk-session-timeout=&quot;6000&quot; zk-sync-time=&quot;2000&quot; /&gt; &lt;!-- channel配置 auto-startup=&quot;true&quot; 否则接收不发数据 --&gt; &lt;int-kafka:inbound-channel-adapter id=&quot;kafkaInboundChannelAdapter&quot; kafka-consumer-context-ref=&quot;consumerContext&quot; auto-startup=&quot;true&quot; channel=&quot;inputFromKafka&quot;&gt; &lt;int:poller fixed-delay=&quot;1&quot; time-unit=&quot;MILLISECONDS&quot; /&gt; &lt;/int-kafka:inbound-channel-adapter&gt; &lt;task:executor id=&quot;kafkaMessageExecutor&quot; pool-size=&quot;8&quot; keep-alive=&quot;120&quot; queue-capacity=&quot;500&quot; /&gt; &lt;bean id=&quot;kafkaDecoder&quot; class=&quot;org.springframework.integration.kafka.serializer.common.StringDecoder&quot; /&gt; &lt;bean id=&quot;consumerProperties&quot; class=&quot;org.springframework.beans.factory.config.PropertiesFactoryBean&quot;&gt; &lt;property name=&quot;properties&quot;&gt; &lt;props&gt; &lt;prop key=&quot;auto.offset.reset&quot;&gt;smallest&lt;/prop&gt; &lt;prop key=&quot;socket.receive.buffer.bytes&quot;&gt;10485760&lt;/prop&gt; &lt;!-- 10M --&gt; &lt;prop key=&quot;fetch.message.max.bytes&quot;&gt;5242880&lt;/prop&gt; &lt;prop key=&quot;auto.commit.interval.ms&quot;&gt;1000&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- 消息接收的BEEN --&gt; &lt;bean id=&quot;kafkaConsumerService&quot; class=&quot;com.kafka.demo.service.impl.KafkaConsumerService&quot; /&gt; &lt;!-- 指定接收的方法 --&gt; &lt;int:outbound-channel-adapter channel=&quot;inputFromKafka&quot; ref=&quot;kafkaConsumerService&quot; method=&quot;processMessage&quot; /&gt; &lt;int-kafka:consumer-context id=&quot;consumerContext&quot; consumer-timeout=&quot;1000&quot; zookeeper-connect=&quot;zookeeperConnect&quot; consumer-properties=&quot;consumerProperties&quot;&gt; &lt;int-kafka:consumer-configurations&gt; &lt;int-kafka:consumer-configuration group-id=&quot;default1&quot; value-decoder=&quot;kafkaDecoder&quot; key-decoder=&quot;kafkaDecoder&quot; max-messages=&quot;5000&quot;&gt; &lt;!-- 两个TOPIC配置 --&gt; &lt;int-kafka:topic id=&quot;myTopic&quot; streams=&quot;4&quot; /&gt; &lt;int-kafka:topic id=&quot;testTopic&quot; streams=&quot;4&quot; /&gt; &lt;/int-kafka:consumer-configuration&gt; &lt;/int-kafka:consumer-configurations&gt; &lt;/int-kafka:consumer-context&gt; &lt;/beans&gt; spring-kafka-producer.xml配置 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:int=&quot;http://www.springframework.org/schema/integration&quot; xmlns:int-kafka=&quot;http://www.springframework.org/schema/integration/kafka&quot; xmlns:task=&quot;http://www.springframework.org/schema/task&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/integration/kafka http://www.springframework.org/schema/integration/kafka/spring-integration-kafka.xsd http://www.springframework.org/schema/integration http://www.springframework.org/schema/integration/spring-integration.xsd http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/task http://www.springframework.org/schema/task/spring-task.xsd&quot;&gt; &lt;!-- commons config --&gt; &lt;bean id=&quot;stringSerializer&quot; class=&quot;org.apache.kafka.common.serialization.StringSerializer&quot; /&gt; &lt;bean id=&quot;kafkaEncoder&quot; class=&quot;org.springframework.integration.kafka.serializer.avro.AvroReflectDatumBackedKafkaEncoder&quot;&gt; &lt;constructor-arg value=&quot;java.lang.String&quot; /&gt; &lt;/bean&gt; &lt;bean id=&quot;producerProperties&quot; class=&quot;org.springframework.beans.factory.config.PropertiesFactoryBean&quot;&gt; &lt;property name=&quot;properties&quot;&gt; &lt;props&gt; &lt;prop key=&quot;topic.metadata.refresh.interval.ms&quot;&gt;3600000&lt;/prop&gt; &lt;prop key=&quot;message.send.max.retries&quot;&gt;5&lt;/prop&gt; &lt;prop key=&quot;serializer.class&quot;&gt;kafka.serializer.StringEncoder&lt;/prop&gt; &lt;prop key=&quot;request.required.acks&quot;&gt;1&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- topic test config --&gt; &lt;int:channel id=&quot;kafkaTopicTest&quot;&gt; &lt;int:queue /&gt; &lt;/int:channel&gt; &lt;int-kafka:outbound-channel-adapter id=&quot;kafkaOutboundChannelAdapterTopicTest&quot; kafka-producer-context-ref=&quot;producerContextTopicTest&quot; auto-startup=&quot;true&quot; channel=&quot;kafkaTopicTest&quot; order=&quot;3&quot;&gt; &lt;int:poller fixed-delay=&quot;1000&quot; time-unit=&quot;MILLISECONDS&quot; receive-timeout=&quot;1&quot; task-executor=&quot;taskExecutor&quot; /&gt; &lt;/int-kafka:outbound-channel-adapter&gt; &lt;task:executor id=&quot;taskExecutor&quot; pool-size=&quot;5&quot; keep-alive=&quot;120&quot; queue-capacity=&quot;500&quot; /&gt; &lt;int-kafka:producer-context id=&quot;producerContextTopicTest&quot; producer-properties=&quot;producerProperties&quot;&gt; &lt;int-kafka:producer-configurations&gt; &lt;!-- 多个topic配置 --&gt; &lt;int-kafka:producer-configuration broker-list=&quot;localhost:9092&quot; key-serializer=&quot;stringSerializer&quot; value-class-type=&quot;java.lang.String&quot; value-serializer=&quot;stringSerializer&quot; topic=&quot;testTopic&quot; /&gt; &lt;int-kafka:producer-configuration broker-list=&quot;localhost:9092&quot; key-serializer=&quot;stringSerializer&quot; value-class-type=&quot;java.lang.String&quot; value-serializer=&quot;stringSerializer&quot; topic=&quot;myTopic&quot; /&gt; &lt;/int-kafka:producer-configurations&gt; &lt;/int-kafka:producer-context&gt; &lt;/beans&gt; 其他代码请参看实例源码：源码下载 三、实例演示a、先根据配置文件使用命令行创建两个topic，截图如下： b、运行项目访问 http://localhost:8080/SpringMvcWithKafka/kafka/test //测试地址效果如图： c、查看kafka控制台信息输出,如下图： 说明：如果使用最新版本的kafka，上面的例子可能就跑步起来了，猜测应该是kafka版本问题，所以推荐使用稳定版本。","categories":[{"name":"kafka","slug":"kafka","permalink":"http://zhengweishan.oschina.io/categories/kafka/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"http://zhengweishan.oschina.io/tags/kafka/"}]},{"title":"kafka学习（二）---- Kafka简单的Java版本的Hello World实例","slug":"kafka学习（二）---- Kafka简单的Java版本的HelloWorld实例","date":"2017-02-01T16:00:00.000Z","updated":"2017-03-01T08:41:22.175Z","comments":true,"path":"2017/02/02/kafka学习（二）---- Kafka简单的Java版本的HelloWorld实例/","link":"","permalink":"http://zhengweishan.oschina.io/2017/02/02/kafka学习（二）---- Kafka简单的Java版本的HelloWorld实例/","excerpt":"1、开发环境我使用的是官网的kafka_2.11-0.10.0.0版本，最新的是kafka_2.11-0.10.0.1版本，大家自行下载安装配置。点击进入下载地址，点击进入如何win下配置开发环境 ##2、 创建项目 ##两种方式： （a）普通的方式创建 注意：开发时候，需要将下载kafka-2.11-0.10.0.0.jar包加入到classpath下面，这个包包含了所有Kafka的api的实现。由于kafka是使用Scala编写的，所以可能下载的kafka中的libs文件中的kafka-2.11-0.10.0.0.jar放到项目中不能用，而且还依赖scala-library-2.11.8.jar，所以推荐使用第二种方式构建项目。 项目结构图： (b)maven构建项目maven下载配置这里不再叙述，请参看：eclipse创建maven多模块项目中有关maven的介绍。好处在于不用自己去添加依赖了，maven自己帮我们加载依赖。 项目结构图：","text":"1、开发环境我使用的是官网的kafka_2.11-0.10.0.0版本，最新的是kafka_2.11-0.10.0.1版本，大家自行下载安装配置。点击进入下载地址，点击进入如何win下配置开发环境 ##2、 创建项目 ##两种方式： （a）普通的方式创建 注意：开发时候，需要将下载kafka-2.11-0.10.0.0.jar包加入到classpath下面，这个包包含了所有Kafka的api的实现。由于kafka是使用Scala编写的，所以可能下载的kafka中的libs文件中的kafka-2.11-0.10.0.0.jar放到项目中不能用，而且还依赖scala-library-2.11.8.jar，所以推荐使用第二种方式构建项目。 项目结构图： (b)maven构建项目maven下载配置这里不再叙述，请参看：eclipse创建maven多模块项目中有关maven的介绍。好处在于不用自己去添加依赖了，maven自己帮我们加载依赖。 项目结构图： 3、实例源码3.1 生产者package com.kafka.demo; import java.util.Date; import java.util.Properties; import kafka.javaapi.producer.Producer; import kafka.producer.KeyedMessage; import kafka.producer.ProducerConfig; /** * @see https://cwiki.apache.org/confluence/display/KAFKA/0.8.0+Producer+Example * @see http://kafka.apache.org/documentation.html#producerapi * @author wesley * */ public class ProducerDemo { @SuppressWarnings(&quot;deprecation&quot;) public static void main(String[] args) { int events = 20; // @see http://kafka.apache.org/08/configuration.html-- 3.3 Producer // Configs // @see http://kafka.apache.org/documentation.html#producerconfigs // 设置配置属性 Properties props = new Properties(); props.put(&quot;metadata.broker.list&quot;, &quot;127.0.0.1:9092&quot;); // 配置kafka的IP和端口 props.put(&quot;serializer.class&quot;, &quot;kafka.serializer.StringEncoder&quot;); // key.serializer.class默认为serializer.class props.put(&quot;key.serializer.class&quot;, &quot;kafka.serializer.StringEncoder&quot;); // 可选配置，如果不配置，则使用默认的partitioner props.put(&quot;partitioner.class&quot;, &quot;com.kafka.demo.PartitionerDemo&quot;); // 触发acknowledgement机制，否则是fire and forget，可能会引起数据丢失 // 值为0,1,-1,可以参考 props.put(&quot;request.required.acks&quot;, &quot;1&quot;); ProducerConfig config = new ProducerConfig(props); // 创建producer Producer&lt;String, String&gt; producer = new Producer&lt;String, String&gt;(config); // 产生并发送消息 long start = System.currentTimeMillis(); for (long i = 0; i &lt; events; i++) { long runtime = new Date().getTime(); String ip = &quot;192.168.1.&quot; + i; String msg = runtime + &quot;--www.kafkademo.com--&quot; + ip; // 如果topic不存在，则会自动创建，默认replication-factor为1，partitions为0 KeyedMessage&lt;String, String&gt; data = new KeyedMessage&lt;String, String&gt;(&quot;page_visits&quot;, ip, msg); System.out.println(&quot;-----Kafka Producer----createMessage----&quot; + data); producer.send(data); } System.out.println(&quot;Time consuming:&quot; + (System.currentTimeMillis() - start)); // 关闭producer producer.close(); } } 3.2 生产者需要配置的Partition类package com.kafka.demo; import kafka.producer.Partitioner; import kafka.utils.VerifiableProperties; @SuppressWarnings(&quot;deprecation&quot;) public class PartitionerDemo implements Partitioner { public PartitionerDemo (VerifiableProperties props) { } public int partition(Object key, int a_numPartitions) { int partition = 0; String stringKey = (String) key; int offset = stringKey.lastIndexOf(&apos;.&apos;); if (offset &gt; 0) { partition = Integer.parseInt( stringKey.substring(offset+1)) % a_numPartitions; } return partition; } } 运行之后的效果： 查看控制台： 红色部分就是新生成的待消费的信息。 3.3 消费者(单线程实例)package com.kafka.demo; import java.util.HashMap; import java.util.List; import java.util.Map; import java.util.Properties; import kafka.consumer.ConsumerConfig; import kafka.consumer.ConsumerIterator; import kafka.consumer.KafkaStream; import kafka.javaapi.consumer.ConsumerConnector; /** * @see http://kafka.apache.org/documentation.html#consumerapi * @see https://cwiki.apache.org/confluence/display/KAFKA/Consumer+Group+Example * @see https://cwiki.apache.org/confluence/display/KAFKA/0.8.0+SimpleConsumer+Example * @author wesley * */ public class ConsumerSimpleDemo extends Thread { // 消费者连接 private final ConsumerConnector consumer; // 要消费的话题 private final String topic; public ConsumerSimpleDemo(String topic) { consumer = kafka.consumer.Consumer.createJavaConsumerConnector(createConsumerConfig()); this.topic = topic; } // 配置相关信息 private static ConsumerConfig createConsumerConfig() { Properties props = new Properties(); // props.put(&quot;zookeeper.connect&quot;,&quot;localhost:2181,10.XX.XX.XX:2181,10.XX.XX.XX:2181&quot;); // 配置要连接的zookeeper地址与端口 props.put(&quot;zookeeper.connect&quot;, &quot;127.0.0.1:2181&quot;); // 配置zookeeper的组id props.put(&quot;group.id&quot;, &quot;group-1&quot;); // 配置zookeeper连接超时间隔 props.put(&quot;zookeeper.session.timeout.ms&quot;, &quot;10000&quot;); // 配置zookeeper异步执行时间 props.put(&quot;zookeeper.sync.time.ms&quot;, &quot;200&quot;); // 配置自动提交时间间隔 props.put(&quot;auto.commit.interval.ms&quot;, &quot;1000&quot;); return new ConsumerConfig(props); } public void run() { Map&lt;String, Integer&gt; topickMap = new HashMap&lt;String, Integer&gt;(); topickMap.put(topic, 1); Map&lt;String, List&lt;KafkaStream&lt;byte[], byte[]&gt;&gt;&gt; streamMap = consumer.createMessageStreams(topickMap); KafkaStream&lt;byte[], byte[]&gt; stream = streamMap.get(topic).get(0); ConsumerIterator&lt;byte[], byte[]&gt; it = stream.iterator(); System.out.println(&quot;*********Results********&quot;); while (true) { if (it.hasNext()) { // 打印得到的消息 System.err.println(Thread.currentThread() + &quot; get data:&quot; + new String(it.next().message())); } try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } } } public static void main(String[] args) { ConsumerSimpleDemo consumerThread = new ConsumerSimpleDemo(&quot;page_visits&quot;); consumerThread.start(); } } 运行之后的效果： 3.4 消费者(线程池实例)package com.kafka.demo; import java.util.HashMap; import java.util.List; import java.util.Map; import java.util.Properties; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; import java.util.concurrent.TimeUnit; import kafka.consumer.Consumer; import kafka.consumer.ConsumerConfig; import kafka.consumer.KafkaStream; import kafka.javaapi.consumer.ConsumerConnector; /* https://cwiki.apache.org/confluence/display/KAFKA/Consumer+Group+Example * http://kafka.apache.org/documentation.html#consumerapi */ public class ConsumerDemo { private final ConsumerConnector consumer; private final String topic; private ExecutorService executor; public ConsumerDemo(String a_zookeeper, String a_groupId, String a_topic) { consumer = Consumer.createJavaConsumerConnector(createConsumerConfig(a_zookeeper,a_groupId)); this.topic = a_topic; } public void shutdown() { if (consumer != null) consumer.shutdown(); if (executor != null) executor.shutdown(); try { if (!executor.awaitTermination(5000, TimeUnit.MILLISECONDS)) { System.out.println(&quot;Timed out waiting for consumer threads to shut down, exiting uncleanly&quot;); } } catch (InterruptedException e) { System.out.println(&quot;Interrupted during shutdown, exiting uncleanly&quot;); } } public void run(int numThreads) { System.out.println(&quot;-----Consumers begin to execute-------&quot;); Map&lt;String, Integer&gt; topicCountMap = new HashMap&lt;String, Integer&gt;(); topicCountMap.put(topic, new Integer(numThreads)); Map&lt;String, List&lt;KafkaStream&lt;byte[], byte[]&gt;&gt;&gt; consumerMap = consumer .createMessageStreams(topicCountMap); List&lt;KafkaStream&lt;byte[], byte[]&gt;&gt; streams = consumerMap.get(topic); System.err.println(&quot;-----Need to consume content----&quot;+streams); // now launch all the threads executor = Executors.newFixedThreadPool(numThreads); // now create an object to consume the messages int threadNumber = 0; for (final KafkaStream&lt;byte[], byte[]&gt; stream : streams) { System.out.println(&quot;-----Consumers begin to consume-------&quot;+stream); executor.submit(new ConsumerMsgTask(stream, threadNumber)); threadNumber++; } } private static ConsumerConfig createConsumerConfig(String a_zookeeper, String a_groupId) { Properties props = new Properties(); // see http://kafka.apache.org/08/configuration.html --3.2 Consumer Configs // http://kafka.apache.org/documentation.html#consumerconfigs props.put(&quot;zookeeper.connect&quot;, a_zookeeper); //配置ZK地址 props.put(&quot;group.id&quot;, a_groupId); //必填字段 props.put(&quot;zookeeper.session.timeout.ms&quot;, &quot;400&quot;); props.put(&quot;zookeeper.sync.time.ms&quot;, &quot;200&quot;); props.put(&quot;auto.commit.interval.ms&quot;, &quot;1000&quot;); return new ConsumerConfig(props); } public static void main(String[] arg) { String[] args = { &quot;127.0.0.1:2181&quot;, &quot;group-1&quot;, &quot;page_visits&quot;, &quot;10&quot; }; String zooKeeper = args[0]; String groupId = args[1]; String topic = args[2]; int threads = Integer.parseInt(args[3]); ConsumerDemo demo = new ConsumerDemo(zooKeeper, groupId, topic); demo.run(threads); try { Thread.sleep(10000); } catch (InterruptedException ie) { } demo.shutdown(); } } 注意：这里要调用处理消息的类 3.5 处理消息的类package com.kafka.demo; import kafka.consumer.ConsumerIterator; import kafka.consumer.KafkaStream; public class ConsumerMsgTask implements Runnable { private KafkaStream&lt;byte[], byte[]&gt; m_stream; private int m_threadNumber; public ConsumerMsgTask(KafkaStream&lt;byte[], byte[]&gt; stream, int threadNumber) { m_threadNumber = threadNumber; m_stream = stream; } public void run() { System.out.println(&quot;-----Consumers begin to consume-------&quot;); ConsumerIterator&lt;byte[], byte[]&gt; it = m_stream.iterator(); while (it.hasNext()){ System.out.println(&quot;Thread &quot; + m_threadNumber + &quot;: &quot;+ new String(it.next().message())); } System.out.println(&quot;Shutting down Thread: &quot; + m_threadNumber); } } 运行效果图： 实例到此结束，大家可以多看看kafka的文档，多了解一些kafka的知识，这里只是演示了怎么用，其实也都是文档中的东西，自己总结了一下。 说明： 为什么使用High Level Consumer？ 有些场景下，从Kafka中读取消息的逻辑不处理消息的offset，仅仅是获取消息数据。High Level Consumer就提供了这种功能。首先要知道的是，High Level Consumer在ZooKeeper上保存最新的offset（从指定的分区中读取）。这个offset基于consumer group名存储。Consumer group名在Kafka集群上是全局性的，在启动新的consumer group的时候要小心集群上没有关闭的consumer。当一个consumer线程启动了，Kafka会将它加入到相同的topic下的相同consumer group里，并且触发重新分配。在重新分配时，Kafka将partition分配给consumer，有可能会移动一个partition给另一个consumer。如果老的、新的处理逻辑同时存在，有可能一些消息传递到了老的consumer上。使用High LevelConsumer首先要知道的是，它应该是多线程的。消费者线程的数量跟tipic的partition数量有关，它们之间有一些特定的规则： 如果线程数量大于主题的分区数量，一些线程将得不到任何消息 如果分区数大于线程数，一些线程将得到多个分区的消息 如果一个线程处理多个分区的消息，它接收到消息的顺序是不能保证的。比如，先从分区10获取了5条消息，从分区11获取了6条消息，然后从分区10获取了5条，紧接着又从分区10获取了5条，虽然分区11还有消息。 添加更多了同consumer group的consumer将触发Kafka重新分配，某个分区本来分配给a线程的，从新分配后，有可能分配给了b线程。 4、参考资料： http://kafka.apache.org/documentation.html https://cwiki.apache.org/confluence/display/KAFKA/Index","categories":[{"name":"kafka","slug":"kafka","permalink":"http://zhengweishan.oschina.io/categories/kafka/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"http://zhengweishan.oschina.io/tags/kafka/"}]},{"title":"kafka学习(一) ---- 基本概念以及环境搭建","slug":"kafka学习(一) ---- 基本概念以及环境搭建","date":"2017-01-31T16:00:00.000Z","updated":"2017-03-01T08:44:51.568Z","comments":true,"path":"2017/02/01/kafka学习(一) ---- 基本概念以及环境搭建/","link":"","permalink":"http://zhengweishan.oschina.io/2017/02/01/kafka学习(一) ---- 基本概念以及环境搭建/","excerpt":"前言由于项目涉及到kafka，自己以前没有接触过这方面的，学习了下，将搭建kafka运行环境同大家分享(单机搭建的Windows下的运行环境，Linux下的由于懒得装虚拟机就没有搭建，以后有时间在分享一次，搭建这个环境就是只为了学习)。 1、基本概念1.1 什么是kafka Apache Kafka is publish-subscribe messaging rethought as a distributed commit log。Kafka is a distributed, partitioned, replicated commit log service. It provides the functionality of a messaging system, but with a unique design.//官方解释 Kafka是一种高吞吐量的分布式发布订阅消息系统，它提供了类似于JMS的特性，但是在设计实现上完全不同，此外它并不是JMS规范的实现。kafka对消息保存时根据Topic进行归类，发送消息者成为Producer,消息接受者成为Consumer,此外kafka集群有多个kafka实例组成，每个实例(server)成为broker。无论是kafka集群，还是producer和consumer都依赖于zookeeper来保证系统可用性集群保存一些meta信息。整体运行机制如下图： 图来源于官网 更多内容请参看：官方文档，这里就不一一翻译了。","text":"前言由于项目涉及到kafka，自己以前没有接触过这方面的，学习了下，将搭建kafka运行环境同大家分享(单机搭建的Windows下的运行环境，Linux下的由于懒得装虚拟机就没有搭建，以后有时间在分享一次，搭建这个环境就是只为了学习)。 1、基本概念1.1 什么是kafka Apache Kafka is publish-subscribe messaging rethought as a distributed commit log。Kafka is a distributed, partitioned, replicated commit log service. It provides the functionality of a messaging system, but with a unique design.//官方解释 Kafka是一种高吞吐量的分布式发布订阅消息系统，它提供了类似于JMS的特性，但是在设计实现上完全不同，此外它并不是JMS规范的实现。kafka对消息保存时根据Topic进行归类，发送消息者成为Producer,消息接受者成为Consumer,此外kafka集群有多个kafka实例组成，每个实例(server)成为broker。无论是kafka集群，还是producer和consumer都依赖于zookeeper来保证系统可用性集群保存一些meta信息。整体运行机制如下图： 图来源于官网 更多内容请参看：官方文档，这里就不一一翻译了。 1.2 kafka的特点 通过I/O的磁盘数据结构提供消息的持久化，这种结构对于即使数以TB的消息存储也能够保持长时间的稳定性能。 高吞吐量：即使是非常普通的硬件Kafka也可以支持每秒数百万的消息。 支持通过Kafka服务器和消费机集群来分区消息。 支持Hadoop并行数据加载1.3 涉及的术语 BrokerKafka集群包含一个或多个服务器，这种服务器被称为broker Topic每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处） PartitionPartition是物理上的概念，每个Topic包含一个或多个Partition. Producer负责发布消息到Kafka broker Consumer消息消费者，向Kafka broker读取消息的客户端。 Consumer Group每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group） 2、环境搭建2.1 下载下载地址：http://kafka.apache.org/downloads.html 2.2 单机搭建win下的运行环境官网没有win版本的，下载之后直接按照Linux下解压缩一样，解压之后文件结构如下： 2.2.1 配置kafka 进入Kafka配置目录：S:\\devTools\\kafka_2.11-0.10.0.0\\config 编辑文件“server.properties” 主要配置日志所在目录（也可以使用默认的） 找到并编辑“log.dirs=/tmp/kafka-logs” to “log.dirs= S:/devTools/kafka_2.11-0.10.0.0/kafka-logs” 如果Zookeeper在某些其他的机器或集群上运行，可以将“zookeeper.connect:2181”修改为自定义IP与端口。在这个演示中我们使用了同一个机器，因此没必要做修改。文件中的Kafka端口和broker.id也是可以配置的。其他设置不变。 Kafka会按照默认在9092端口上运行，并连接zookeeper的默认端口：2181。 2.2.2 运行kafka 重要：请确保在启动Kafka服务器前，Zookeeper实例已经准备好并开始运行。 Zookeeper如何安装运行请参看我的博客：Dubbo与Zookeeper、SpringMVC整合和使用中有关Zookeeper的介绍。 kafka在win下的启动命令都在bin目录下的Windows文件下，如下图： 不知道是不是win脚本问题，直接运行这些命令都是失败的启动不了kafka,没有办法还是cmd启动吧。 进入Kafka安装目录S:\\devTools\\kafka_2.11-0.10.0.0\\ 按下Shift+右键，选择“打开命令窗口”选项，打开命令行。 现在输入.\\bin\\windows\\kafka-server-start.bat .\\config\\server.properties 并回车。 如果一切正常，命令行应当是这样： 现在Kafka已经准备好并开始运行，可以创建主题来存储消息了。我们也能从Java/Scala代码中，或直接从命令行中生成或使用数据。 2.2.3 创建主题 现在创建主题，命名为“demo”，replication factor=1（因为只有1个Kafka服务器在运行）。如果集群中所运行的Kafka服务器不止1个，可以相应增加replication-factor，从而提高数据可用性和系统容错性。 在S:\\devTools\\kafka_2.11-0.10.0.0\\bin\\windows打开新的命令行。 输入下面的命令，回车： kafka-topics.bat –create –zookeeper localhost:2181 –replication-factor 1 –partitions 1 –topic demo 结果如下： 2.2.4 创建生产者 在S:\\devTools\\kafka_2.11-0.10.0.0\\bin\\windows打开新的命令行。 输入下面的命令，回车： kafka-console-producer.bat –broker-list localhost:9092 –topic demo 2.2.5 创建消费者 在S:\\devTools\\kafka_2.11-0.10.0.0\\bin\\windows打开新的命令行。 输入下面的命令，回车： kafka-console-consumer.bat –zookeeper localhost:2181 –topic demo 2.2.6 演示执行以上的命令之后有两个窗口：一个生产者，一个消费者。在producer命令行中任意输入内容，回车；在其他consumer命令行中能看到相应消息。如果能够将消息推送到consumer端并显示出来的话，Kafka安装就完成了。 最后上个成功的截图： 2.3 常用的命令 列出主题：kafka-topics.bat –-list –-zookeeper localhost:2181 描述主题：kafka-topics.bat –-describe –-zookeeper localhost:2181 –-topic [Topic Name] 从头读取消息：kafka-console-consumer.bat –-zookeeper localhost:2181 –-topic [Topic Name] –-from –beginning 删除主题：kafka-run-class.bat kafka.admin.TopicCommand –-delete –-topic [topic_to_delete] –-zookeeper localhost:2181 演示一个删除的：","categories":[{"name":"kafka","slug":"kafka","permalink":"http://zhengweishan.oschina.io/categories/kafka/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"http://zhengweishan.oschina.io/tags/kafka/"}]},{"title":"JMS学习（四）-----Spring和ActiveMQ整合的完整实例","slug":"JMS学习（四）Spring和ActiveMQ整合的完整实例","date":"2017-01-24T16:00:00.000Z","updated":"2017-03-01T08:40:05.554Z","comments":true,"path":"2017/01/25/JMS学习（四）Spring和ActiveMQ整合的完整实例/","link":"","permalink":"http://zhengweishan.oschina.io/2017/01/25/JMS学习（四）Spring和ActiveMQ整合的完整实例/","excerpt":"1、前言我们基于Spring+JMS+ActiveMQ+Tomcat，做一个Spring4.2.6和ActiveMQ5.7.0整合实例，实现了Point-To-Point的异步队列消息和PUB/SUB（发布/订阅）模型，简单实例，不包含任何业务。 项目结构","text":"1、前言我们基于Spring+JMS+ActiveMQ+Tomcat，做一个Spring4.2.6和ActiveMQ5.7.0整合实例，实现了Point-To-Point的异步队列消息和PUB/SUB（发布/订阅）模型，简单实例，不包含任何业务。 项目结构 2、配置文件2.1 pom.xml&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.activemq.demo&lt;/groupId&gt; &lt;artifactId&gt;SpringActiveMq&lt;/artifactId&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;SpringActiveMq Maven Webapp&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;org.springframework.version&gt;4.2.6.RELEASE&lt;/org.springframework.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;${org.springframework.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;version&gt;${org.springframework.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;${org.springframework.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;${org.springframework.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;${org.springframework.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- activeMQ与spring整合所需要的包 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jms&lt;/artifactId&gt; &lt;version&gt;${org.springframework.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- activeMQ --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-core&lt;/artifactId&gt; &lt;version&gt;5.7.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.xbean&lt;/groupId&gt; &lt;artifactId&gt;xbean-spring&lt;/artifactId&gt; &lt;version&gt;4.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.codehaus.jackson&lt;/groupId&gt; &lt;artifactId&gt;jackson-core-asl&lt;/artifactId&gt; &lt;version&gt;1.9.12&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.codehaus.jackson&lt;/groupId&gt; &lt;artifactId&gt;jackson-mapper-asl&lt;/artifactId&gt; &lt;version&gt;1.9.12&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;net.sf.json-lib&lt;/groupId&gt; &lt;artifactId&gt;json-lib&lt;/artifactId&gt; &lt;version&gt;2.4&lt;/version&gt; &lt;classifier&gt;jdk15&lt;/classifier&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-core&lt;/artifactId&gt; &lt;version&gt;2.4.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.4.3&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;SpringActiveMq&lt;/finalName&gt; &lt;/build&gt; &lt;/project&gt; 2.2 spring-activeMQ.xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:amq=&quot;http://activemq.apache.org/schema/core&quot; xmlns:jms=&quot;http://www.springframework.org/schema/jms&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd http://www.springframework.org/schema/jms http://www.springframework.org/schema/jms/spring-jms-4.0.xsd http://activemq.apache.org/schema/core http://activemq.apache.org/schema/core/activemq-core-5.7.0.xsd&quot;&gt; &lt;!-- 真正可以产生Connection的ConnectionFactory，由对应的 JMS服务厂商提供 --&gt; &lt;bean id=&quot;targetConnectionFactory&quot; class=&quot;org.apache.activemq.ActiveMQConnectionFactory&quot;&gt; &lt;property name=&quot;brokerURL&quot; value=&quot;tcp://localhost:61616&quot; /&gt; &lt;/bean&gt; &lt;!-- Spring用于管理真正的ConnectionFactory的ConnectionFactory --&gt; &lt;bean id=&quot;connectionFactory&quot; class=&quot;org.springframework.jms.connection.CachingConnectionFactory&quot;&gt; &lt;!-- 目标ConnectionFactory对应真实的可以产生JMS Connection的pooledConnectionFactory --&gt; &lt;property name=&quot;targetConnectionFactory&quot; ref=&quot;targetConnectionFactory&quot; /&gt; &lt;property name=&quot;sessionCacheSize&quot; value=&quot;100&quot; /&gt; &lt;/bean&gt; &lt;!-- Spring提供的JMS工具类，它可以进行消息发送、接收等 --&gt; &lt;bean id=&quot;jmsTemplate&quot; class=&quot;org.springframework.jms.core.JmsTemplate&quot;&gt; &lt;!-- 这个connectionFactory对应的是我们定义的Spring提供的那个ConnectionFactory对象 --&gt; &lt;property name=&quot;connectionFactory&quot; ref=&quot;connectionFactory&quot; /&gt; &lt;!-- 非pub/sub模型（发布/订阅），即队列模式 --&gt; &lt;property name=&quot;pubSubDomain&quot; value=&quot;false&quot; /&gt; &lt;/bean&gt; &lt;!--这个是队列目的地，点对点的 --&gt; &lt;bean id=&quot;queueDestination&quot; class=&quot;org.apache.activemq.command.ActiveMQQueue&quot;&gt; &lt;constructor-arg&gt; &lt;value&gt;queue&lt;/value&gt; &lt;/constructor-arg&gt; &lt;/bean&gt; &lt;!--这个是主题目的地，一对多的 --&gt; &lt;bean id=&quot;topicDestination&quot; class=&quot;org.apache.activemq.command.ActiveMQTopic&quot;&gt; &lt;constructor-arg value=&quot;topic&quot; /&gt; &lt;/bean&gt; &lt;!-- 消息监听器 --&gt; &lt;bean id=&quot;consumerMessageListener&quot; class=&quot;com.activemq.demo.ConsumerMessageListener&quot; /&gt; &lt;!-- 消息监听容器 --&gt; &lt;bean id=&quot;jmsContainer&quot; class=&quot;org.springframework.jms.listener.DefaultMessageListenerContainer&quot;&gt; &lt;property name=&quot;connectionFactory&quot; ref=&quot;connectionFactory&quot; /&gt; &lt;property name=&quot;destination&quot; ref=&quot;queueDestination&quot; /&gt; &lt;property name=&quot;messageListener&quot; ref=&quot;consumerMessageListener&quot; /&gt; &lt;/bean&gt; &lt;/beans&gt; 2.3 servlet-context.xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:task=&quot;http://www.springframework.org/schema/task&quot; xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd http://www.springframework.org/schema/task http://www.springframework.org/schema/task/spring-task-4.0.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd&quot; default-lazy-init=&quot;false&quot;&gt; &lt;mvc:annotation-driven &gt; &lt;!-- 消息转换器 --&gt; &lt;mvc:message-converters register-defaults=&quot;true&quot;&gt; &lt;bean class=&quot;org.springframework.http.converter.StringHttpMessageConverter&quot;&gt; &lt;property name=&quot;supportedMediaTypes&quot; value=&quot;text/html;charset=UTF-8&quot;/&gt; &lt;/bean&gt; &lt;bean class=&quot;org.springframework.http.converter.json.MappingJackson2HttpMessageConverter&quot;&gt; &lt;property name=&quot;supportedMediaTypes&quot;&gt; &lt;list&gt; &lt;value&gt;text/html; charset=UTF-8&lt;/value&gt; &lt;value&gt;application/json;charset=UTF-8&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/mvc:message-converters&gt; &lt;/mvc:annotation-driven&gt; &lt;!-- 静态资源 --&gt; &lt;mvc:resources mapping=&quot;/resources/**&quot; location=&quot;/resources/&quot;/&gt; &lt;!-- 中文乱码解决 --&gt; &lt;bean class=&quot;org.springframework.web.servlet.mvc.annotation.AnnotationMethodHandlerAdapter&quot; &gt; &lt;property name=&quot;messageConverters&quot;&gt; &lt;list&gt; &lt;bean class = &quot;org.springframework.http.converter.StringHttpMessageConverter&quot;&gt; &lt;property name = &quot;supportedMediaTypes&quot;&gt; &lt;list&gt; &lt;value&gt;text/plain;charset=UTF-8&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;context:component-scan base-package=&quot;com.activemq.demo&quot;/&gt; &lt;/beans&gt; 2.4 web.xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;!DOCTYPE web-app PUBLIC &quot;-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN&quot; &quot;http://java.sun.com/dtd/web-app_2_3.dtd&quot;&gt; &lt;web-app&gt; &lt;display-name&gt;dubbo_consumer&lt;/display-name&gt; &lt;description&gt;dubbo_consumer test&lt;/description&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt; classpath*:spring-activeMQ.xml &lt;/param-value&gt; &lt;/context-param&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;servlet&gt; &lt;servlet-name&gt;appServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath*:servlet-context.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;appServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;/web-app&gt; 3、部署运行部署之后访问：http://localhost:8081/SpringActiveMq/test/sendMessage，效果如下： ActiveMq控制台： 4、spring-activeMQ.xml解析4.1 配置ConnectionFactoryconnectionFactory是Spring用于创建到JMS服务器链接的，Spring提供了多种connectionFactory，我们介绍两个SingleConnectionFactory和CachingConnectionFactory。 SingleConnectionFactory：对于建立JMS服务器链接的请求会一直返回同一个链接，并且会忽略Connection的close方法调用。 CachingConnectionFactory：继承了SingleConnectionFactory，所以它拥有SingleConnectionFactory的所有功能，同时它还新增了缓存功能，它可以缓存Session、MessageProducer和MessageConsumer。我们使用CachingConnectionFactory来作为示例。 Spring提供的ConnectionFactory只是Spring用于管理ConnectionFactory的，真正产生到JMS服务器链接的ConnectionFactory还得是由JMS服务厂商提供，并且需要把它注入到Spring提供的ConnectionFactory中。我们这里使用的是ActiveMQ实现的JMS，所以在我们这里真正的可以产生Connection的就应该是由ActiveMQ提供的ConnectionFactory。所以定义一个ConnectionFactory的完整代码应该如下所示： &lt;!-- 连接池 --&gt; &lt;bean id=&quot;pooledConnectionFactory&quot; class=&quot;org.apache.activemq.pool.PooledConnectionFactory&quot; destroy-method=&quot;stop&quot;&gt; &lt;property name=&quot;connectionFactory&quot;&gt; &lt;bean class=&quot;org.apache.activemq.ActiveMQConnectionFactory&quot;&gt; &lt;property name=&quot;brokerURL&quot; value=&quot;tcp://localhost:61616&quot; /&gt; &lt;/bean&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- 真正可以产生Connection的ConnectionFactory，由对应的 JMS服务厂商提供 --&gt; &lt;!-- 如果连接网络：tcp://ip:61616；未连接网络：tcp://localhost:61616--&gt; &lt;bean id=&quot;targetConnectionFactory&quot; class=&quot;org.apache.activemq.ActiveMQConnectionFactory&quot;&gt; &lt;property name=&quot;brokerURL&quot; value=&quot;tcp://localhost:61616&quot; /&gt; &lt;/bean&gt; &lt;!-- Spring用于管理真正的ConnectionFactory的ConnectionFactory --&gt; &lt;bean id=&quot;connectionFactory&quot; class=&quot;org.springframework.jms.connection.CachingConnectionFactory&quot;&gt; &lt;!-- 目标ConnectionFactory对应真实的可以产生JMS Connection的pooledConnectionFactory --&gt; &lt;property name=&quot;targetConnectionFactory&quot; ref=&quot;targetConnectionFactory&quot; /&gt; &lt;property name=&quot;sessionCacheSize&quot; value=&quot;100&quot; /&gt; &lt;/bean&gt; 或者这样配置： &lt;!-- ActiveMQ 连接工厂 --&gt; &lt;!-- 真正可以产生Connection的ConnectionFactory，由对应的 JMS服务厂商提供--&gt; &lt;!-- 如果连接网络：tcp://ip:61616；未连接网络：tcp://localhost:61616 以及用户名，密码--&gt; &lt;amq:connectionFactory id=&quot;amqConnectionFactory&quot; brokerURL=&quot;tcp://192.168.3.3:61616&quot; userName=&quot;admin&quot; password=&quot;admin&quot; /&gt; &lt;!-- Spring Caching连接工厂 --&gt; &lt;!-- Spring用于管理真正的ConnectionFactory的ConnectionFactory --&gt; &lt;bean id=&quot;connectionFactory&quot; class=&quot;org.springframework.jms.connection.CachingConnectionFactory&quot;&gt; &lt;!-- 目标ConnectionFactory对应真实的可以产生JMS Connection的ConnectionFactory --&gt; &lt;property name=&quot;targetConnectionFactory&quot; ref=&quot;amqConnectionFactory&quot;&gt;&lt;/property&gt; &lt;!-- 同上，同理 --&gt; &lt;!-- &lt;constructor-arg ref=&quot;amqConnectionFactory&quot; /&gt; --&gt; &lt;!-- Session缓存数量 --&gt; &lt;property name=&quot;sessionCacheSize&quot; value=&quot;100&quot; /&gt; &lt;/bean&gt; 4.2 配置生产者配置好ConnectionFactory之后我们就需要配置生产者。生产者负责产生消息并发送到JMS服务器。但是我们要怎么进行消息发送呢？通常是利用Spring为我们提供的JmsTemplate类来实现的，所以配置生产者其实最核心的就是配置消息发送的JmsTemplate。对于消息发送者而言，它在发送消息的时候要知道自己该往哪里发，为此，我们在定义JmsTemplate的时候需要注入一个Spring提供的ConnectionFactory对象。 在利用JmsTemplate进行消息发送的时候，我们需要知道发送哪种消息类型：一个是点对点的ActiveMQQueue，另一个就是支持订阅/发布模式的ActiveMQTopic。如下所示： &lt;!-- Spring提供的JMS工具类，它可以进行消息发送、接收等 --&gt; &lt;bean id=&quot;jmsTemplate&quot; class=&quot;org.springframework.jms.core.JmsTemplate&quot;&gt; &lt;!-- 这个connectionFactory对应的是我们定义的Spring提供的那个ConnectionFactory对象 --&gt; &lt;property name=&quot;connectionFactory&quot; ref=&quot;connectionFactory&quot; /&gt; &lt;!-- 非pub/sub模型（发布/订阅），即队列模式 如果value是true pub/sub模型（发布/订阅） --&gt; &lt;property name=&quot;pubSubDomain&quot; value=&quot;false&quot; /&gt; &lt;/bean&gt; 4.3 配置消费者生产者往指定目的地Destination发送消息后，接下来就是消费者对指定目的地的消息进行消费了。那么消费者是如何知道有生产者发送消息到指定目的地Destination了呢？每个消费者对应每个目的地都需要有对应的MessageListenerContainer。对于消息监听容器而言，除了要知道监听哪个目的地之外，还需要知道到哪里去监听，也就是说它还需要知道去监听哪个JMS服务器，通过配置MessageListenerContainer的时候往里面注入一个ConnectionFactory来实现的。所以我们在配置一个MessageListenerContainer的时候有三个属性必须指定：一个是表示从哪里监听的ConnectionFactory；一个是表示监听什么的Destination；一个是接收到消息以后进行消息处理的MessageListener。 &lt;!-- 消息监听器 --&gt; &lt;bean id=&quot;consumerMessageListener&quot; class=&quot;com.activemq.demo.ConsumerMessageListener&quot; /&gt; &lt;!-- 消息监听容器 --&gt; &lt;bean id=&quot;jmsContainer&quot; class=&quot;org.springframework.jms.listener.DefaultMessageListenerContainer&quot;&gt; &lt;property name=&quot;connectionFactory&quot; ref=&quot;connectionFactory&quot; /&gt; &lt;property name=&quot;destination&quot; ref=&quot;queueDestination&quot; /&gt; &lt;property name=&quot;messageListener&quot; ref=&quot;consumerMessageListener&quot; /&gt; &lt;/bean&gt; 5、总结Spring提供了对JMS的支持，ActiveMQ提供了很好的实现，而此时我们已经将两者完美的结合在了一起。","categories":[{"name":"JMS","slug":"JMS","permalink":"http://zhengweishan.oschina.io/categories/JMS/"}],"tags":[{"name":"JMS","slug":"JMS","permalink":"http://zhengweishan.oschina.io/tags/JMS/"},{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"http://zhengweishan.oschina.io/tags/ActiveMQ/"}]},{"title":"JMS学习（三）----- ActiveMQ简单的HelloWorld实例","slug":"JMS学习（三）ActiveMQ简单的HelloWorld实例","date":"2017-01-23T16:00:00.000Z","updated":"2017-03-01T08:40:01.239Z","comments":true,"path":"2017/01/24/JMS学习（三）ActiveMQ简单的HelloWorld实例/","link":"","permalink":"http://zhengweishan.oschina.io/2017/01/24/JMS学习（三）ActiveMQ简单的HelloWorld实例/","excerpt":"开发环境我使用的是ActiveMQ 5.13.3 Release的Windows版，官网最新版是ActiveMQ 5.13.4 Release，大家可以自行下载，下载地址。 需要注意的是，开发时候，要将apache-activemq-5.13.3-bin.zip解压缩后里面的activemq-all-5.13.3.jar包加入到classpath下面，这个包包含了所有jms接口api的实现。 项目截图： ActiviteMQ消息有3中形式JMS 公共 ———-点对点域 ———-发布/订阅域 ConnectionFactory ———- QueueConnectionFactory ———- TopicConnectionFactory Connection ———- QueueConnection ———- TopicConnection Destination ———- Queue ———- Topic Session ———- QueueSession ———- TopicSession MessageProducer ———- QueueSender ———- TopicPublisher MessageConsumer ———- QueueReceiver ———- TopicSubscriber (1)、点对点方式（point-to-point） 点对点的消息发送方式主要建立在 Message Queue,Sender,reciever上，Message Queue 存贮消息，Sneder 发送消息，receive接收消息.具体点就是Sender Client发送Message Queue ,而 receiver Cliernt从Queue中接收消息和”发送消息已接受”到Quere,确认消息接收。消息发送客户端与接收客户端没有时间上的依赖，发送客户端可以在任何时刻发送信息到Queue，而不需要知道接收客户端是不是在运行 (2)、发布/订阅 方式（publish/subscriber Messaging） 发布/订阅方式用于多接收客户端的方式.作为发布订阅的方式，可能存在多个接收客户端，并且接收端客户端与发送客户端存在时间上的依赖。一个接收端只能接收他创建以后发送客户端发送的信息。作为subscriber ,在接收消息时有两种方法，destination的receive方法，和实现message listener 接口的onMessage 方法。","text":"开发环境我使用的是ActiveMQ 5.13.3 Release的Windows版，官网最新版是ActiveMQ 5.13.4 Release，大家可以自行下载，下载地址。 需要注意的是，开发时候，要将apache-activemq-5.13.3-bin.zip解压缩后里面的activemq-all-5.13.3.jar包加入到classpath下面，这个包包含了所有jms接口api的实现。 项目截图： ActiviteMQ消息有3中形式JMS 公共 ———-点对点域 ———-发布/订阅域 ConnectionFactory ———- QueueConnectionFactory ———- TopicConnectionFactory Connection ———- QueueConnection ———- TopicConnection Destination ———- Queue ———- Topic Session ———- QueueSession ———- TopicSession MessageProducer ———- QueueSender ———- TopicPublisher MessageConsumer ———- QueueReceiver ———- TopicSubscriber (1)、点对点方式（point-to-point） 点对点的消息发送方式主要建立在 Message Queue,Sender,reciever上，Message Queue 存贮消息，Sneder 发送消息，receive接收消息.具体点就是Sender Client发送Message Queue ,而 receiver Cliernt从Queue中接收消息和”发送消息已接受”到Quere,确认消息接收。消息发送客户端与接收客户端没有时间上的依赖，发送客户端可以在任何时刻发送信息到Queue，而不需要知道接收客户端是不是在运行 (2)、发布/订阅 方式（publish/subscriber Messaging） 发布/订阅方式用于多接收客户端的方式.作为发布订阅的方式，可能存在多个接收客户端，并且接收端客户端与发送客户端存在时间上的依赖。一个接收端只能接收他创建以后发送客户端发送的信息。作为subscriber ,在接收消息时有两种方法，destination的receive方法，和实现message listener 接口的onMessage 方法。 ActiviteMQ接收和发送消息基本流程 发送消息的基本步骤： (1)、创建连接使用的工厂类JMS ConnectionFactory (2)、使用管理对象JMS ConnectionFactory建立连接Connection，并启动 (3)、使用连接Connection 建立会话Session (4)、使用会话Session和管理对象Destination创建消息生产者MessageSender (5)、使用消息生产者MessageSender发送消息 消息接收者从JMS接受消息的步骤 (1)、创建连接使用的工厂类JMS ConnectionFactory (2)、使用管理对象JMS ConnectionFactory建立连接Connection，并启动 (3)、使用连接Connection 建立会话Session (4)、使用会话Session和管理对象Destination创建消息接收者MessageReceiver (5)、使用消息接收者MessageReceiver接受消息，需要用setMessageListener将MessageListener接口绑定到MessageReceiver消息接收者必须实现了MessageListener接口，需要定义onMessage事件方法。 使用JMS方式发送接收消息package com.active.mq.demo; import javax.jms.Connection; import javax.jms.ConnectionFactory; import javax.jms.JMSException; import org.apache.activemq.ActiveMQConnection; import org.apache.activemq.ActiveMQConnectionFactory; public class MQConnectionFactory { private static final String USERNAME = ActiveMQConnection.DEFAULT_USER;//默认连接用户名 private static final String PASSWORD = ActiveMQConnection.DEFAULT_PASSWORD;//默认连接密码 private static final String BROKEURL = ActiveMQConnection.DEFAULT_BROKER_URL;//默认连接地址 private static ConnectionFactory connectionFactory = new ActiveMQConnectionFactory(USERNAME, PASSWORD, BROKEURL);//连接工厂 /** * 通过连接工厂获取连接 * @return */ public static Connection getConnection(){ Connection connection = null; try { connection = connectionFactory.createConnection(); } catch (JMSException e) { e.printStackTrace(); } return connection; } } package com.active.mq.demo; import javax.jms.Connection; import javax.jms.Destination; import javax.jms.JMSException; import javax.jms.MessageConsumer; import javax.jms.Session; import javax.jms.TextMessage; public class JMSConsumer { public static void main(String[] args) { Connection connection = null;//连接 Session session = null;//会话 接受或者发送消息的线程 Destination destination;//消息的目的地 MessageConsumer messageConsumer;//消息的消费者 try { //通过连接工厂获取连接 connection = MQConnectionFactory.getConnection(); //启动连接 connection.start(); //创建session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); //创建一个连接HelloWorld的消息队列 destination = session.createQueue(&quot;HelloWorld&quot;); //创建消息消费者 messageConsumer = session.createConsumer(destination); while (true) { TextMessage textMessage = (TextMessage) messageConsumer.receive(100000); if(textMessage != null){ System.out.println(&quot;收到的消息:&quot; + textMessage.getText()); }else { break; } } //提交回话 session.commit(); } catch (JMSException e) { e.printStackTrace(); }finally{ if(connection != null){ try { connection.close(); } catch (JMSException e) { e.printStackTrace(); } } if(session !=null){ try { session.close(); } catch (JMSException e) { e.printStackTrace(); } } } } } package com.active.mq.demo; import javax.jms.Connection; import javax.jms.Destination; import javax.jms.JMSException; import javax.jms.MessageProducer; import javax.jms.Session; import javax.jms.TextMessage; public class JMSProducer { //发送的消息数量 private static final int SENDNUM = 10; public static void main(String[] args) { //连接 Connection connection = null; //会话 接受或者发送消息的线程 Session session = null; //消息的目的地 Destination destination; //消息生产者 MessageProducer messageProducer; try { //通过连接工厂获取连接 connection = MQConnectionFactory.getConnection(); //启动连接 connection.start(); //创建session session = connection.createSession(true, Session.AUTO_ACKNOWLEDGE); //创建一个名称为HelloWorld的消息队列 destination = session.createQueue(&quot;HelloWorld&quot;); //创建消息生产者 messageProducer = session.createProducer(destination); //发送消息 sendMessage(session, messageProducer); //提交回话 session.commit(); } catch (Exception e) { e.printStackTrace(); }finally{ if(connection != null){ try { connection.close(); } catch (JMSException e) { e.printStackTrace(); } } if(session !=null){ try { session.close(); } catch (JMSException e) { e.printStackTrace(); } } } } /** * 发送消息 * @param session * @param messageProducer 消息生产者 * @throws Exception */ public static void sendMessage(Session session,MessageProducer messageProducer) throws Exception{ for (int i = 0; i &lt; JMSProducer.SENDNUM; i++) { //创建一条文本消息 TextMessage message = session.createTextMessage(&quot;发送JMS消息第&quot; + (i + 1) + &quot;条&quot;); System.out.println(&quot;发送消息：Activemq 发送JMS消息&quot; + (i + 1)); //通过消息生产者发出消息 messageProducer.send(message); } } } Queue队列方式发送点对点消息数据在获取工厂类中加入如下代码： private static QueueConnectionFactory queueConnectionFactory = new ActiveMQConnectionFactory(USERNAME, PASSWORD, BROKEURL); /** * 通过连接工厂获取连接(Queue方式) * @return */ public static QueueConnection getQueueConnection(){ QueueConnection connection = null; try { connection = queueConnectionFactory.createQueueConnection(); } catch (JMSException e) { e.printStackTrace(); } return connection; } //消息生产者 package com.active.mq.demo; import javax.jms.DeliveryMode; import javax.jms.JMSException; import javax.jms.MapMessage; import javax.jms.Queue; import javax.jms.QueueConnection; import javax.jms.QueueSender; import javax.jms.QueueSession; import javax.jms.Session; public class QueueProducer { private static final int SEND_NUM = 10; public static void main(String[] args) { QueueConnection queueConnection = null; QueueSession queueSession = null; try { // 通过工厂创建一个连接 queueConnection = MQConnectionFactory.getQueueConnection(); // 启动连接 queueConnection.start(); // 创建一个session会话 queueSession = queueConnection.createQueueSession(Boolean.TRUE, Session.AUTO_ACKNOWLEDGE); // 创建一个消息队列 Queue queue = queueSession.createQueue(&quot;QueueMsgDemo&quot;); // 创建消息发送者 QueueSender sender = queueSession.createSender(queue); // 设置持久化模式 sender.setDeliveryMode(DeliveryMode.NON_PERSISTENT); sendMessage(queueSession, sender); // 提交会话 queueSession.commit(); } catch (Exception e) { e.printStackTrace(); }finally { // 关闭释放资源 if (queueSession != null) { try { queueSession.close(); } catch (JMSException e) { e.printStackTrace(); } } if (queueConnection != null) { try { queueConnection.close(); } catch (JMSException e) { e.printStackTrace(); } } } } public static void sendMessage(QueueSession session, QueueSender sender) throws Exception { for (int i = 0; i &lt; SEND_NUM; i++) { String message = &quot;发送queue消息第&quot; + (i + 1) + &quot;条&quot;; //创建一个Map集合信息 MapMessage map = session.createMapMessage(); map.setString(&quot;text&quot;, message); map.setLong(&quot;time&quot;, System.currentTimeMillis()); System.out.println(&quot;ActiveMQ 发送queue消息：&quot;+(i + 1)); sender.send(map); } } } //消费者 package com.active.mq.demo; import javax.jms.JMSException; import javax.jms.MapMessage; import javax.jms.Message; import javax.jms.MessageListener; import javax.jms.Queue; import javax.jms.QueueConnection; import javax.jms.QueueReceiver; import javax.jms.QueueSession; import javax.jms.Session; public class QueueConsumer { public static void main(String[] args) { QueueConnection queueConnection = null; QueueSession queueSession = null; try { // 通过工厂创建一个连接 queueConnection = MQConnectionFactory.getQueueConnection(); // 启动连接 queueConnection.start(); // 创建一个session会话 queueSession = queueConnection.createQueueSession(Boolean.TRUE, Session.AUTO_ACKNOWLEDGE); // 创建一个消息队列 Queue queue = queueSession.createQueue(&quot;QueueMsgDemo&quot;); // 创建消息接收者 QueueReceiver receiver = queueSession.createReceiver(queue); receiver.setMessageListener(new MessageListener() { public void onMessage(Message msg) { if (msg != null) { MapMessage map = (MapMessage) msg; try { System.out.println(map.getLong(&quot;time&quot;) + &quot;接收到消息#&quot; + map.getString(&quot;text&quot;)); } catch (JMSException e) { e.printStackTrace(); } } } }); // 休眠100ms再关闭 Thread.sleep(1000 * 100); // 提交会话 queueSession.commit(); } catch (Exception e) { e.printStackTrace(); } finally { // 关闭释放资源 if (queueSession != null) { try { queueSession.close(); } catch (JMSException e) { e.printStackTrace(); } } if (queueConnection != null) { try { queueConnection.close(); } catch (JMSException e) { e.printStackTrace(); } } } } } Topic主题发布和订阅消息在获取工厂类中加入如下代码： private static TopicConnectionFactory topicConnectionFactory = new ActiveMQConnectionFactory(USERNAME, PASSWORD, BROKEURL); /** * 通过连接工厂获取连接(Topic方式) * @return */ public static TopicConnection getTopicConnection(){ TopicConnection topicConnection = null; try { topicConnection = topicConnectionFactory.createTopicConnection(); } catch (JMSException e) { e.printStackTrace(); } return topicConnection; } //生产者 package com.active.mq.demo; import javax.jms.DeliveryMode; import javax.jms.JMSException; import javax.jms.MapMessage; import javax.jms.Session; import javax.jms.Topic; import javax.jms.TopicConnection; import javax.jms.TopicPublisher; import javax.jms.TopicSession; public class TopicProducer { private static final int SEND_NUM = 10; public static void main(String[] args) { TopicConnection connection = null; TopicSession session = null; try { // 通过工厂创建一个连接 connection = MQConnectionFactory.getTopicConnection(); // 启动连接 connection.start(); // 创建一个session会话 session = connection.createTopicSession(true, Session.AUTO_ACKNOWLEDGE); // 创建一个消息队列 Topic topic = session.createTopic(&quot;TopicDemo&quot;); // 创建消息发送者 TopicPublisher publisher = session.createPublisher(topic); // 设置持久化模式 publisher.setDeliveryMode(DeliveryMode.NON_PERSISTENT); sendMessage(session, publisher); // 提交会话 session.commit(); } catch (Exception e) { e.printStackTrace(); } finally { // 关闭释放资源 if (session != null) { try { session.close(); } catch (JMSException e) { e.printStackTrace(); } } if (connection != null) { try { connection.close(); } catch (JMSException e) { e.printStackTrace(); } } } } public static void sendMessage(TopicSession session, TopicPublisher publisher) throws Exception { for (int i = 0; i &lt; SEND_NUM; i++) { String message = &quot;发送Topic消息第&quot; + (i + 1) + &quot;条&quot;; MapMessage map = session.createMapMessage(); map.setString(&quot;text&quot;, message); map.setLong(&quot;time&quot;, System.currentTimeMillis()); System.out.println(&quot;ActiveMQ 发送Topic消息：&quot;+(i + 1)); publisher.send(map); } } } //消费者 package com.active.mq.demo; import javax.jms.JMSException; import javax.jms.MapMessage; import javax.jms.Message; import javax.jms.MessageListener; import javax.jms.Session; import javax.jms.Topic; import javax.jms.TopicConnection; import javax.jms.TopicSession; import javax.jms.TopicSubscriber; public class TopicConsumer { public static void main(String[] args) { TopicConnection connection = null; TopicSession session = null; try { // 通过工厂创建一个连接 connection = MQConnectionFactory.getTopicConnection(); // 启动连接 connection.start(); // 创建一个session会话 session = connection.createTopicSession(Boolean.TRUE, Session.AUTO_ACKNOWLEDGE); // 创建一个消息队列 Topic topic = session.createTopic(&quot;TopicDemo&quot;); // 创建消息消费者 TopicSubscriber subscriber = session.createSubscriber(topic); subscriber.setMessageListener(new MessageListener() { public void onMessage(Message msg) { if (msg != null) { MapMessage map = (MapMessage) msg; try { System.out.println(map.getLong(&quot;time&quot;) + &quot;Topic接收消息#&quot; + map.getString(&quot;text&quot;)); } catch (JMSException e) { e.printStackTrace(); } } } }); // 休眠100ms再关闭 Thread.sleep(1000 * 100); // 提交会话 session.commit(); } catch (Exception e) { e.printStackTrace(); } finally { // 关闭释放资源 if (session != null) { try { session.close(); } catch (JMSException e) { e.printStackTrace(); } } if (connection != null) { try { connection.close(); } catch (JMSException e) { e.printStackTrace(); } } } } } 运行以使用JMS方式发送接收消息为例说明1、首先，启动ActiveMQ2、运行发送者，eclipse控制台输出，如下图： 3、查看ActiveMQ服务器，Queues内容如下： 我们可以看到创建了一个名称为HelloWorld的消息队列，队列中有10条消息未被消费，我们也可以通过Browse查看是哪些消息，如果这些队列中的消息，被删除，消费者则无法消费。 4、运行一下消费者，eclipse控制台打印消息，如下： 5、我们在查看一下ActiveMQ服务器，Queues内容如下： 我们可以看到HelloWorld的消息队列发生变化，多一个消息者，队列中的10条消息被消费了，点击Browse查看，已经为空了。点击Active Consumers，我们可以看到这个消费者的详细信息。 实例到此就结束了，大家可以自己多看点ActiveMQ服务器的内容，进一步熟悉ActiveMQ。","categories":[{"name":"JMS","slug":"JMS","permalink":"http://zhengweishan.oschina.io/categories/JMS/"}],"tags":[{"name":"JMS","slug":"JMS","permalink":"http://zhengweishan.oschina.io/tags/JMS/"},{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"http://zhengweishan.oschina.io/tags/ActiveMQ/"}]},{"title":"JMS学习（二）----- ActiveMQ简单介绍以及安装","slug":"JMS学习（二）ActiveMQ简单介绍以及安装","date":"2017-01-22T16:00:00.000Z","updated":"2017-03-01T08:39:57.456Z","comments":true,"path":"2017/01/23/JMS学习（二）ActiveMQ简单介绍以及安装/","link":"","permalink":"http://zhengweishan.oschina.io/2017/01/23/JMS学习（二）ActiveMQ简单介绍以及安装/","excerpt":"1、简介ActiveMQ是一个易于使用的消息中间件（MOM：Message Orient middleware）。 消息中间件有很多的用途和优点： 将数据从一个应用程序传送到另一个应用程序，或者从软件的一个模块传送到另外一个模块； 负责建立网络通信的通道，进行数据的可靠传送。 保证数据不重发，不丢失 能够实现跨平台操作，能够为不同操作系统上的软件集成技工数据传送服务 首先我们先说下什么是MQ，MQ英文名MessageQueue，中文名也就是大家用的消息队列，干嘛用的呢，说白了就是一个消息的接受和转发的容器，可用于消息推送。下面介绍主题，就是ActiveMQ： ActiveMQ是由Apache出品的，一款最流行的，能力强劲的开源消息总线。ActiveMQ是一个完全支持JMS1.1和J2EE 1.4规范的 JMS Provider实现，它非常快速，支持多种语言的客户端和协议，而且可以非常容易的嵌入到企业的应用环境中，并有许多高级功能。","text":"1、简介ActiveMQ是一个易于使用的消息中间件（MOM：Message Orient middleware）。 消息中间件有很多的用途和优点： 将数据从一个应用程序传送到另一个应用程序，或者从软件的一个模块传送到另外一个模块； 负责建立网络通信的通道，进行数据的可靠传送。 保证数据不重发，不丢失 能够实现跨平台操作，能够为不同操作系统上的软件集成技工数据传送服务 首先我们先说下什么是MQ，MQ英文名MessageQueue，中文名也就是大家用的消息队列，干嘛用的呢，说白了就是一个消息的接受和转发的容器，可用于消息推送。下面介绍主题，就是ActiveMQ： ActiveMQ是由Apache出品的，一款最流行的，能力强劲的开源消息总线。ActiveMQ是一个完全支持JMS1.1和J2EE 1.4规范的 JMS Provider实现，它非常快速，支持多种语言的客户端和协议，而且可以非常容易的嵌入到企业的应用环境中，并有许多高级功能。 2、下载与配置2.1 下载官网下载ActiveMQ 现在ActiveMQ最新的版本是5.13.3。 2.2 启动下载之后解压缩目录结构如图： 从它的目录来说，还是很简单的： bin存放的是脚本文件 conf存放的是基本配置文件 data存放的是日志文件 docs存放的是说明文档 examples存放的是简单的实例 lib存放的是activemq所需jar包 webapps用于存放项目的目录 启动ActiveMQ:进去bin目录下你会发现下图这样的内容： win32文件夹是32位操作系统的启动命令，win64文件夹是64位操作系统的启动命令，文件内容都是如下： 这样就会有三个activemq.bat脚本文件，如果直接启动bin目录下的这个脚本文件，直接闪退（这个问题一直不知道怎么回事，回头看看脚本执行文件），启动不了服务。如果根据自己的操作系统选择对应的执行脚本则可以启动成功，可以看到下图的效果。 从上图我们可以看到activemq的存放地址，以及浏览器要访问的地址. ActiveMQ默认使用的TCP连接端口是61616, 通过查看该端口的信息可以测试ActiveMQ是否成功启动 netstat -an|find “61616” 如图： ActiveMQ默认启动时，启动了内置的jetty服务器，提供一个用于监控ActiveMQ的admin应用。url：http://127.0.0.1:8161/admin/ 用户名和密码都是admin 至此，服务端启动完毕","categories":[{"name":"JMS","slug":"JMS","permalink":"http://zhengweishan.oschina.io/categories/JMS/"}],"tags":[{"name":"JMS","slug":"JMS","permalink":"http://zhengweishan.oschina.io/tags/JMS/"},{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"http://zhengweishan.oschina.io/tags/ActiveMQ/"}]},{"title":"JAVA常用开发环境配置","slug":"java常用开发环境配置","date":"2017-01-21T16:00:00.000Z","updated":"2017-01-22T10:40:15.897Z","comments":true,"path":"2017/01/22/java常用开发环境配置/","link":"","permalink":"http://zhengweishan.oschina.io/2017/01/22/java常用开发环境配置/","excerpt":"1、jdk配置1、1下载安装http://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html 下载安装就好（选择和你系统一样的版本32位或者64位） 1、2环境配置计算机--&gt;属性--&gt;高级系统设置--&gt;环境变量 在系统变量中新建 变量名：JAVA_HOME 变量值：C:\\Program Files\\Java\\jdk1.7.0_80 (ps:如果你没有改变默认路径复制就可以，如果修改过请选择jdk的安装目录) JAVA_HOME是用来表示jdk的安装目录。 配置JAVA_HOME的原因是：（1）方便引用。（2）其他软件会引用约定好的JAVA_HOME变量。比如tomcat就需要引用JAVA_HOME。 在系统变量中查找 Path 编辑 追加新的变量值：%JAVA_HOME%\\bin;%JAVA_HOME%\\jre\\bin; （ps:原来Path的变量值末尾如果没有;号，先输入；号再输入上面的代码） 在系统变量中新建 变量名：CLASSPATH 变量值：.;%JAVA_HOME%lib;%JAVA_HOME%lib\\tools.jar; (ps:前面有个 .; 这个是告诉JDK，搜索CLASS时先查找当前目录的CLASS文件 ) 验证是否成功 win+R 输入cmd 进入命令提示符界面 输入java -version (ps:java空格-version) 查看当前jdk的版本,显示版本信息 则说明安装和配置成功。","text":"1、jdk配置1、1下载安装http://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html 下载安装就好（选择和你系统一样的版本32位或者64位） 1、2环境配置计算机--&gt;属性--&gt;高级系统设置--&gt;环境变量 在系统变量中新建 变量名：JAVA_HOME 变量值：C:\\Program Files\\Java\\jdk1.7.0_80 (ps:如果你没有改变默认路径复制就可以，如果修改过请选择jdk的安装目录) JAVA_HOME是用来表示jdk的安装目录。 配置JAVA_HOME的原因是：（1）方便引用。（2）其他软件会引用约定好的JAVA_HOME变量。比如tomcat就需要引用JAVA_HOME。 在系统变量中查找 Path 编辑 追加新的变量值：%JAVA_HOME%\\bin;%JAVA_HOME%\\jre\\bin; （ps:原来Path的变量值末尾如果没有;号，先输入；号再输入上面的代码） 在系统变量中新建 变量名：CLASSPATH 变量值：.;%JAVA_HOME%lib;%JAVA_HOME%lib\\tools.jar; (ps:前面有个 .; 这个是告诉JDK，搜索CLASS时先查找当前目录的CLASS文件 ) 验证是否成功 win+R 输入cmd 进入命令提示符界面 输入java -version (ps:java空格-version) 查看当前jdk的版本,显示版本信息 则说明安装和配置成功。 2、tomcat配置2、1下载安装http://tomcat.apache.org/download-70.cgi 下载解压到你指定的地方，选择和你系统一样的版本32位或者64位下载页面： 2、2环境配置步骤同1.2 在系统变量中新建 变量名：CATALINA_HOME 变量值：S:\\devTools\\apache-tomcat-7.0.69 在系统变量中查找 CLASSPATH 编辑 追加新的变量值：%CATALINA_HOME%\\common\\bin; （ps:原来Path的变量值末尾如果没有;号，先输入；号再输入上面的代码） 在系统变量中查找 Path 编辑 追加新的变量值：%CATALINA_HOME%\\bin; （ps:原来Path的变量值末尾如果没有;号，先输入；号再输入上面的代码） 验证是否成功 找到安装路径下的bin 文件夹，找到里面的startup.bat执行文件，运行，然后执行下面的操作。 打开浏览器，输入http：//localhost:8080.如果出现下面的内容说明成功了。 3、maven配置3、1下载安装https://maven.apache.org/download.cgi 下载解压到指定的地方就可以。下载页面： 3、2环境配置步骤同1.2 在系统变量中新建 变量名：MAVEN_HOME 变量值：S:\\devTools\\apache-maven-3.2.3 在系统变量中查找 Path 编辑 追加新的变量值：%MAVEN_HOME%\\bin; （ps:原来Path的变量值末尾如果没有;号，先输入；号再输入上面的代码） 验证是否成功 win+R 输入cmd 进入命令提示符界面 输入mvn -version (ps:mvn空格-version) 查看当前mvn的版本,显示版本信息 则说明安装和配置成功。 4、ant配置4、1下载安装http://ant.apache.org/bindownload.cgi 下载解压到指定的地方就可以。下载页面： 4、2环境配置步骤同1.2 在系统变量中新建 变量名：ANT_HOME 变量值：S:\\devTools\\apache-ant-1.9.7 在系统变量中查找 Path 编辑 追加新的变量值：%ANT_HOME%\\bin; （ps:原来Path的变量值末尾如果没有;号，先输入；号再输入上面的代码） 验证是否成功 win+R 输入cmd 进入命令提示符界面 输入ant -version (ps:ant空格-version) 查看当前mvn的版本,显示版本信息 则说明安装和配置成功。 5、eclipse整合maven配置参考我的博客：eclipse创建maven多模块项目 第三部分：Eclipse配置maven","categories":[{"name":"JAVA","slug":"JAVA","permalink":"http://zhengweishan.oschina.io/categories/JAVA/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://zhengweishan.oschina.io/tags/JAVA/"}]},{"title":"JMS学习（一）-----基本概念","slug":"JMS学习（一）基本概念","date":"2017-01-21T16:00:00.000Z","updated":"2017-01-22T10:51:10.585Z","comments":true,"path":"2017/01/22/JMS学习（一）基本概念/","link":"","permalink":"http://zhengweishan.oschina.io/2017/01/22/JMS学习（一）基本概念/","excerpt":"1、简介JMS即Java消息服务（Java Message Service）应用程序接口，是一个Java平台中关于面向消息中间件（MOM）的API，用于在两个应用程序之间，或分布式系统中发送消息，进行异步通信。 2、体系架构JMS提供者：连接面向消息中间件的，JMS接口的一个实现。提供者可以是Java平台的JMS实现，也可以是非Java平台的面向消息中间件的适配器。 JMS客户：生产或消费基于消息的Java的应用程序或对象。 JMS生产者：创建并发送消息的JMS客户。 JMS消费者：接收消息的JMS客户。 JMS消息：包括可以在JMS客户之间传递的数据的对象 JMS队列：一个容纳那些被发送的等待阅读的消息的区域。与队列名字所暗示的意思不同，消息的接受顺序并不一定要与消息的发送顺序相同。一旦一个消息被阅读，该消息将被从队列中移走。 JMS主题：一种支持发送消息给多个订阅者的机制。","text":"1、简介JMS即Java消息服务（Java Message Service）应用程序接口，是一个Java平台中关于面向消息中间件（MOM）的API，用于在两个应用程序之间，或分布式系统中发送消息，进行异步通信。 2、体系架构JMS提供者：连接面向消息中间件的，JMS接口的一个实现。提供者可以是Java平台的JMS实现，也可以是非Java平台的面向消息中间件的适配器。 JMS客户：生产或消费基于消息的Java的应用程序或对象。 JMS生产者：创建并发送消息的JMS客户。 JMS消费者：接收消息的JMS客户。 JMS消息：包括可以在JMS客户之间传递的数据的对象 JMS队列：一个容纳那些被发送的等待阅读的消息的区域。与队列名字所暗示的意思不同，消息的接受顺序并不一定要与消息的发送顺序相同。一旦一个消息被阅读，该消息将被从队列中移走。 JMS主题：一种支持发送消息给多个订阅者的机制。 3、对象模型 (1) ConnectionFactory（连接工厂） 创建Connection对象的工厂，针对两种不同的jms消息模型，分别有QueueConnectionFactory和TopicConnectionFactory两种。可以通过JNDI来查找ConnectionFactory对象。 (2) Destination（JMS目的） Destination的意思是消息生产者的消息发送目标或者说消息消费者的消息来源。对于消息生产者来说，它的Destination是某个队列（Queue）或某个主题（Topic）;对于消息消费者来说，它的Destination也是某个队列或主题（即消息来源）。 所以，Destination实际上就是两种类型的对象：Queue、Topic可以通过JNDI来查找Destination。 (3) Connection（JMS连接） Connection表示在客户端和JMS系统之间建立的链接（对TCP/IP socket的包装）。Connection可以产生一个或多个Session。跟ConnectionFactory一样，Connection也有两种类型：QueueConnection和TopicConnection。 (4) Session（JMS会话） Session是我们操作消息的接口。可以通过session创建生产者、消费者、消息等。Session提供了事务的功能。当我们需要使用session发送/接收多个消息时，可以将这些发送/接收动作放到一个事务中。同样，也分QueueSession和TopicSession。 (5) 消息的生产者（JMS生产者） 消息生产者由Session创建，并用于将消息发送到Destination。同样，消息生产者分两种类型：QueueSender和TopicPublisher。可以调用消息生产者的方法（send或publish方法）发送消息。 (6) 消息消费者（JMS消费者） 消息消费者由Session创建，用于接收被发送到Destination的消息。两种类型：QueueReceiver和TopicSubscriber。可分别通过session的createReceiver(Queue)或createSubscriber(Topic)来创建。当然，也可以session的creatDurableSubscriber方法来创建持久化的订阅者。 (7) MessageListener 消息监听器。如果注册了消息监听器，一旦消息到达，将自动调用监听器的onMessage方法。EJB中的MDB（Message-Driven Bean）就是一种MessageListener。 (8) JMS消息 JMS消息通常有两种类型： ① 点对点（Point-to-Point）。在点对点的消息系统中，消息分发给一个单独的使用者。点对点消息往往与队列（javax.jms.Queue）相关联。 ② 发布/订阅（Publish/Subscribe）。发布/订阅消息系统支持一个事件驱动模型，消息生产者和消费者都参与消息的传递。生产者发布事件，而使用者订阅感兴趣的事件，并使用事件。该类型消息一般与特定的主题（javax.jms.Topic）关联。 4、消息类型分析（1）Point-to-Point （Point-to-Point)模型是基于队列(Queue)的,对于PTP消息模型而言,它的消息目的是一个消息队列(Queue),消息生产者每次发送消息总是把消息送入消息队列中,消息消费者总是从消息队列中读取消息.先进队列的消息将先被消息消费者读取. 特点： 每个消息只有一个消费者（Consumer）(即一旦被消费，消息就不再在消息队列中) 发送者和接收者之间在时间上没有依赖性，也就是说当发送者发送了消息之后，不管接收者有没有正在运行，它不会影响到消息被发送到队列 接收者在成功接收消息之后需向队列应答成功 （2）Publish/Subscribe 定义了如何向一个内容节点发布和订阅消息,这些节点被称作主题(topic). 主题可以被认为是消息的传输中介,发布者(publisher)发布消息到主题,订阅者(subscribe) 从主题订阅消息.主题使得消息订阅者和消息发布者保持互相独立,不需要接触即可保证消息的传送. 特点： 每个消息可以有多个消费者 发布者和订阅者之间有时间上的依赖性。针对某个主题（Topic）的订阅者，它必须创建一个订阅者之后，才能消费发布者的消息，而且为了消费消息，订阅者必须保持运行的状态。 为了缓和这样严格的时间相关性，JMS允许订阅者创建一个可持久化的订阅。这样，即使订阅者没有被激活（运行），它也能接收到发布者的消息。 5、好处应用程序A 发送一条消息到消息服务器（也就是JMS Provider）的某个目得地(Destination)，然后消息服务器把消息转发给应用程序B。因为应用程序A 和应用程序B 没有直接的代码关连，所以两者实现了解偶。如下图： 结合上面的图总结以下三点好处: 提供消息灵活性 松散耦合 异步性","categories":[{"name":"JMS","slug":"JMS","permalink":"http://zhengweishan.oschina.io/categories/JMS/"}],"tags":[{"name":"JMS","slug":"JMS","permalink":"http://zhengweishan.oschina.io/tags/JMS/"},{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"http://zhengweishan.oschina.io/tags/ActiveMQ/"}]},{"title":"使用Hexo+OSChina+git搭建自己的博客网站","slug":"Hexo+OSChina","date":"2017-01-21T16:00:00.000Z","updated":"2017-01-22T03:50:05.209Z","comments":true,"path":"2017/01/22/Hexo+OSChina/","link":"","permalink":"http://zhengweishan.oschina.io/2017/01/22/Hexo+OSChina/","excerpt":"基础工具介绍码云Pages码云 Pages 是一个免费的静态网页托管服务，您可以使用码云 Pages 托管博客、项目官网等静态网页。如果您使用过 Github Pages 那么您会很快上手使用码云的Pages服务。 官方介绍：http://www.oschina.net/news/73980/gitosc-pages HexoHexo 是一个简单地、轻量地、基于Node的一个静态博客框架，可以方便的生成静态网页托管在github和Heroku上，引用Hexo作者 [@tommy351] 的话： 快速、简单且功能强大的 Node.js 博客框架。A fast, simple &amp; powerful blog framework, powered by Node.js. 官网地址：https://hexo.io gitGit是一个开源的分布式版本控制系统，用以有效、高速的处理从很小到非常大的项目版本管理。 官网地址：https://git-scm.com","text":"基础工具介绍码云Pages码云 Pages 是一个免费的静态网页托管服务，您可以使用码云 Pages 托管博客、项目官网等静态网页。如果您使用过 Github Pages 那么您会很快上手使用码云的Pages服务。 官方介绍：http://www.oschina.net/news/73980/gitosc-pages HexoHexo 是一个简单地、轻量地、基于Node的一个静态博客框架，可以方便的生成静态网页托管在github和Heroku上，引用Hexo作者 [@tommy351] 的话： 快速、简单且功能强大的 Node.js 博客框架。A fast, simple &amp; powerful blog framework, powered by Node.js. 官网地址：https://hexo.io gitGit是一个开源的分布式版本控制系统，用以有效、高速的处理从很小到非常大的项目版本管理。 官网地址：https://git-scm.com 搭建环境码云Pages使用这里使用开源中国码云，没有使用github（你懂的，支持下国内软件），没有开源中国码云的小伙伴赶紧注册了。具体可以参见 ：官网 的介绍以及使用，这里就不在啰里啰嗦的介绍了。 因为我想以根目录访问网站，所以我创建了一个这样子的项目： https://git.oschina.net/zhengweishan/zhengweishan. 启动码云Pages,就可以访问了，访问地址： http://zhengweishan.oschina.io/ 官方说明如下： *如果你想以根目录的形式访问自己的静态网站，只需要建立一个与自己个性地址同名的项目即可，如http://git.oschina.net/ipvb 这个用户，想要创建一个自己的站点，但不想以子目录的方式访问，想以ipvb.oschina.io 直接访问，那么他就可以创建一个名字为ipvb的项目http://git.oschina.net/ipvb/ipvb 部署完成后，就可以以http://ipvb.oschina.io 进行访问了。 * git安装请参考http://www.runoob.com/git/git-install-setup.html，这里就不在累赘的介绍了。 Node.js安装请参考http://www.runoob.com/nodejs/nodejs-install-setup.html，这里就不在累赘的介绍了。可能有人会问：为什么要安装Node.js？很简单嘛，我们的Hexo是基于Node的一个静态博客框架嘛。 Hexo安装 安装 如果您的电脑中已经安装上述必备程序，那么恭喜您！接下来只需要使用 npm 即可完成 Hexo 的安装（可以参看官网文档）。打开命令窗口输入下面代码： npm install hexo-cli -g 安装成功后输入hexo 如果得到下面这个结果，恭喜你！安装成功！ Hexo常用命令请参考：https://hexo.io/zh-cn/docs/commands.html 本地运行 安装 Hexo 完成后，Hexo 将会在指定文件夹中新建所需要的文件。这里本地先新建了与博客地址一样的文件夹： zhengweishan.oschina.io.然后请进入你创建的改文件夹的上级目录，在该目录下打开命令行窗口，依次执行下列命令: hexo init zhengweishan.oschina.io cd zhengweishan.oschina.io npm install #install before start blogging hexo generate #生成静态文件到项目根目录的public文件夹中 新建完成后，指定文件夹的目录如下： . ├── .deploy #需要部署的文件 ├── node_modules #Hexo插件 ├── public #生成的静态网页文件 ├── scaffolds #模板 ├── source #博客正文和其他源文件, 404 favicon CNAME 等都应该放在这里 | ├── _drafts #草稿 | └── _posts #文章 ├── themes #主题 ├── _config.yml #全局配置文件 └── package.json 进行到这步后就可以先在本地运行下，看看效果了。执行下面命令： cd zhengweishan.oschina.io npm install #install before start blogging hexo server #运行本地服务 浏览器输入http://localhost:4000就可以看到效果。如下： 远程发布 注册一个码云帐号，并创建一个项目，这里使用已经创建好的项目https://git.oschina.net/zhengweishan/zhengweishan，然后获取git地址：https://git.oschina.net/zhengweishan/zhengweishan.git 这里使用git将项目中public文件夹下的文件管理起来，并推送到码云上。借用一个插件来帮助我们完成，安装 hexo-deployer-git。安装代码如下： npm install hexo-deployer-git --save 配置项目根目录_config.yml 文件，修改deploy的值，如下图： 参考：https://hexo.io/docs/deployment.html 修改完后在命令窗口执行下面命令： cd zhengweishan.oschina.io npm install #install before start blogging hexo deploy #一键部署功能 之后会弹出一个对话框，输入码云的帐号密码。大家最后在安装好git以后配置一个全局的文件，这样就可以不用每次提交都输入账号密码了。 部署成功之后，登录码云，查看之前创建的项目中出现了public文件夹中的文件，这时候代表之前的部署是成功的。 最后启动码云的Pages功能，详细参看：http://www.oschina.net/news/73980/gitosc-pages 启动之后如下图， 然后浏览器输入生成的网址就可以访问了，如下图所示： 看到之前和本地启动一样的效果了,这样子博客网站就部署完成了。","categories":[{"name":"Hexo","slug":"Hexo","permalink":"http://zhengweishan.oschina.io/categories/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://zhengweishan.oschina.io/tags/Hexo/"}]},{"title":"JAVA反射机制","slug":"java反射机制","date":"2017-01-19T16:00:00.000Z","updated":"2017-01-20T07:54:02.846Z","comments":true,"path":"2017/01/20/java反射机制/","link":"","permalink":"http://zhengweishan.oschina.io/2017/01/20/java反射机制/","excerpt":"简介Java反射机制是指在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性；这种动态获取的信息以及动态调用对象的方法的功能称为java语言的反射机制。用一句话总结就是反射可以实现在运行时可以知道任意一个类的属性和方法。","text":"简介Java反射机制是指在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性；这种动态获取的信息以及动态调用对象的方法的功能称为java语言的反射机制。用一句话总结就是反射可以实现在运行时可以知道任意一个类的属性和方法。 Class 对象在java中类也是对象，是Class类的实例对象，这个对象称为该类的类类型对于普通的对象，我们一般都会这样创建和表示： Code code = new Code(); 上面说了，所有的类都是Class的对象，那么该如何表示呢，是不是可不可以通过如下方式呢： Class cl = new Class(); 但是我们查看Class的源码时，是这样写的： private Class(ClassLoader loader) { // Initialize final field for classLoader. The initialization value of non-null // prevents future JIT optimizations from assuming this final field is null. classLoader = loader; } 可以看到构造器是私有的，只有JVM可以创建Class的对象，因此不可以像普通类一样new一个Class对象，虽然我们不能new一个Class对象，但是却可以通过已有的类得到一个Class对象，共有三种方式： Class objectClass = Object.class;//任何一个类都有一个隐含的静态成员变量class，这种方式是通过获取类的静态成员变量class得到的 Class objectClass = object.getClass();//object是Object的一个对象，这种方式是通过一个类的对象的getClass()方法获得的 Class objectClass = Class.forName(&quot;xxx.xxx.Object&quot;);//这种方法是Class类调用forName方法，通过一个类的全量限定名获得,一般使用这种方式获取 简单的例子： Class objectClass1 = User.class; System.out.println(objectClass1.getName()); User user = new User(); Class objectClass2 = user.getClass(); System.out.println(objectClass2.getName()); Class objectClass3 = Class.forName(&quot;com.java.reflection.demo.User&quot;); System.out.println(objectClass3.getName()); 执行结果： com.java.reflection.demo.User com.java.reflection.demo.User com.java.reflection.demo.User 类名、包名、父类我们可以从Class对象中获取两个版本的类名： Class object = Class.forName(&quot;com.java.reflection.demo.User&quot;); object.getName() //全限定类名（包含包名） eg:com.java.reflection.demo.User object.getSimpleName()//类的名字(不包含包名) eg:User object.getPackage() //包名 eg:com.java.reflection.demo object.getSuperClass()//父类 eg:java.lang.Object 修饰符可以通过 Class 对象来访问一个类的修饰符， 即public,private,static 等等的关键字，你可以使用如下方法来获取类的修饰符： Class object = Class.forName(&quot;com.java.reflection.demo.User&quot;); int modifiers = aClass.getModifiers(); 修饰符都被包装成一个int类型的数字，这样每个修饰符都是一个位标识(flag bit)，这个位标识可以设置和清除修饰符的类型。 可以使用 java.lang.reflect.Modifier 类中的方法来检查修饰符的类型： Modifier.isAbstract(int modifiers) Modifier.isFinal(int modifiers) Modifier.isInterface(int modifiers) Modifier.isNative(int modifiers) Modifier.isPrivate(int modifiers) Modifier.isProtected(int modifiers) Modifier.isPublic(int modifiers) Modifier.isStatic(int modifiers) Modifier.isStrict(int modifiers) Modifier.isSynchronized(int modifiers) Modifier.isTransient(int modifiers) Modifier.isVolatile(int modifiers) 方法、变量、实现接口、构造函数可以通过 Class 对象获取 Method 对象，类的成员变量，实现的接口、Constructor类的实例。 Method对象 Method[] methods = Class.forName(className).getMethods();//public方法 //Method[] methods = Class.forName(className).getDeclaredMethods();//private方法 //指定的方法 Method method = cl.getMethod(“method”);//public //Method method = cl.getDeclaredMethod(“method”)//private 成员变量 Field[] fields = Class.forName(className).getFields();//public修饰的成员变量 //Field[] fields = Class.forName(className).getDeclaredFields();//private修饰的成员变量 //指定的成员变量 Field field = Class.forName(className).getDeclaredField(“name”); 实现的接口 Class[] interfaces = Class.forName(className).getInterfaces(); Constructor类的实例 Constructor[] constructors = Class.forName(className).getConstructors(); //指定的Constructor类的实例 Constructor userConstructor = (Constructor) Class.forName(className).getConstructor(String.class,Integer.class,String.class); 演示demo下载gitHub:https://github.com/wesley5201314/JavaReflection gitosc:https://git.oschina.net/zhengweishan/JavaReflection 总结到此，Java反射机制入门的差不多了，我是复习SpringMVC AOP里面自定义异常处理的时候，里面我们通过Java反射来实现的，希望这篇笔记也对你有用。 参考资料 Java Reflection Tutorial Java反射机制深入详解 Java反射入门 Java反射机制 java反射详解 Java 反射机制浅析 反射机制的理解及其用途","categories":[{"name":"JAVA","slug":"JAVA","permalink":"http://zhengweishan.oschina.io/categories/JAVA/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://zhengweishan.oschina.io/tags/JAVA/"},{"name":"Reflection","slug":"Reflection","permalink":"http://zhengweishan.oschina.io/tags/Reflection/"}]},{"title":"JVM简介及工作原理分析","slug":"jvm","date":"2017-01-19T16:00:00.000Z","updated":"2017-01-20T07:23:48.909Z","comments":true,"path":"2017/01/20/jvm/","link":"","permalink":"http://zhengweishan.oschina.io/2017/01/20/jvm/","excerpt":"1、什么是JVMJVM是Java Virtual Machine（Java虚拟机）的缩写，JVM是一种用于计算设备的规范，它是一个虚构出来的计算机，是通过在实际的计算机上仿真模拟各种计算机功能来实现的。 简单来说，JVM是用于执行Java应用程序和字节码的软件模块，并且可以将字节码转换为特定硬件和特定操作系统的本地代码。JVM在执行字节码时，实际上最终还是把字节码解释成具体平台上的机器指令执行，这就是Java的能够“一次编译，到处运行”的原因。 JVM包括一套字节码指令集、一组寄存器、一个栈、一个垃圾回收堆和一个存储方法域。 2、JRE/JDK/JVM是什么关系JRE(JavaRuntimeEnvironment，Java运行环境)，也就是Java平台。所有的Java 程序都要在JRE下才能运行。普通用户只需要运行已开发好的java程序，安装JRE即可。 JDK(Java Development Kit)是程序开发者用来来编译、调试java程序用的开发工具包。JDK的工具也是Java程序，也需要JRE才能运行。为了保持JDK的独立性和完整性，在JDK的安装过程中，JRE也是 安装的一部分。所以，在JDK的安装目录下有一个名为jre的目录，用于存放JRE文件。 JVM(JavaVirtualMachine，Java虚拟机)是JRE的一部分。它是一个虚构出来的计算机，是通过在实际的计算机上仿真模拟各种计算机功能来实现的。JVM有自己完善的硬件架构，如处理器、堆栈、寄存器等，还具有相应的指令系统。Java语言最重要的特点就是跨平台运行。使用JVM就是为了支持与操作系统无关，实现跨平台。","text":"1、什么是JVMJVM是Java Virtual Machine（Java虚拟机）的缩写，JVM是一种用于计算设备的规范，它是一个虚构出来的计算机，是通过在实际的计算机上仿真模拟各种计算机功能来实现的。 简单来说，JVM是用于执行Java应用程序和字节码的软件模块，并且可以将字节码转换为特定硬件和特定操作系统的本地代码。JVM在执行字节码时，实际上最终还是把字节码解释成具体平台上的机器指令执行，这就是Java的能够“一次编译，到处运行”的原因。 JVM包括一套字节码指令集、一组寄存器、一个栈、一个垃圾回收堆和一个存储方法域。 2、JRE/JDK/JVM是什么关系JRE(JavaRuntimeEnvironment，Java运行环境)，也就是Java平台。所有的Java 程序都要在JRE下才能运行。普通用户只需要运行已开发好的java程序，安装JRE即可。 JDK(Java Development Kit)是程序开发者用来来编译、调试java程序用的开发工具包。JDK的工具也是Java程序，也需要JRE才能运行。为了保持JDK的独立性和完整性，在JDK的安装过程中，JRE也是 安装的一部分。所以，在JDK的安装目录下有一个名为jre的目录，用于存放JRE文件。 JVM(JavaVirtualMachine，Java虚拟机)是JRE的一部分。它是一个虚构出来的计算机，是通过在实际的计算机上仿真模拟各种计算机功能来实现的。JVM有自己完善的硬件架构，如处理器、堆栈、寄存器等，还具有相应的指令系统。Java语言最重要的特点就是跨平台运行。使用JVM就是为了支持与操作系统无关，实现跨平台。 3、JVM体系结构 JVM的内部体系结构分为三部分（图片来自网络）： （1）类装载器（ClassLoader）子系统 用来装载.class文件 （2）执行引擎 执行字节码，或者执行本地方法 （3）运行时数据区 方法区，堆，java栈，PC寄存器，本地方法栈 4、JVM工作原理JVM是java的核心和基础，在java编译器和os平台之间的虚拟处理器。它是一种基于下层的操作系统和硬件平台并利用软件方法来实现的抽象的计算机，可以在上面执行java的字节码程序。java编译器只需面向JVM，生成JVM能理解的代码或字节码文件。Java源文件经编译器，编译成字节码程序，通过JVM将每一条指令翻译成不同平台机器码，通过特定平台运行。可以用下图来表示编译执行的简化过程： 5、JVM执行过程 1、加载class文件； 2、分配内存； 3、解释字节码成机器码； 4、运行过程垃圾收集； 5、结束。 JRE（java运行时环境）由JVM构造的java程序的运行环，也是Java程序运行的环境，但是他同时一个操作系统的一个应用程序一个进程，因此他也有他自己的运行的生命周期，也有自己的代码和数据空间。 JVM在整个jdk中处于最底层，负责于操作系统的交互，用来屏蔽操作系统环境，提供一个完整的Java运行环境，因此也就虚拟计算机。 操作系统装入JVM是通过jdk中Java.exe来完成，通过下面4步来完成JVM环境： 1) 创建JVM装载环境和配置 2) 装载JVM.dll 3) 初始化JVM.dll并挂界到JNIENV(JNI调用接口)实例 4) 调用JNIEnv实例装载并处理class类。 6、JVM的生命周期a、两个概念JVM实例和JVM执行引擎实例 JVM实例对应了一个独立运行的Java程序 (进程级别) JVM执行引擎实例则对应了属于用户运行程序的线程 (线程级别) b、JVM的生命周期 JVM实例的诞生 当启动一个Java程序时，一个JVM实例就产生了，任何一个拥有public static void main(String[] args)函数的class都可以作为JVM实例运行的起点 JVM实例的运行 main()作为该程序初始线程的起点，任何其他线程均由该线程启动。JVM内部有两种线程：守护线程和非守护线程，main()属于非守护线程，守护线程通常由JVM自己使用，java程序也可以标明自己创建的线程是守护线程。 JVM实例的消亡 当程序中的所有非守护线程都终止时，JVM才退出；若安全管理器允许，程 序也可以使用Runtime类或者System.exit()来退出。 7、ClassLoader（类加载器）a、JVM整个类加载过程JVM将整个类加载过程划分为了三个步骤： （1）装载 装载过程负责找到二进制字节码并加载至JVM中，JVM通过类名、类所在的包名通过ClassLoader来完成类的加载，同样，也采用以上三个元素来标识一个被加载了的类：类名+包名+ClassLoader实例ID。 （2）链接 链接过程负责对二进制字节码的格式进行校验、初始化装载类中的静态变量以及解析类中调用的接口、类。在完成了校验后，JVM初始化类中的静态变量，并将其值赋为默认值。最后一步为对类中的所有属性、方法进行验证，以确保其需要调用的属性、方法存在，以及具备应的权限（例如public、private域权限等），会造成NoSuchMethodError、NoSuchFieldError等错误信息。 （3）初始化 初始化过程即为执行类中的静态初始化代码、构造器代码以及静态属性的初始化，在四种情况下初始化过程会被触发执行： 调用了new； 反射调用了类中的方法； 子类调用了初始化； JVM启动过程中指定的初始化类。 b、JVM类加载顺序JVM有两种类加载器： 启动类装载器：是JVM实现的一部分 用户自定义类装载器：是Java程序的一部分，必须是ClassLoader类的子类 当JVM启动时，由Bootstrap向User-Defined方向加载类；应用进行ClassLoader时，由User-Defined向Bootstrap方向查找并加载类； 1. Bootstrap ClassLoader 这是JVM的根ClassLoader，它是用C++实现的，JVM启动时初始化此ClassLoader，并由此ClassLoader完成$JAVA_HOME中jre/lib/rt.jar（Sun JDK的实现）中所有class文件的加载，这个jar中包含了java规范定义的所有接口以及实现。 2. Extension ClassLoader JVM用此classloader来加载扩展功能的一些jar包。 3. System ClassLoader JVM用此classloader来加载启动参数中指定的Classpath中的jar包以及目录，在Sun JDK中ClassLoader对应的类名为AppClassLoader。 4. User-Defined ClassLoader User-DefinedClassLoader是Java开发人员继承ClassLoader抽象类自行实现的ClassLoader，基于自定义的ClassLoader可用于加载非Classpath中的jar以及目录。 有关ClassLoader抽象类的几个关键方法： loadClass 此方法负责加载指定名字的类，ClassLoader的实现方法为先从已经加载的类中寻找，如没有则继续从parent ClassLoader中寻找，如仍然没找到，则从System ClassLoader中寻找，最后再调用findClass方法来寻找，如要改变类的加载顺序，则可覆盖此方法 findLoadedClass 此方法负责从当前ClassLoader实例对象的缓存中寻找已加载的类，调用的为native的方法。 findClass 此方法直接抛出ClassNotFoundException，因此需要通过覆盖loadClass或此方法来以自定义的方式加载相应的类。 findSystemClass 此方法负责从System ClassLoader中寻找类，如未找到，则继续从Bootstrap ClassLoader中寻找，如仍然为找到，则返回null。 defineClass 此方法负责将二进制的字节码转换为Class对象 resolveClass 此方法负责完成Class对象的链接，如已链接过，则会直接返回。 8、执行引擎JVM通过执行引擎来完成字节码的执行，在执行过程中JVM采用的是自己的一套指令系统，每个线程在创建后，都会产生一个程序计数器（pc）和栈（Stack），其中程序计数器中存放了下一条将要执行的指令，Stack中存放Stack Frame，表示的为当前正在执行的方法，每个方法的执行都会产生Stack Frame，Stack Frame中存放了传递给方法的参数、方法内的局部变量以及操作数栈，操作数栈用于存放指令运算的中间结果，指令负责从操作数栈中弹出参与运算的操作数，指令执行完毕后再将计算结果压回到操作数栈，当方法执行完毕后则从Stack中弹出，继续其他方法的执行。 在执行方法时JVM提供了四种指令来执行： （1）invokestatic：调用类的static方法 （2）invokevirtual：调用对象实例的方法 （3）invokeinterface：将属性定义为接口来进行调用 （4）invokespecial：JVM对于初始化对象（Java构造器的方法为：）以及调用对象实例中的私有方法时。 主要的执行技术有:解释，即时编译，自适应优化、芯片级直接执行 （1）解释属于第一代JVM， （2）即时编译JIT属于第二代JVM， （3）自适应优化（目前Sun的HotspotJVM采用这种技术）则吸取第一代JVM和第二代JVM的经验，采用两者结合的方式开始对所有的代码都采取解释执行的方式，并监视代码执行情况，然后对那些经常调用的方法启动一个后台线程，将其编译为本地代码，并进行优化。若方法不再频繁使用，则取消编译过的代码，仍对其进行解释执行。 9、JVM运行时数据区 PC寄存器（Program Counter Register） （Program Counter Register）是一块较小的内存空间，它可以看做是当前线程所执行的字节码的行号指示器。在虚拟机的概念模型里（仅是概念模型，各种虚拟机可能会通过一些更高效的方式去实现），字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令、分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。 由于Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的。在任何一个确定的时刻，一个处理器都只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各个线程之间计数器互不影响，独立存储。 如果线程正在执行的是一个Java方法，那这个计数器记录的是正在执行的字节码指令的地址；如果正在执行的是Native方法，这个计数器值则为空（undefined）。此内存区域是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError情况的区域。 程序计数器是线程私有的，它的生命周期与线程相同（随线程而生，随线程而灭）。 JVM栈（JVM Stacks） 每个JVM 线程都有一个私有的JVM 栈(Stacks)，它将和线程同时创建。JVM 栈用来存储帧(后面会讲解)。JVM 栈类似于传统语言例如C 的栈，它持有局部变量和部分结果并且参与方法的调用和返回。 由于JVM 栈除了压入弹出帧外不会被直接操作，所以帧可以由堆(Heap)来分配。对于JVM 栈的内存不必是连续的。 JVM 规范允许JVM 栈的大小是固定的，也可以是根据需求计算来扩展和收缩。如果JVM 栈是固定大小，则每个JVM 栈大小可以在栈创建时独立地选择。一个JVM 实现可以让程序员或用户控制JVM 初始栈的大小，以及在动态扩展或收缩JVM 栈时，控制其最大值和最小值。 以下异常情况常与JVM 栈有关： 如果线程中的计算需要一个比允许的JVM 栈更大时，JVM 将会抛出StackOverflowError. 如果JVM 栈可动态扩展，当没有足够的内存分配给所尝试的扩展，或者没有足够的内存来为一个新线程创建初始化JVM 栈，JVM 将会抛出OutOfMemoryError. 堆（Heap） JVM 有一个所有JVM 线程间共享的堆（Heap）。堆是分配所有类实例和数组内存的运行期数据区域。堆在虚拟机启动时被创建。堆中对象的存储由自动存储管理系统（常被称为垃圾回收器或GC）回收，对象从来不会被显示的回收。JVM 承担着非特殊类型的自动存储管理系统，当然存储管理技术也可以根据实现者的系统要求来选择。堆可以是固定大小或是根据需求计算进行扩展，或者也可以是当一个大的堆不必要时进行收缩。堆的内存不需要是连续的。 一个JVM 实现可以让开发者或者用户控制堆初始的大小，同样的，如果堆能够动态扩展或者收缩，可以控制其最大值和最小值。 以下异常情况常与堆有关：如果计算需求所须更多的堆无法由自动存储管理系统提供时，JVM 将会抛出OutOfMemoryError. 方法区域（Method Area） （1）方法区域存放了所加载的类的信息（名称、修饰符等）、类中的静态变量、类中定义为final类型的常量、类中的Field信息、类中的方法信息，当开发人员在程序中通过Class对象中的getName、isInterface等方法来获取信息时，这些数据都来源于方法区域，可见方法区域的重要性，同样，方法区域也是全局共享的，在一定的条件下它也会被GC；当方法区域需要使用的内存超过其允许的大小时，会抛出OutOfMemory的错误信息。 （2）方法区在虚拟机启动时被创建。虽然方法区逻辑上是堆的一部分，但是简单的实现可以选择既不垃圾回收也不压缩它。该版本的JVM 规范不要求指定方法区的位置或者用于管理编译后代码的策略。方法区可以是固定大小，也可以根据需求计算扩展，并且当大的方法区不再需要时进行收缩。方法区的内存不需要是连续的。 一个JVM 实现可以让开发者或用户控制方法区初始的大小，同样的，在可变大小方法区时，控制方法区的最大值和最小值。在Sun JDK中这块区域对应的为Permanet Generation，又称为持久代，默认为64M，可通过-XX:PermSize以及-XX:MaxPermSize来指定其大小。 运行时常量池（Runtime Constant Pool） 运行时常量池（Runtime Constant Pool）是方法区的一部分。Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池（Constant Pool Table），用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池中存放。 以下异常情况常与类或接口的常量池有关：当创建类或接口时，如果常量池的建立需要的内存不能被JVM 的方法区分配，JVM 会抛出OutOfMenoryError. 本地方法堆栈（Native Method Stacks） 本地方法栈（Native Method Stack）与虚拟机栈所发挥的作用是非常类似，它们之间的区别在于虚拟机栈为虚拟机执行Java方法服务，而本地方法栈则是为虚拟机使用到的Native方法服务。在虚拟机规范中对本地方法栈中方法使用的语言、使用方式与数据结构并没有强制规定，因此具体的虚拟机可以自由的实现它。 以下异常情况常与本地方法栈有关： 如果线程中计算所需的本地方法栈大于允许范围，JVM 会抛出StackOverflowError。 如果本地方法栈能动态扩展，当没有足够的内存分配给所尝试的扩展，或者没有足够的内存分配给新线程中创建的初始本地方法栈，JVM 就会抛出OutOfMemoryError。 与虚拟机栈一样，本地方法栈也是线程私有的。","categories":[{"name":"JVM","slug":"JVM","permalink":"http://zhengweishan.oschina.io/categories/JVM/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://zhengweishan.oschina.io/tags/JAVA/"},{"name":"GC","slug":"GC","permalink":"http://zhengweishan.oschina.io/tags/GC/"},{"name":"JVM","slug":"JVM","permalink":"http://zhengweishan.oschina.io/tags/JVM/"}]},{"title":"JAVA垃圾回收机制","slug":"GC","date":"2017-01-19T16:00:00.000Z","updated":"2017-01-20T07:24:09.566Z","comments":true,"path":"2017/01/20/GC/","link":"","permalink":"http://zhengweishan.oschina.io/2017/01/20/GC/","excerpt":"概述说起垃圾回收(Garbage Collection，GC)，大家肯定很自然的和java联系起来。在Java中，程序员不需要去关心内存动态分配和垃圾回收的问题，这一切都交给了JVM来处理。顾名思义，垃圾回收就是释放垃圾占用的空间。（Java中指对象所占用的内存在对象不再使用后会自动被回收,是由一个叫垃圾回收器Garbage Collector的进程完成的） 对象引用Java 中的垃圾回收一般是在 Java 堆中进行，因为堆中几乎存放了 Java 中所有的对象实例。谈到 Java 堆中的垃圾回收，自然要谈到引用。在 JDK1.2 之前，Java 中的引用定义很很纯粹：如果 reference 类型的数据中存储的数值代表的是另外一块内存的起始地址，就称这块内存代表着一个引用。但在 JDK1.2 之后，Java 对引用的概念进行了扩充，将其分为强引用（Strong Reference）、软引用（Soft Reference）、弱引用（Weak Reference）、虚引用（Phantom Reference）四种，引用强度依次减弱。 强引用：如“Object obj = new Object（）”，这类引用是 Java 程序中最普遍的。只要强引用还存在，垃圾收集器就永远不会回收掉被引用的对象。 软引用：它用来描述一些可能还有用，但并非必须的对象。在系统内存不够用时，这类引用关联的对象将被垃圾收集器回收。JDK1.2 之后提供了 SoftReference 类来实现软引用。 弱引用：它也是用来描述非需对象的，但它的强度比软引用更弱些，被弱引用关联的对象只能生存岛下一次垃圾收集发生之前。当垃圾收集器工作时，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。在 JDK1.2 之后，提供了 WeakReference 类来实现弱引用。 虚引用：最弱的一种引用关系，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的是希望能在这个对象被收集器回收时收到一个系统通知。JDK1.2 之后提供了 PhantomReference 类来实现虚引用。","text":"概述说起垃圾回收(Garbage Collection，GC)，大家肯定很自然的和java联系起来。在Java中，程序员不需要去关心内存动态分配和垃圾回收的问题，这一切都交给了JVM来处理。顾名思义，垃圾回收就是释放垃圾占用的空间。（Java中指对象所占用的内存在对象不再使用后会自动被回收,是由一个叫垃圾回收器Garbage Collector的进程完成的） 对象引用Java 中的垃圾回收一般是在 Java 堆中进行，因为堆中几乎存放了 Java 中所有的对象实例。谈到 Java 堆中的垃圾回收，自然要谈到引用。在 JDK1.2 之前，Java 中的引用定义很很纯粹：如果 reference 类型的数据中存储的数值代表的是另外一块内存的起始地址，就称这块内存代表着一个引用。但在 JDK1.2 之后，Java 对引用的概念进行了扩充，将其分为强引用（Strong Reference）、软引用（Soft Reference）、弱引用（Weak Reference）、虚引用（Phantom Reference）四种，引用强度依次减弱。 强引用：如“Object obj = new Object（）”，这类引用是 Java 程序中最普遍的。只要强引用还存在，垃圾收集器就永远不会回收掉被引用的对象。 软引用：它用来描述一些可能还有用，但并非必须的对象。在系统内存不够用时，这类引用关联的对象将被垃圾收集器回收。JDK1.2 之后提供了 SoftReference 类来实现软引用。 弱引用：它也是用来描述非需对象的，但它的强度比软引用更弱些，被弱引用关联的对象只能生存岛下一次垃圾收集发生之前。当垃圾收集器工作时，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。在 JDK1.2 之后，提供了 WeakReference 类来实现弱引用。 虚引用：最弱的一种引用关系，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的是希望能在这个对象被收集器回收时收到一个系统通知。JDK1.2 之后提供了 PhantomReference 类来实现虚引用。 垃圾对象的判定Java 堆中存放着几乎所有的对象实例，GC通过确定对象是否被活动对象引用来确定是否收集该对象。GC首先要判断该对象是否是时候可以收集，两种常用的方法是引用计数和对象引用遍历。 引用计数收集器 引用计数是垃圾收集器中的早期策略。在这种方法中，堆中每个对象（不是引用）都有一个引用计数。当一个对象被创建时，且将该对象分配给一个变量，该变量计数设置为1。当任何其它变量被赋值为这个对象的引用时，计数加1（a = b,则b引用的对象+1），但当一个对象的某个引用超过了生命周期或者被设置为一个新值时，对象的引用计数减1。任何引用计数为0的对象可以被当作垃圾收集。当一个对象被垃圾收集时，它引用的任何对象计数减1。 优点：引用计数收集器可以很快的执行，交织在程序运行中。对程序不被长时间打断的实时环境比较有利。 缺点： 无法检测出循环引用。如父对象有一个对子对象的引用，子对象反过来引用父对象。这样，他们的引用计数永远不可能为0 根搜索收集器 Java 和 C# 中都是采用根搜索算法来判定对象是否存活的。这种算法的基本思路是通过一系列名为“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链，当一个对象到 GC Roots 没有任何引用链相连时，就证明此对象是不可用的。在 Java 语言里，可作为 GC Roots 的兑现包括下面几种： 虚拟机栈（栈帧中的本地变量表）中引用的对象。 方法区中的类静态属性引用的对象。 方法区中的常量引用的对象。 本地方法栈中 JNI（Native 方法）的引用对象。 实际上，在根搜索算法中，要真正宣告一个对象死亡，至少要经历两次标记过程：如果对象在进行根搜索后发现没有与 GC Roots 相连接的引用链，那它会被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行 finalize()方法。当对象没有覆盖 finalize()方法，或 finalize()方法已经被虚拟机调用过，虚拟机将这两种情况都视为没有必要执行。如果该对象被判定为有必要执行 finalize()方法，那么这个对象将会被放置在一个名为 F-Queue 队列中，并在稍后由一条由虚拟机自动建立的、低优先级的 Finalizer 线程去执行 finalize()方法。finalize()方法是对象逃脱死亡命运的最后一次机会（因为一个对象的 finalize()方法最多只会被系统自动调用一次），稍后 GC 将对 F-Queue 中的对象进行第二次小规模的标记，如果要在 finalize()方法中成功拯救自己，只要在 finalize()方法中让该对象重引用链上的任何一个对象建立关联即可。而如果对象这时还没有关联到任何链上的引用，那它就会被回收掉。 跟踪收集器 早期的JVM使用引用计数，现在大多数JVM采用对象引用遍历。对象引用遍历从一组对象开始，沿着整个对象图上的每条链接，递归确定可到达（reachable）的对象。如果某对象不能从这些根对象的一个（至少一个）到达，则将它作为垃圾收集。在对象遍历阶段，GC必须记住哪些对象可以到达，以便删除不可到达的对象，这称为标记（marking）对象。 下一步，GC要删除不可到达的对象。删除时，有些GC只是简单的扫描堆栈，删除未标记的未标记的对象，并释放它们的内存以生成新的对象，这叫做清除（sweeping）。这种方法的问题在于内存会分成好多小段，而它们不足以用于新的对象，但是组合起来却很大。因此，许多GC可以重新组织内存中的对象，并进行压缩（compact），形成可利用的空间。 为此，GC需要停止其他的活动活动。这种方法意味着所有与应用程序相关的工作停止，只有GC运行。结果，在响应期间增减了许多混杂请求。另外，更复杂的 GC不断增加或同时运行以减少或者清除应用程序的中断。有的GC使用单线程完成这项工作，有的则采用多线程以增加效率。 常用的垃圾收集算法 （1）Mark-Sweep（标记-清除）算法 标记—清除算法是最基础的收集算法，它分为“标记”和“清除”两个阶段：首先标记出所需回收的对象，在标记完成后统一回收掉所有被标记的对象，它的标记过程其实就是前面的根搜索算法中判定垃圾对象的标记过程。标记—清除算法的执行情况如下图所示： （2）Copying（复制）算法 为了解决Mark-Sweep算法的缺陷，Copying算法就被提了出来，该算法的提出是为了克服句柄的开销和解决堆碎片的垃圾回收。它开始时把堆分成 一个对象 面和多个空闲面， 程序从对象面为对象分配空间，当对象满了，基于copying算法的垃圾 收集就从根集中扫描活动对象，并将每个 活动对象复制到空闲面(使得活动对象所占的内存之间没有空闲洞)，这样空闲面变成了对象面，原来的对象面变成了空闲面，程序会在新的对象面中分配内存。一种典型的基于coping算法的垃圾回收是stop-and-copy算法，它将堆分成对象面和空闲区域面，在对象面与空闲区域面的切换过程中，程序暂停执行。具体过程如下图所示： （3）Mark-Compact（标记-整理）算法 该算法标记的过程与标记—清除算法中的标记过程一样，但对标记后出的垃圾对象的处理情况有所不同，它不是直接对可回收对象进行清理，而是让所有的对象都向一端移动，然后直接清理掉端边界以外的内存。标记—整理算法的回收情况如下所示： (4)Generational Collection（分代收集）算法 分代收集算法是目前大部分JVM的垃圾收集器采用的算法。它的核心思想是根据对象存活的生命周期将内存划分为若干个不同的区域。一般情况下将堆区划分为老年代（Tenured Generation）和新生代（Young Generation），老年代的特点是每次垃圾收集时只有少量对象需要被回收，而新生代的特点是每次垃圾回收时都有大量的对象需要被回收，那么就可以根据不同代的特点采取最适合的收集算法。 目前大部分垃圾收集器对于新生代都采取Copying算法，因为新生代中每次垃圾回收都要回收大部分对象，也就是说需要复制的操作次数较少，但是实际中并不是按照1：1的比例来划分新生代的空间的，一般来说是将新生代划分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden空间和其中的一块Survivor空间，当进行回收时，将Eden和Survivor中还存活的对象复制到另一块Survivor空间中，然后清理掉Eden和刚才使用过的Survivor空间。 而由于老年代的特点是每次回收都只回收少量对象，一般使用的是Mark-Compact算法。大致流程如下图： 常用的垃圾收集器垃圾收集器是内存回收算法的具体实现，Java 虚拟机规范中对垃圾收集器应该如何实现并没有任何规定，因此不同厂商、不同版本的虚拟机所提供的垃圾收集器都可能会有很大的差别。下面介绍一下HotSpot（JDK 7)虚拟机提供的几种垃圾收集器，用户可以根据自己的需求组合出各个年代使用的收集器。 1.Serial/Serial Old Serial/Serial Old收集器是最基本最古老的收集器，它是一个单线程收集器，并且在它进行垃圾收集时，必须暂停所有用户线程。Serial收集器是针对新生代的收集器，采用的是Copying算法，Serial Old收集器是针对老年代的收集器，采用的是Mark-Compact算法。它的优点是实现简单高效，但是缺点是会给用户带来停顿。 2.ParNew ParNew收集器是Serial收集器的多线程版本，使用多个线程进行垃圾收集。 3.Parallel Scavenge Parallel Scavenge收集器是一个新生代的多线程收集器（并行收集器），它在回收期间不需要暂停其他用户线程，其采用的是Copying算法，该收集器与前两个收集器有所不同，它主要是为了达到一个可控的吞吐量。 4.Parallel Old Parallel Old是Parallel Scavenge收集器的老年代版本（并行收集器），使用多线程和Mark-Compact算法。 5.CMS CMS（Current Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器，它是一种并发收集器，采用的是Mark-Sweep算法。 6.G1 G1收集器是当今收集器技术发展最前沿的成果，它是一款面向服务端应用的收集器，它能充分利用多CPU、多核环境。因此它是一款并行与并发收集器，并且它能建立可预测的停顿时间模型。 新生代收集器使用的收集器：Serial、PraNew、Parallel Scavenge 老年代收集器使用的收集器：Serial Old、Parallel Old、CMS 分代的垃圾回收策略，是基于这样一个事实：不同的对象的生命周期是不一样的。因此，不同生命周期的对象可以采取不同的回收算法，以便提高回收效率。 年轻代（Young Generation） 1.所有新生成的对象首先都是放在年轻代的。年轻代的目标就是尽可能快速的收集掉那些生命周期短的对象。 2.新生代内存按照8:1:1的比例分为一个eden区和两个survivor(survivor0,survivor1)区。一个Eden区，两个 Survivor区(一般而言)。大部分对象在Eden区中生成。回收时先将eden区存活对象复制到一个survivor0区，然后清空eden区，当这个survivor0区也存放满了时，则将eden区和survivor0区存活对象复制到另一个survivor1区，然后清空eden和这个survivor0区，此时survivor0区是空的，然后将survivor0区和survivor1区交换，即保持survivor1区为空， 如此往复。 3.当survivor1区不足以存放 eden和survivor0的存活对象时，就将存活对象直接存放到老年代。若是老年代也满了就会触发一次Full GC，也就是新生代、老年代都进行回收 4.新生代发生的GC也叫做Minor GC，MinorGC发生频率比较高(不一定等Eden区满了才触发) 年老代（Old Generation） 1.在年轻代中经历了N次垃圾回收后仍然存活的对象，就会被放到年老代中。因此，可以认为年老代中存放的都是一些生命周期较长的对象。 2.内存比新生代也大很多(大概比例是1:2)，当老年代内存满时触发Major GC即Full GC，Full GC发生频率比较低，老年代对象存活时间比较长，存活率标记高。 持久代（Permanent Generation） 用于存放静态文件，如Java类、方法等。持久代对垃圾回收没有显著影响，但是有些应用可能动态生成或者调用一些class，例如Hibernate 等，在这种时候需要设置一个比较大的持久代空间来存放这些运行过程中新增的类。 对垃圾回收策略说明以下两点： 新生代 GC（Minor GC）：发生在新生代的垃圾收集动作，因为 Java 对象大多都具有朝生夕灭的特性，因此Minor GC 非常频繁，一般回收速度也比较快。 老年代 GC（Major GC/Full GC）：发生在老年代的 GC，出现了 Major GC，经常会伴随至少一次 Minor GC。由于老年代中的对象生命周期比较长，因此 Major GC 并不频繁，一般都是等待老年代满了后才进行 Full GC，而且其速度一般会比 Minor GC 慢 10 倍以上。另外，如果分配了 Direct Memory，在老年代中进行 Full GC时，会顺便清理掉 Direct Memory 中的废弃对象。 GC的执行机制由于对象进行了分代处理，因此垃圾回收区域、时间也不一样。GC有两种类型：Scavenge GC和Full GC。 Scavenge GC 一般情况下，当新对象生成，并且在Eden申请空间失败时，就会触发Scavenge GC，对Eden区域进行GC，清除非存活对象，并且把尚且存活的对象移动到Survivor区。然后整理Survivor的两个区。这种方式的GC是对年轻代的Eden区进行，不会影响到年老代。因为大部分对象都是从Eden区开始的，同时Eden区不会分配的很大，所以Eden区的GC会频繁进行。因而，一般在这里需要使用速度快、效率高的算法，使Eden去能尽快空闲出来。 Full GC 对整个堆进行整理，包括Young、Tenured和Perm。Full GC因为需要对整个堆进行回收，所以比Scavenge GC要慢，因此应该尽可能减少Full GC的次数。在对JVM调优的过程中，很大一部分工作就是对于FullGC的调节。有如下原因可能导致Full GC： 1.年老代（Tenured）被写满 2.持久代（Perm）被写满 3.System.gc()被显示调用 4.上一次GC之后Heap的各域分配策略动态变化 详解分代垃圾回收在JVM中，内存是按照分代进行组织的。 其中，堆内存分为年轻代和年老代，非堆内存主要是Permanent区域，主要用于存储一些类的元数据，常量池等信息。而年轻代又分为两种，一种是Eden区域，另外一种是两个大小对等的Survivor区域。之所以将Java内存按照分代进行组织，主要是基于这样一个“弱假设” - 大多数对象都在年轻时候死亡。同时，将内存按照分代进行组织，使得我们可以在不同的分代上使用不同的垃圾回收算法，使得整个内存的垃圾回收更加有效。 年轻代的垃圾回收 具体流程如下： 在年轻代上采用的垃圾回收算法是“Mark-Copy”算法，并不同于我们前面所了解的任何一种基本垃圾回收算法，但是Mark算法是一样的，基于根对象找到所有的可达对象，具体可看Mark-Sweep算法中的Mark步骤. 而对于Copy算法，它仅仅是简单的将符合一定年龄的对象从一个分代拷贝到另一个分代。 首先，新对象的内存分配都是先在Eden区域中进行的，当Eden区域的空间不足于分配新对象时，就会触发年轻代上的垃圾回收（发生在Eden和Survivor内存区域上），我们称之为”minor garbage collection”.同时，每个对象都有一个“年龄”，这个年龄实际上指的就是该对象经历过的minor gc的次数。如图1所示，当对象刚分配到Eden区域时，对象的年龄为“0”，当minor gc被触发后，所有存活的对象（仍然可达对象）会被拷贝到其中一个Survivor区域，同时年龄增长为“1”。并清除整个Eden内存区域中的非可达对象。 当第二次minor gc被触发时（如图2所示），JVM会通过Mark算法找出所有在Eden内存区域和Survivor1内存区域存活的对象，并将他们拷贝到新的Survivor2内存区域(这也就是为什么需要两个大小一样的Survivor区域的原因)，同时对象的年龄加1. 最后，清除所有在Eden内存区域和Survivor1内存区域的非可达对象。 当对象的年龄足够大（这个年龄可以通过JVM参数进行指定，这里假定是2），当minor gc再次发生时，它会从Survivor内存区域中升级到年老代中，如图3所示。 其实，即使对象的年龄不够大，但是Survivor内存区域中没有足够的空间来容纳从Eden升级过来的对象时，也会有部分对象直接升级到Tenured内存区域中。 年老代的垃圾回收 具体流程如下： 当minor gc发生时，又有对象从Survivor区域升级到Tenured区域，但是Tenured区域已经没有空间容纳新的对象了，那么这个时候就会触发年老代上的垃圾回收，我们称之为”major garbage collection”. 而在年老代上选择的垃圾回收算法则取决于JVM上采用的是什么垃圾回收器。通过的垃圾回收器有两种：Parallel Scavenge(PS) 和Concurrent Mark Sweep(CMS)。这两种垃圾回收器的不同更多的是体现在年老代的垃圾回收过程中，年轻代的垃圾回收过程在这两种垃圾回收器中基本上是一致的。就像其名字所表示的那样，Parallel Scavenge垃圾回收器在执行垃圾回收时使用了多线程来一起进行垃圾回收，这样可以提高垃圾回收的效率。而Concurrent Mark Sweep垃圾回收器在进行垃圾回收时，应用程序可以同时运行。 PS垃圾回收器在年老代上采用的垃圾回收算法可以看作是标记-清除算法和标记-压缩算法的结合体。 首先，PS垃圾回收器先是会在年老代上使用标记-清除算法来回收掉非可达对象所占有的空间，但是我们知道，标记清除算法的一个缺陷就是它会引起内存碎片问题。继而有可能会引发连续的major gc。假设当前存在的内存碎片有10M，但最大的内存碎片只能容纳2M的对象，这个时候如果有一个3M的对象从Survivor区域升级到Tenured区域，那Tenured区域也没有办法存放这个3M的对象。结果就是不断的触发major gc，直到Out of Memory。所以，PS垃圾回收器在清除非可达对象后，还会进行一次compact，来消除内存碎片。如下图： CMS垃圾收集器相比于PS垃圾收集器，它成功的减少了垃圾收集时暂停应用程序的时间，因为CMS在进行垃圾收集时，应用程序是可以并行运行的。下面让我们来看看它是怎么做到的。 从它的名字可以看出，CMS垃圾收集器在年老代上采用的垃圾回收算法是标记-清除算法。但是，它跟标准的标记-清除算法略有不同。它主要分为四个阶段： Initial Mark阶段 - 这个阶段是Stop-The-World的，它会暂停应用程序的运行，但是在这里阶段，它不会标记出在Tenured区域中所有的可达对象。它只会从根对象开始出发，标记到根对象的第一层孩子节点即停止。然后恢复应用程序的运行。所以，这个暂停应用程序的时间是很短的。 Concurrent Mark阶段 - 在这个阶段中，CMS垃圾回收器以Initial Mark阶段标记的节点为根对象，重新开始标记Tenured区域中的可达对象。当然，在这个阶段中是不需要暂停应用程序的。这也是它称为”Concurrent Mark”的原因。这同时也造成了一个问题，那就是由于CMS垃圾回收器和应用程序同时运行，Concurrent Mark阶段它并不保证在Tenured区域的可达对象都被标记了 - 应用程序一直在分配新对象。 Remark阶段 - 由于Concurrent Mark阶段它并不保证在Tenured区域的可达对象都被标记了，所以我们需要再次暂停应用程序，确保所有的可达对象都被标记。为了加快速度，这里也采用了多线程来同时标记可达对象。 Concurrent Sweep阶段 - 最后，恢复应用程序的执行，同时CMS执行sweep，来清除所有非可达对象所占用的内存空间。 一张图看他们的区别： 黑色箭头代表应用程序的运行，绿色箭头代表CMS垃圾收集器的运行。一根线条表示单线程，多个线条表示多线程。 所以，相比于PS垃圾收集器，CMS垃圾收集器成功的减少了应用程序暂时的时间。但是很不幸的是，CMS垃圾收集器虽然减少了暂停应用程序的运行时间，但是由于它没有Compact阶段，它还是存在着内存碎片问题。于是，为了去除内存碎片问题，同时又保留CMS垃圾收集器低暂停时间的优点，JAVA7发布了一个新的垃圾收集器 - G1垃圾收集器。它会在未来逐步替换掉CMS垃圾收集器。 Garbage First(G1)垃圾收集器（JDK7）G1垃圾收集器和CMS垃圾收集器有几点不同。首先，最大的不同是内存的组织方式变了。Eden，Survivor和Tenured等内存区域不再是连续的了，而是变成了一个个大小一样的region - 每个region从1M到32M不等。 一个region有可能属于Eden，Survivor或者Tenured内存区域。图中的E表示该region属于Eden内存区域，S表示属于Survivor内存区域，T表示属于Tenured内存区域。图中空白的表示未使用的内存空间。G1垃圾收集器还增加了一种新的内存区域，叫做Humongous内存区域，如图中的H块。这种内存区域主要用于存储大对象-即大小超过一个region大小的50%的对象。 在G1垃圾收集器中，年轻代的垃圾回收过程跟PS垃圾收集器和CMS垃圾收集器差不多，新对象的分配还是在Eden region中，当所有Eden region的大小超过某个值时，触发minor gc，回收Eden region和Survivor region上的非可达对象，同时升级存活的可达对象到对应的Survivor region和Tenured region上。对象从Survivor region升级到Tenured region依然是取决于对象的年龄。 对于年老代上的垃圾收集，G1垃圾收集器也分为4个阶段，基本跟CMS垃圾收集器一样，但略有不同： Initial Mark阶段 - 同CMS垃圾收集器的Initial Mark阶段一样，G1也需要暂停应用程序的执行，它会标记从根对象出发，在根对象的第一层孩子节点中标记所有可达的对象。但是G1的垃圾收集器的Initial Mark阶段是跟minor gc一同发生的。也就是说，在G1中，你不用像在CMS那样，单独暂停应用程序的执行来运行Initial Mark阶段，而是在G1触发minor gc的时候一并将年老代上的Initial Mark给做了。 Concurrent Mark阶段 - 在这个阶段G1做的事情跟CMS一样。但G1同时还多做了一件事情，那就是，如果在Concurrent Mark阶段中，发现哪些Tenured region中对象的存活率很小或者基本没有对象存活，那么G1就会在这个阶段将其回收掉，而不用等到后面的clean up阶段。这也是Garbage First名字的由来。同时，在该阶段，G1会计算每个 region的对象存活率，方便后面的clean up阶段使用 。 Remark阶段 - 在这个阶段G1做的事情跟CMS一样, 但是采用的算法不同，G1采用一种叫做SATB(snapshot-at-the-begining)的算法能够在Remark阶段更快的标记可达对象。 Clean up/Copy阶段 - 在G1中，没有CMS中对应的Sweep阶段。相反 它有一个Clean up/Copy阶段，在这个阶段中,G1会挑选出那些对象存活率低的region进行回收，这个阶段也是和minor gc一同发生的,如下图所示： 从上可以看到，由于Initial Mark阶段和Clean up/Copy阶段都是跟minor gc同时发生的，相比于CMS，G1暂停应用程序的时间更少，从而提高了垃圾回收的效率。","categories":[{"name":"JVM","slug":"JVM","permalink":"http://zhengweishan.oschina.io/categories/JVM/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://zhengweishan.oschina.io/tags/JAVA/"},{"name":"GC","slug":"GC","permalink":"http://zhengweishan.oschina.io/tags/GC/"},{"name":"JVM","slug":"JVM","permalink":"http://zhengweishan.oschina.io/tags/JVM/"}]},{"title":"ElasticSearch JAVA API基础学习------Elasticsearch学习（二）","slug":"es2","date":"2017-01-18T16:00:00.000Z","updated":"2017-01-20T05:32:38.031Z","comments":true,"path":"2017/01/19/es2/","link":"","permalink":"http://zhengweishan.oschina.io/2017/01/19/es2/","excerpt":"ElasticSearch JAVA API基础学习——Elasticsearch学习（二）在上一篇博客中（Elasticsearch安装）已经完成了es的安装，那么接下来，将介绍下如在java代码中完成对某个索引的类型的文档的增删改查。这个java api的介绍在官网上也有很好的例子，大家可以参考下。 完整演示demo下载： github:https://github.com/wesley5201314/Elasticsearch-demo gitosc:https://git.oschina.net/zhengweishan/Elasticsearch-demo es中的索引就对应数据库，类型就对应着数据库中的表，文档就对应着数据库表中的记录，因此，我们首先得创建一个索引，然后，再创建一个类型，这个类型会包含字段类型信息，然后就可以在这个索引上对此类型的文档进行增删改查了。 下面，将分步介绍：","text":"ElasticSearch JAVA API基础学习——Elasticsearch学习（二）在上一篇博客中（Elasticsearch安装）已经完成了es的安装，那么接下来，将介绍下如在java代码中完成对某个索引的类型的文档的增删改查。这个java api的介绍在官网上也有很好的例子，大家可以参考下。 完整演示demo下载： github:https://github.com/wesley5201314/Elasticsearch-demo gitosc:https://git.oschina.net/zhengweishan/Elasticsearch-demo es中的索引就对应数据库，类型就对应着数据库中的表，文档就对应着数据库表中的记录，因此，我们首先得创建一个索引，然后，再创建一个类型，这个类型会包含字段类型信息，然后就可以在这个索引上对此类型的文档进行增删改查了。 下面，将分步介绍： 创建一个EsClient.java类，直接贴出代码如下： package com.es.demo; import java.io.IOException; import java.net.InetAddress; import java.util.Properties; import org.elasticsearch.client.transport.TransportClient; import org.elasticsearch.common.settings.Settings; import org.elasticsearch.common.transport.InetSocketTransportAddress; public class EsClient { /** 配置文件参数 */ private static Properties properties = null; private static String es_ip = null; //ip private static int es_port = 0; //端口 private static String es_cluster_name = null; //集群名字 private static TransportClient client = null; public TransportClient getClient() throws IOException{ properties = new Properties(); properties.load(TransportClient.class.getClassLoader().getResourceAsStream(&quot;env.properties&quot;)); es_ip = properties.getProperty(&quot;target.es.ip&quot;); es_port = Integer.valueOf(properties.getProperty(&quot;target.es.port&quot;)); es_cluster_name = properties.getProperty(&quot;target.es.cluster.name&quot;); System.out.println(&quot;原始地址，es_ip = &quot;+es_ip); String [] hosts = es_ip.split(&quot;,&quot;); System.out.println(&quot;切割之后的esIp数组 = &quot;+hosts);//针对于以后的集群部署我这里只有 一台服务器 Settings settings = Settings.settingsBuilder() .put(&quot;cluster.name&quot;,es_cluster_name) .put(&quot;client.transport.sniff&quot;, true).build(); client = TransportClient.builder().settings(settings) .build(); for(int i=0;i&lt;hosts.length;i++){ client.addTransportAddress(new InetSocketTransportAddress(InetAddress.getByName(hosts[i]), es_port)); } return client; } } 然后创建一个实体类Test.java对应es中的数据 package com.es.demo; public class Test { private String author; private String content; private String title; private String category; public String getAuthor() { return author; } public void setAuthor(String author) { this.author = author; } public String getContent() { return content; } public void setContent(String content) { this.content = content; } public String getTitle() { return title; } public void setTitle(String title) { this.title = title; } public String getCategory() { return category; } public void setCategory(String category) { this.category = category; } @Override public String toString() { return &quot;Test [author=&quot; + author + &quot;, content=&quot; + content + &quot;, title=&quot; + title + &quot;, category=&quot; + category + &quot;]&quot;; } } 然后再提供一个转换工具类（此类不是多好，有好的大家可以提供下）： package com.es.demo; import java.lang.reflect.Field; import java.lang.reflect.InvocationTargetException; import java.lang.reflect.Method; import java.math.BigDecimal; import java.math.BigInteger; import java.util.Date; import java.util.Map; import org.joda.time.DateTime; import org.joda.time.format.ISODateTimeFormat; /** * * &lt;br&gt; * 标题: map转成bean&lt;br&gt; * 描述: &lt;br&gt; * 公司: www.tydic.com&lt;br&gt; * @autho wesley * @time 2016年10月31日 下午5:03:08 */ public class ConverterUtil { /** 转换为驼峰（大写） * * @param underscoreName * @return */ public static String camelCaseName(String underscoreName) { StringBuilder result = new StringBuilder(); if (underscoreName != null &amp;&amp; underscoreName.length() &gt; 0) { boolean flag = false; for (int i = 0; i &lt; underscoreName.length(); i++) { char ch = underscoreName.charAt(i); if (&quot;_&quot;.charAt(0) == ch) { flag = true; } else { if (flag) { result.append(Character.toUpperCase(ch)); flag = false; } else { result.append(Character.toLowerCase(ch)); } } } } return result.toString(); } /** 转换为下划线(大写) * * @param camelCaseName * @return */ public static String underscoreName(String camelCaseName) { StringBuilder result = new StringBuilder(); int len = camelCaseName.length(); if (camelCaseName != null &amp;&amp; len &gt; 0) { result.append(camelCaseName.substring(0, 1).toUpperCase()); for (int i = 1; i &lt; len; i++) { char ch = camelCaseName.charAt(i); if (Character.isUpperCase(ch)) { result.append(&quot;_&quot;); result.append(ch); } else { result.append(Character.toUpperCase(ch)); } } } return result.toString(); } /** 把Map&lt;String,Object&gt;处理成实体类 * * @param clazz *想要的实体类 * @param map *包含信息的Map对象 * @return */ @SuppressWarnings({ &quot;unchecked&quot;, &quot;rawtypes&quot; }) public static Object mapToObject(Class clazz, Map&lt;String, Object&gt; map) { if (null == map) { return null; } Field[] fields = clazz.getDeclaredFields(); // 取到类下所有的属性，也就是变量名 Field field; Object o = null; try { o = clazz.newInstance(); } catch (InstantiationException e1) { e1.printStackTrace(); } catch (IllegalAccessException e1) { e1.printStackTrace(); } for (int i = 0; i &lt; fields.length; i++) { field = fields[i]; String fieldName = field.getName(); // 把属性的第一个字母处理成大写 String stringLetter = fieldName.substring(0, 1).toUpperCase(); // 取得set方法名，比如setBbzt String setterName = &quot;set&quot; + stringLetter + fieldName.substring(1); // 真正取得set方法。 Method setMethod = null; Class fieldClass = field.getType(); try { if (isHaveSuchMethod(clazz, setterName)) { if (fieldClass == String.class) { setMethod = clazz.getMethod(setterName, fieldClass); if (null != map.get(fieldName) &amp;&amp; !(&quot;&quot;).equals(map.get(fieldName))) { setMethod.invoke(o, String.valueOf(map.get(fieldName)));// 为其赋值 } } else if (fieldClass == Integer.class || fieldClass == int.class) { setMethod = clazz.getMethod(setterName, fieldClass); if (null != map.get(fieldName) &amp;&amp; !(&quot;&quot;).equals(map.get(fieldName))) { setMethod.invoke(o, Integer.parseInt(String.valueOf(map.get(fieldName))));// 为其赋值 } } else if (fieldClass == Boolean.class || fieldClass == boolean.class) { setMethod = clazz.getMethod(setterName, fieldClass); if (null != map.get(fieldName) &amp;&amp; !(&quot;&quot;).equals(map.get(fieldName))) { setMethod.invoke(o, Boolean.getBoolean(String.valueOf(map.get(fieldName))));// 为其赋值 } } else if (fieldClass == Short.class || fieldClass == short.class) { setMethod = clazz.getMethod(setterName, fieldClass); if (null != map.get(fieldName) &amp;&amp; !(&quot;&quot;).equals(map.get(fieldName))) { setMethod.invoke(o, Short.parseShort(String.valueOf(map.get(fieldName))));// 为其赋值 } } else if (fieldClass == Long.class || fieldClass == long.class) { setMethod = clazz.getMethod(setterName, fieldClass); if (null != map.get(fieldName) &amp;&amp; !(&quot;&quot;).equals(map.get(fieldName))) { setMethod.invoke(o, Long.parseLong(String.valueOf(map.get(fieldName))));// 为其赋值 } } else if (fieldClass == Double.class || fieldClass == double.class) { setMethod = clazz.getMethod(setterName, fieldClass); if (null != map.get(fieldName) &amp;&amp; !(&quot;&quot;).equals(map.get(fieldName))) { setMethod.invoke(o, Double.parseDouble(String.valueOf(map.get(fieldName))));// 为其赋值 } } else if (fieldClass == Float.class || fieldClass == float.class) { setMethod = clazz.getMethod(setterName, fieldClass); if (null != map.get(fieldName) &amp;&amp; !(&quot;&quot;).equals(map.get(fieldName))) { setMethod.invoke(o, Float.parseFloat(String.valueOf(map.get(fieldName))));// 为其赋值 } } else if (fieldClass == BigInteger.class) { setMethod = clazz.getMethod(setterName, fieldClass); if (null != map.get(fieldName) &amp;&amp; !(&quot;&quot;).equals(map.get(fieldName))) { setMethod.invoke(o, BigInteger.valueOf(Long.parseLong(String.valueOf(map.get(fieldName)))));// 为其赋值 } } else if (fieldClass == BigDecimal.class) { setMethod = clazz.getMethod(setterName, fieldClass); if (null != map.get(fieldName) &amp;&amp; !(&quot;&quot;).equals(map.get(fieldName))) { setMethod.invoke(o, BigDecimal.valueOf(Long.parseLong(String.valueOf(map.get(fieldName)))));// 为其赋值 } } else if (fieldClass == Date.class) { setMethod = clazz.getMethod(setterName, fieldClass); if (null != map.get(fieldName) &amp;&amp; !(&quot;&quot;).equals(map.get(fieldName))) { DateTime date = ISODateTimeFormat.dateTimeParser().parseDateTime((String) map.get(fieldName)); setMethod.invoke(o, new Date(date.getMillis()));// 为期赋值 } /* * if (map.get(fieldName).getClass() == java.sql.Date.class) { setMethod.invoke(o, new Date(((java.sql.Date) * map.get(fieldName)).getTime()));// 为其赋值 } else if (map.get(fieldName).getClass() == * java.sql.Time.class) { setMethod.invoke(o, new Date(((java.sql.Time) map.get(fieldName)).getTime()));// 为其赋值 } else * if (map.get(fieldName).getClass() == java.sql.Timestamp.class) { setMethod.invoke(o, new Date(((java.sql.Timestamp) * map.get(fieldName)).getTime()));// 为其赋值 }else if(map.get(fieldName).getClass() == * org.joda.time.format.ISODateTimeFormat.class){ DateTime date = * ISODateTimeFormat.dateTimeParser().parseDateTime((String)map.get(fieldName)); setMethod.invoke(o, new * Date(date.getMillis())); } */ } } } catch (SecurityException e) { e.printStackTrace(); } catch (NoSuchMethodException e) { e.printStackTrace(); } catch (IllegalArgumentException e) { e.printStackTrace(); } catch (IllegalAccessException e) { e.printStackTrace(); } catch (InvocationTargetException e) { e.printStackTrace(); } } return o; } /** 判断某个类里是否有某个方法 * * @param clazz * @param methodName * @return */ public static boolean isHaveSuchMethod(Class&lt;?&gt; clazz, String methodName) { Method[] methodArray = clazz.getMethods(); boolean result = false; if (null != methodArray) { for (int i = 0; i &lt; methodArray.length; i++) { if (methodArray[i].getName().equals(methodName)) { result = true; break; } } } return result; } public static void main(String[] args) { System.err.println(underscoreName(&quot;name_full&quot;)); System.err.println(camelCaseName(&quot;NAME_FILL&quot;)); System.err.println(camelCaseName(&quot;nameFill&quot;)); System.err.println(underscoreName(&quot;nameFill&quot;)); } } 暂时没有封装，直接用main学习演示基本操作的的，代码如下： package com.es.demo; import java.io.IOException; import java.util.ArrayList; import java.util.HashMap; import java.util.List; import java.util.Map; import org.elasticsearch.action.ActionWriteResponse.ShardInfo; import org.elasticsearch.action.admin.indices.create.CreateIndexRequestBuilder; import org.elasticsearch.action.admin.indices.create.CreateIndexResponse; import org.elasticsearch.action.admin.indices.delete.DeleteIndexRequest; import org.elasticsearch.action.admin.indices.delete.DeleteIndexRequestBuilder; import org.elasticsearch.action.admin.indices.delete.DeleteIndexResponse; import org.elasticsearch.action.admin.indices.mapping.put.PutMappingRequest; import org.elasticsearch.action.admin.indices.mapping.put.PutMappingResponse; import org.elasticsearch.action.delete.DeleteRequestBuilder; import org.elasticsearch.action.delete.DeleteResponse; import org.elasticsearch.action.index.IndexRequestBuilder; import org.elasticsearch.action.index.IndexResponse; import org.elasticsearch.action.indexedscripts.delete.DeleteIndexedScriptRequestBuilder; import org.elasticsearch.action.search.SearchRequestBuilder; import org.elasticsearch.action.search.SearchResponse; import org.elasticsearch.action.search.SearchType; import org.elasticsearch.action.update.UpdateRequestBuilder; import org.elasticsearch.action.update.UpdateResponse; import org.elasticsearch.client.Requests; import org.elasticsearch.client.transport.TransportClient; import org.elasticsearch.common.xcontent.XContentBuilder; import org.elasticsearch.common.xcontent.XContentFactory; import org.elasticsearch.index.query.BoolQueryBuilder; import org.elasticsearch.index.query.QueryBuilders; import org.elasticsearch.search.SearchHit; import org.elasticsearch.search.SearchHits; import com.fasterxml.jackson.databind.ObjectMapper; /** * Hello world! * */ public class App { public static void main( String[] args ) throws IOException { EsClient esClient = new EsClient(); TransportClient client = esClient.getClient(); //---------------演示查询 /* SearchRequestBuilder request = client.prepareSearch(&quot;wesley&quot;) .setTypes(&quot;test&quot;).setSearchType(SearchType.QUERY_THEN_FETCH); //初始化查询参数 BoolQueryBuilder query = QueryBuilders.boolQuery(); query.must(QueryBuilders.termQuery(&quot;author&quot;,&quot;author&quot;)); request.setQuery(query); //查询操作 SearchResponse response = request.execute().actionGet(); List&lt;Test&gt; returnList = new ArrayList&lt;Test&gt;(); SearchHits hints = response.getHits(); for(SearchHit theHit : hints){// 每条纪录 Map&lt;String,Object&gt; testInfo = new HashMap&lt;String,Object&gt;(); for(Map.Entry&lt;String, Object&gt; entity : theHit.getSource().entrySet()){ testInfo.put(entity.getKey(), entity.getValue()==null ? null : entity.getValue().toString());// 根据数值大小，value 可能为Integer/Long 不依赖ES映射类型 } returnList.add((Test)ConverterUtil.mapToObject(Test.class, testInfo)); } for(Test test:returnList){ System.out.println(&quot;-----------------&quot;+test); }*/ //---------------演示查询------------end //-----------演示创建索引,类型,文档----------- /*ObjectMapper objectMapper = new ObjectMapper(); Test test = new Test(); test.setAuthor(&quot;author6&quot;); test.setCategory(&quot;category6&quot;); test.setTitle(&quot;title6&quot;); test.setContent(&quot;content6&quot;); String source = objectMapper.writeValueAsString(test); System.out.println(&quot;--------&quot;+source); IndexRequestBuilder indexBuilder = client.prepareIndex().setIndex(&quot;wesley6&quot;).setType(&quot;test6&quot;).setSource(source); IndexResponse indexResponse = indexBuilder.execute().actionGet(); System.out.println(&quot;--------&quot;+indexResponse.isCreated()+&quot;----------&quot;);*/ //-----------演示创建索引,类型,文档-----------end //------------演示删除文档------- /*DeleteRequestBuilder deleteRequestBuilder = client.prepareDelete(&quot;wesley6&quot;, &quot;test6&quot;, &quot;AVmV5176AmysSwOEBaDt&quot;); DeleteResponse deleteResponse = deleteRequestBuilder.execute().actionGet(); System.out.println(&quot;------isDelete-----&quot;+deleteResponse.isFound());*/ //------------演示删除文档-------end //------------演示删除指定索引------- /*DeleteIndexRequestBuilder deleteRequestBuilder = client.admin().indices().prepareDelete(&quot;wesley6&quot;); DeleteIndexResponse deleteResponse = deleteRequestBuilder.execute().actionGet(); System.out.println(&quot;------isDelete-----&quot;+deleteResponse.isAcknowledged());*/ //------------演示删除指定索引-------end //----------演示创建索引，类型 // 使用XContentBuilder创建Mapping /*XContentBuilder builder = XContentFactory.jsonBuilder() .startObject() .field(&quot;properties&quot;) .startObject() .field(&quot;name&quot;) .startObject() .field(&quot;index&quot;, &quot;not_analyzed&quot;) .field(&quot;type&quot;, &quot;string&quot;) .endObject() .field(&quot;age&quot;) .startObject() .field(&quot;index&quot;, &quot;not_analyzed&quot;) .field(&quot;type&quot;, &quot;integer&quot;) .endObject() .endObject() .endObject(); System.out.println(builder.string()); //创建索引 CreateIndexRequestBuilder createIndexRequestBuilder = client.admin().indices().prepareCreate(&quot;wesley00&quot;); CreateIndexResponse createIndexResponse = createIndexRequestBuilder.execute().actionGet(); System.out.println(&quot;------isCreated----&quot;+createIndexResponse.isAcknowledged()); //创建type PutMappingRequest mappingRequest = Requests.putMappingRequest(&quot;wesley00&quot;).source(builder).type(&quot;user&quot;); PutMappingResponse putMappingResponse = client.admin().indices().putMapping(mappingRequest).actionGet(); System.out.println(&quot;------isCreated----&quot;+putMappingResponse.isAcknowledged());*/ //----------演示创建索引，类型---end //---------演示更新文档---- XContentBuilder builder = XContentFactory.jsonBuilder() .startObject() .field(&quot;author&quot;, &quot;lisi&quot;) .field(&quot;title&quot;, &quot;update111&quot;) .field(&quot;content&quot;,&quot;111111&quot;) .field(&quot;category&quot;,&quot;category-update&quot;) .endObject(); UpdateRequestBuilder updateRequestBuilder = client.prepareUpdate().setIndex(&quot;wesley&quot;).setType(&quot;test&quot;).setDoc(builder).setId(&quot;1111&quot;); System.out.println(&quot;----------&quot;+updateRequestBuilder); UpdateResponse updateResponse = updateRequestBuilder.execute().actionGet(); System.out.println(&quot;---------&quot;+updateResponse); //说明isCreated这个方法如果返回的是true说明原来没有数据重新创建了，如果返回false说明更新成功。不知道他们为什么这么设计。 //Returns true if document was created due to an UPSERT operation 源码中的注释说明。 System.out.println(&quot;---------&quot;+updateResponse.isCreated()+&quot;---version-&quot;+updateResponse.getVersion()+&quot;-------------&quot;); // ////---------演示更新文档----end-- } } 最后，稍作总结，上面都是只贴出了代码，也没给出比较详细的解释，这个大家可以参考着官网的介绍，然后结合贴出的代码，估计就能够看懂了。另外，还有其它java api比如聚合查询，暂时也没去研究，大家可以去学习下，我也是刚学，有啥问题的地方欢迎指出，谢谢！ ElasticSearch2.x API变化官网链接https://www.elastic.co/guide/en/elasticsearch/reference/2.3/breaking-changes-2.0.html","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://zhengweishan.oschina.io/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch学习","slug":"Elasticsearch学习","permalink":"http://zhengweishan.oschina.io/tags/Elasticsearch学习/"}]},{"title":"Elasticsearch安装与Elasticsearch-Head插件安转(windows环境)------Elasticsearch学习（一）","slug":"es1","date":"2017-01-18T16:00:00.000Z","updated":"2017-01-20T05:32:23.359Z","comments":true,"path":"2017/01/19/es1/","link":"","permalink":"http://zhengweishan.oschina.io/2017/01/19/es1/","excerpt":"Elasticsearch安装与Elasticsearch-Head插件安转(windows环境)——Elasticsearch学习（一）概述Elasticsearch是一个基于Apache Lucene(TM)的开源分布式搜索引擎，是一个高可扩展的、开源的全文本搜索和分析工具。 安装Elasticsearch目前最新版本是5.1.1，这里需要注意的是这个版本的需要使用JDK1.8以及以后的版本。下载地址： https://www.elastic.co/downloads/elasticsearch 官方说法： Elasticsearch requires Java 8 or later. Use the official Oracle distribution or an open-source distribution such as OpenJDK. 我这里就下载了2.4.3版本的（需要JDK1.7）","text":"Elasticsearch安装与Elasticsearch-Head插件安转(windows环境)——Elasticsearch学习（一）概述Elasticsearch是一个基于Apache Lucene(TM)的开源分布式搜索引擎，是一个高可扩展的、开源的全文本搜索和分析工具。 安装Elasticsearch目前最新版本是5.1.1，这里需要注意的是这个版本的需要使用JDK1.8以及以后的版本。下载地址： https://www.elastic.co/downloads/elasticsearch 官方说法： Elasticsearch requires Java 8 or later. Use the official Oracle distribution or an open-source distribution such as OpenJDK. 我这里就下载了2.4.3版本的（需要JDK1.7） 下载地址（版本2.4.3） 下载完成后，解压缩在一个指定的目录。在cmd命令行进入该目录，再进入 bin目录，运行elasticsearch.bat命令，启动成功后。在浏览器中输入:http://localhost:9200/ 表示安装成功了。 官网安装：https://www.elastic.co/guide/en/elasticsearch/reference/2.4/_installation.html 安装Plugin（Elasticsearch-Head）在cmd命令行中进入安装目录，运行以下命令： 查看安装插件的命令，或者在bin目录下执行： plugin -h 在执行如下命令： 或者在bin目录下执行： plugin install mobz/elasticsearch-head 然后安装成功后，在浏览器中输入:http://localhost:9200/_plugin/head/，可以看到效果。 如果不用安装命令，也可以直接下载安装。下载安装包 在cmd命令行中进入安装目录，看是否有plugins目录，如果没有，则创建(第一次时，没有,需要创建)。 进入plugins目录,创建head目录 进入head目录，创建_site目录 解压下载的elasticsearch-head-master.zip,将其elasticsearch-head-master目录下的所有文件放入_site目录中。 再次重新启动elasticsearch。在浏览器中输入:http://localhost:9200/_plugin/head/查看结果。 至此，需要的环境就搭建完毕，有些插件大家可以根据需要安装，我这里就安装了一个方便通过浏览器直接与Elasticsearch进行交互。","categories":[{"name":"Elasticsearch","slug":"Elasticsearch","permalink":"http://zhengweishan.oschina.io/categories/Elasticsearch/"}],"tags":[{"name":"Elasticsearch学习","slug":"Elasticsearch学习","permalink":"http://zhengweishan.oschina.io/tags/Elasticsearch学习/"}]},{"title":"Hello World","slug":"hello-world","date":"2017-01-17T02:31:59.321Z","updated":"2017-01-20T05:33:00.495Z","comments":true,"path":"2017/01/17/hello-world/","link":"","permalink":"http://zhengweishan.oschina.io/2017/01/17/hello-world/","excerpt":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}